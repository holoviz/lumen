{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Chat with Your Data","text":"<p>An open-source Python framework for building extensible, domain-aware AI data applications.</p>    Your browser does not support the video tag.  <p>Lumen is designed for teams who want conversational data exploration without giving up control:</p> <ul> <li>Open source and inspectable end-to-end</li> <li>Extensible and configurable: plug in custom data sources, Python analyses, tools, and agents</li> <li>Domain-aware: encode business logic, terminology, and constraints directly in code</li> </ul> <p>Ask questions in natural language, but keep execution explicit, reproducible, and grounded in Python.</p> <p>Quick Demo</p> <p>New to Lumen? Try our 30-second quick start ‚Üí to see it in action with a walkthrough.</p> <p>Bring your own LLM. Then connect to your data sources: Snowflake, BigQuery, DuckDB, and any database supported by SQLAlchemy. See all installation options ‚Üí</p> CSV File + OpenAIDuckDB + LLM GatewaysSQLAlchemy + Local LLMsBigQuery + GoogleSnowflake + MistralPostgreSQL + Ollama (Local) <pre><code>export OPENAI_API_KEY=sk-...\n\nlumen-ai serve your_data.csv --provider openai --show  # parquet also works\n</code></pre> <p>Then ask:</p> <ul> <li>Show me the top 10 rows</li> <li>What's the average revenue by region? Plot as a bar chart.</li> <li>Filter for sales over $1000 and create a histogram</li> </ul> <pre><code>from lumen.sources.duckdb import DuckDBSource\nimport lumen.ai as lmai\n\nsource = DuckDBSource(\n    tables={\n        \"penguins\": \"https://datasets.holoviz.org/penguins/v1/penguins.csv\"\n    }\n)\n\nllm = lmai.llm.Bedrock()  # LiteLLM also works\nui = lmai.ExplorerUI(data=source, llm=llm)\nui.servable()\n</code></pre> <p>Then ask:</p> <ul> <li>Which islands have the most penguins? Plot as a horizontal bar chart.</li> <li>Create a scatter plot of bill length vs body mass, colored by species</li> <li>Calculate the ratio of flipper length to body mass, then plot it</li> </ul> <pre><code>from lumen.sources.sqlalchemy import SQLAlchemySource\n\nsource = SQLAlchemySource(\n    url='sqlite:///data.db'  # any database flavor\n)\nllm = lmai.llm.AINavigator()  # LlamaCpp or Ollama also work\nui = lmai.ExplorerUI(data=source, llm=llm)\nui.servable()\n</code></pre> <p>Then ask:</p> <ul> <li>How much sleep did I get last week?</li> <li>Show a timeseries of my daily step counts</li> <li>What's the average heart rate during workouts?</li> </ul> <pre><code>from lumen.sources.bigquery import BigQuerySource\nimport lumen.ai as lmai\n\nsource = BigQuerySource(project_id='your-project-id')\n\nllm = lmai.llm.Google()\nui = lmai.ExplorerUI(data=source, llm=llm)\nui.servable()\n</code></pre> <p>Then ask:</p> <ul> <li>What are the peak traffic hours? Show as a line chart.</li> <li>Calculate conversion rate by source and display in a table</li> <li>Find anomalies in daily user counts</li> </ul> <pre><code>from lumen.sources.snowflake import SnowflakeSource\nimport lumen.ai as lmai\n\nsource = SnowflakeSource(\n    account='your-account',\n    database='your-database',\n    authenticator='externalbrowser'\n)\n\nllm = lmai.llm.MistralAI()\nui = lmai.ExplorerUI(data=source, llm=llm)\nui.servable()\n</code></pre> <p>Then ask:</p> <ul> <li>Which customers have the highest lifetime value?</li> <li>Show monthly revenue trends for the last year</li> <li>Join orders and products, then show top categories by profit</li> </ul> <pre><code>export OPENAI_BASE_URL=http://localhost:11434/v1\nexport OPENAI_API_KEY=ollama\n\nlumen-ai serve postgresql://user:pass@localhost/mydb \\\n  --provider ollama \\\n  --model qwen3:32b \\\n  --show\n</code></pre> <p>Then ask:</p> <ul> <li>Show me customer signup trends by month</li> <li>Which products have declining sales? Show the trend.</li> <li>Find users who haven't logged in for 90 days</li> </ul>","path":["Chat with Your Data"],"tags":[]},{"location":"#why-lumen","level":2,"title":"Why Lumen?","text":"<p>Stop waiting for data teams. Ask questions in plain English.</p> <p>You have questions about your data. Your data team is backlogged three sprints. You could learn SQL, but by the time you do, the question will have changed.</p> <p>Lumen eliminates this bottleneck. See launch options ‚Üí</p> Who Benefit Data analysts Skip boilerplate code and focus on insights Developers Build data apps in hours instead of weeks Data teams Enable self-service without losing control Researchers Share reproducible analysis without teaching syntax <p>No vendor lock-in. Use OpenAI, Google, Anthropic, Mistral, or run models locally with LlamaCPP so that your data never leaves your machine. Configure your LLM provider ‚Üí</p> <pre><code># Run 100% local - no API keys, no cloud, full privacy\nllm = lmai.llm.LlamaCpp(\n    model_kwargs={\n        'default': {\n            'repo_id': 'unsloth/Qwen3-8B-GGUF',\n            'filename': 'Qwen3-8B-Q5_K_M.gguf'\n        }\n    }\n)\nui = lmai.ExplorerUI(data='data.csv', llm=llm)\n\n# Or switch to cloud providers anytime - just one line\n# llm=lmai.llm.OpenAI() or Anthropic(), Google(), MistralAI()\n</code></pre> <p>Connect to anything. PostgreSQL, Snowflake, DuckDB, or CSV files‚Äîif it has data, Lumen can support it. See all data sources ‚Üí</p> <pre><code># Mix sources - local files + cloud databases\nui = lmai.ExplorerUI(data=[\n    'local_data.csv',                                    # CSV file\n    'postgresql://localhost/mydb',                       # PostgreSQL\n    SnowflakeSource(account='...', database='...'),      # Snowflake\n    BigQuerySource(project_id='my-project')              # BigQuery\n])\n</code></pre> <p>Designed for extension. Pure Python + YAML configs. Build custom agents, tools, and visualizations when you need them. Or use Reports to turn recurring analyses into one-click reproducible dashboards. View tutorials ‚Üí</p> Custom AnalysisCustomize Agent PromptsAdd Custom Tools <pre><code># Add domain-specific analysis in minutes\nclass RevenueAnalysis(lmai.analysis.Analysis):\n    \"\"\"Calculate key revenue metrics.\"\"\"\n\n    columns = ['revenue', 'churned']\n\n    def __call__(self, pipeline, ctx):\n        df = pipeline.data\n        return pd.DataFrame({\n            'MRR': df['revenue'].sum() / 12,\n            'Churn Rate': (df['churned'].sum() / len(df)) * 100\n        }, index=[0])\n\nui = lmai.ExplorerUI(data=source, analyses=[RevenueAnalysis])\n</code></pre> <p>Analyses run deterministic calculations with code instead of LLM generation‚Äîperfect for financial metrics, scientific formulas, or any calculation that must produce identical results every time.</p> <p>Learn about analyses ‚Üí</p> <pre><code># Teach agents your domain terminology\ncontext = \"\"\"\n{{ super() }}\n\nIn our business:\n- \"Accounts\" means customer accounts\n- Q1 = Jan-Mar, Q2 = Apr-Jun, Q3 = Jul-Sep, Q4 = Oct-Dec\n- \"Active\" means logged in within 30 days\n\"\"\"\n\nagent = lmai.agents.ChatAgent(\n    template_overrides={\"main\": {\"context\": context}}\n)\nui = lmai.ExplorerUI(data=source, agents=[agent])\n</code></pre> <p>Agents are specialized workers that handle different question types (SQLAgent writes queries, VegaLiteAgent creates charts). Customize their prompts to teach them your domain terminology and business rules.</p> <p>Learn prompt customization ‚Üí</p> <pre><code># Extend agents with custom functions\ndef calculate_customer_ltv(customer_id: str, table) -&gt; dict:\n    \"\"\"Calculate customer lifetime value.\"\"\"\n    customer_data = table[table['customer_id'] == customer_id]\n    total_revenue = customer_data['revenue'].sum()\n    return {\n        'ltv': total_revenue,\n        'avg_order': total_revenue / len(customer_data)\n    }\n\ntool = lmai.tools.FunctionTool(\n    function=calculate_customer_ltv,\n    requires=['table'],\n    provides=['ltv', 'avg_order']\n)\nui = lmai.ExplorerUI(data=source, tools=[tool])\n</code></pre> <p>Tools let agents access external data and perform specialized tasks‚Äîwrap APIs, integrate libraries, or add custom business logic that agents can call when needed.</p> <p>Learn about tools ‚Üí</p>","path":["Chat with Your Data"],"tags":[]},{"location":"#what-makes-it-different","level":2,"title":"What Makes It Different?","text":"<p>AI + YAML + Python. Use what fits your workflow.</p> Traditional BI Code-First Lumen Inflexible, expensive Too much boilerplate Chat for instant results Vendor lock-in Manual UI building YAML specs for reproducibility No customization Full control Python extensions when needed <p>Chat with your data to generate visualizations instantly, write YAML specs for reproducible dashboards, or drop into Python for custom logic:</p> AI ConversationYAML SpecificationResult <p>You: \"Create a dashboard showing penguin measurements by species with filters\"</p> <p>Lumen AI generates:</p> <ul> <li>SQL queries to aggregate data</li> <li>Interactive filters for species, island, sex</li> <li>Multiple visualizations (scatter plot, histogram, table)</li> <li>Responsive layout</li> </ul> <p>Try it now ‚Üí</p> <pre><code>sources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  filtered:\n    source: penguins\n    table: data\n    filters:\n      - type: widget\n        field: species\n      - type: widget\n        field: island\n\nlayouts:\n  - title: Palmer Penguins Dashboard\n    pipeline: filtered\n    views:\n      - type: hvplot\n        kind: scatter\n        x: bill_length_mm\n        y: bill_depth_mm\n        color: species\n      - type: hvplot\n        kind: hist\n        y: body_mass_g\n      - type: table\n</code></pre> <p>Learn YAML specs ‚Üí</p> <p></p> <p>Interactive dashboard with:</p> <ul> <li>üìä Scatter plot showing bill measurements by species</li> <li>üìà Histogram of body mass distribution</li> <li>üìã Filterable data table</li> <li>üéõÔ∏è Sidebar widgets for filtering</li> <li>üé® Dark theme</li> <li>üì± Responsive design</li> </ul> <p>Built in 15 minutes with YAML or 2 minutes with AI chat.</p>","path":["Chat with Your Data"],"tags":[]},{"location":"#community-support","level":2,"title":"Community &amp; Support","text":"<p>Questions? Join our community:</p> <ul> <li>Forum: Discourse</li> <li>Chat: Discord</li> <li>Bugs: GitHub Issues</li> <li>Contributing: Guide</li> </ul>","path":["Chat with Your Data"],"tags":[]},{"location":"contributing/","level":1,"title":"Contributing to Lumen","text":"<p>We welcome contributions from the community! Here's how to help.</p>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#ways-to-contribute","level":2,"title":"Ways to Contribute","text":"","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#report-bugs","level":3,"title":"üêõ Report Bugs","text":"<p>Found an issue? Open a GitHub issue:</p> <ul> <li>Be specific about what failed</li> <li>Include traceback/error message</li> <li>Provide minimal reproducible example</li> <li>Your environment (OS, Python version, etc.)</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#improve-documentation","level":3,"title":"üìö Improve Documentation","text":"<p>Help others learn Lumen:</p> <ul> <li>Fix typos and clarify language</li> <li>Add examples and use cases</li> <li>Improve existing guides</li> <li>Submit new tutorials</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#suggest-features","level":3,"title":"‚ú® Suggest Features","text":"<p>Have an idea? Open a GitHub issue:</p> <ul> <li>Explain the use case</li> <li>Describe what you want to build</li> <li>Vote on existing feature requests</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#contribute-code","level":3,"title":"üîß Contribute Code","text":"<ul> <li>Bug fixes welcome</li> <li>New features via discussion first</li> <li>Performance improvements</li> <li>Tests and test improvements</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#help-in-community","level":3,"title":"üí¨ Help in Community","text":"<ul> <li>Answer questions on Discourse</li> <li>Share examples and projects</li> <li>Participate in discussions</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#getting-started-with-code","level":2,"title":"Getting Started with Code","text":"","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#1-fork-clone","level":3,"title":"1. Fork &amp; Clone","text":"<pre><code># Visit and fork the repo on GitHub\n[https://github.com/holoviz/lumen](https://github.com/holoviz/lumen)\n# Then clone your fork\ngit clone https://github.com/YOUR_USERNAME/lumen.git\ncd lumen\n</code></pre>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#2-create-environment","level":3,"title":"2. Create Environment","text":"<pre><code># Using pixi (recommended)\npixi install\n\n# Or using pip\npip install -e \".[tests]\"\n</code></pre>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#pixi-environments","level":4,"title":"Pixi Environments","text":"<p>Lumen uses pixi for development. Key environments:</p> <ul> <li><code>test-312</code> / <code>test-313</code>: Full test suite with AI and SQL dependencies</li> <li><code>test-core</code>: Minimal test environment</li> <li><code>docs</code>: Documentation building</li> <li><code>lint</code>: Code linting with pre-commit</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#3-make-your-changes","level":3,"title":"3. Make Your Changes","text":"<pre><code># Create a branch\ngit checkout -b fix/issue-name\n\n# Make changes, test, commit\ngit add .\ngit commit -m \"Fix: clear description of change\"\n</code></pre>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#4-run-tests","level":3,"title":"4. Run Tests","text":"<pre><code># Run test suite with pixi\npixi run -e test-312 test-unit\n</code></pre>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#5-lint-your-code","level":3,"title":"5. Lint Your Code","text":"<pre><code># Run linting\npixi run -e lint lint\n</code></pre>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#6-build-preview-docs","level":3,"title":"6. Build &amp; Preview Docs","text":"<pre><code># Serve docs locally with live reload\npixi run -e docs docs-serve\n\n# Build docs\npixi run -e docs docs-build\n</code></pre>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#7-submit-pr","level":3,"title":"7. Submit PR","text":"<ul> <li>Push to your fork</li> <li>Open a Pull Request</li> <li>Link any related issues</li> <li>Describe your changes</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#contribution-guidelines","level":2,"title":"Contribution Guidelines","text":"","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#code-style","level":3,"title":"Code Style","text":"<ul> <li>Follow PEP 8</li> <li>Use type hints where possible</li> <li>Add docstrings to functions/classes</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#testing","level":3,"title":"Testing","text":"<ul> <li>Add tests for new features</li> <li>Ensure all tests pass</li> <li>Aim for &gt;80% coverage</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#documentation","level":3,"title":"Documentation","text":"<ul> <li>Update docs for new features</li> <li>Add docstrings</li> <li>Include examples</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#commit-messages","level":3,"title":"Commit Messages","text":"<ul> <li>Clear, descriptive messages</li> <li>Reference issues: \"Fixes #123\"</li> <li>Use present tense: \"Add feature\" not \"Added feature\"</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#need-help","level":2,"title":"Need Help?","text":"<ul> <li>Forum: Discourse</li> <li>Chat: Discord</li> </ul>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#code-of-conduct","level":2,"title":"Code of Conduct","text":"<p>We're committed to providing a welcoming and inclusive environment. By participating, you agree to uphold the HoloViz Code of Conduct.</p>","path":["Contributing to Lumen"],"tags":[]},{"location":"contributing/#thank-you","level":2,"title":"Thank You!","text":"<p>Every contribution helps Lumen grow. Thank you for your help! üôå</p>","path":["Contributing to Lumen"],"tags":[]},{"location":"faq/","level":1,"title":"FAQ","text":"<p>Common questions about Lumen AI.</p>","path":["FAQ"],"tags":[]},{"location":"faq/#what-is-lumen-ai","level":2,"title":"What is Lumen AI?","text":"<p>Lumen is an open-source, extensible Python framework for building domain-aware, extensible AI data applications. Out-of-the-box it allows connecting to a variety of data sources, letting the user ask questions in plain English, and get SQL queries, visualizations, and analysis without writing any code.</p> <p>It uses natural language as an interface, but all work is executed through explicit, inspectable components: - SQL generated against real data sources - Deterministic Python analyses - Reproducible specifications for visualizations and layouts</p> <p>Lumen is designed to be configured and extended with your own data sources, analysis code, tools, and agents, so results reflect your domain logic rather than generic assumptions.</p>","path":["FAQ"],"tags":[]},{"location":"faq/#why-use-lumen-instead-of-chatgpt","level":2,"title":"Why use Lumen instead of ChatGPT?","text":"<p>ChatGPT is a general-purpose conversational model. It does not have access to your data, cannot execute queries, and cannot enforce domain rules or reproducibility.</p> <p>Lumen provides the missing execution layer: - Connects directly to your databases and files - Generates and runs SQL and Python, not just text - Produces inspectable query history and artifacts - Encodes domain terminology, constraints, and business logic - Works with any LLM provider, including fully local models</p> <p>ChatGPT can help you think about data. Lumen lets you work with data, using AI as an interface rather than a black box.</p>","path":["FAQ"],"tags":[]},{"location":"faq/#is-lumen-free","level":2,"title":"Is Lumen free?","text":"<p>Yes, fully open source (BSD 3-Clause). Costs:</p> <ul> <li>LLM API calls (OpenAI, Anthropic) - pay per token</li> <li>Local LLMs - free after download</li> <li>Hosting - only if deploying to cloud</li> </ul>","path":["FAQ"],"tags":[]},{"location":"faq/#can-i-use-lumen-offline","level":2,"title":"Can I use Lumen offline?","text":"<p>Yes. Install with local LLM:</p> <pre><code>pip install 'lumen[ai-llama]'\n</code></pre> <p>See LLM Providers for setup.</p>","path":["FAQ"],"tags":[]},{"location":"faq/#which-llm-providers","level":2,"title":"Which LLM providers?","text":"<ul> <li>OpenAI (GPT-4o, GPT-4o-mini)</li> <li>Anthropic (Claude 4-5 Sonnet, Haiku)</li> <li>Google Gemini</li> <li>Mistral AI</li> <li>Azure OpenAI</li> <li>Local models (Ollama, Llama.cpp)</li> </ul>","path":["FAQ"],"tags":[]},{"location":"faq/#can-i-use-my-own-llm-endpoint","level":2,"title":"Can I use my own LLM endpoint?","text":"<p>Yes:</p> <pre><code>llm = lmai.llm.OpenAI(\n    api_key='...',\n    endpoint='https://your-endpoint.com/v1'\n)\n</code></pre>","path":["FAQ"],"tags":[]},{"location":"faq/#how-do-i-load-data-from-an-in-memory-dataframe","level":2,"title":"How do I load data from an in-memory DataFrame?","text":"<pre><code>import lumen.ai as lmai\nfrom lumen.sources.duckdb import DuckDBSource\n\ndf = pd.DataFrame({\n    'revenue': [1200, 2400, 3600, 4800],\n    'churned': [0, 1, 0, 1]\n})\nsource = DuckDBSource.from_df(tables={\"data\": df})\nui = lmai.ExplorerUI(data=source)\nui.servable()\n</code></pre>","path":["FAQ"],"tags":[]},{"location":"faq/#i-launched-the-ui-but-it-only-shows-a-loading-indicator","level":2,"title":"I launched the UI, but it only shows a loading indicator?","text":"<p>Make sure to call <code>.servable()</code> on the UI object to make it available in a server context:</p> <pre><code>ui = lmai.ExplorerUI(data=source)\nui.servable()\n</code></pre>","path":["FAQ"],"tags":[]},{"location":"faq/#can-i-add-authentication","level":2,"title":"Can I add authentication?","text":"<p>Yes. Lumen supports basic auth and OAuth through Panel. See Panel's authentication docs.</p>","path":["FAQ"],"tags":[]},{"location":"installation/","level":1,"title":"Installation","text":"<p>Lumen works with Python 3.11+ on Linux, Windows, and Mac.</p> <p>Already installed?</p> <p>Jump to the Quick Start to start chatting with your data.</p>","path":["Installation"],"tags":[]},{"location":"installation/#bring-your-own-llm","level":2,"title":"Bring Your Own LLM","text":"<p>Lumen works with any LLM provider. Choose the approach that fits your needs:</p> <ul> <li>‚òÅÔ∏è Cloud providers ‚Äî OpenAI, Anthropic, Google, Mistral, Azure (easiest to get started)</li> <li>üñ•Ô∏è Locally hosted ‚Äî Ollama, Llama.cpp (free, runs on your machine, no API keys)</li> <li>üîÄ Router/Multi-provider ‚Äî LiteLLM (unified interface, 100+ models)</li> </ul>","path":["Installation"],"tags":[]},{"location":"installation/#cloud-service-providers","level":2,"title":"Cloud Service Providers","text":"<p>Use hosted LLM APIs from major providers. Fastest to set up, pay-per-use pricing.</p> OpenAIAnthropicGoogle GeminiMistralAzure OpenAIAzure Mistral AI <pre><code>pip install 'lumen[ai-openai]'\nexport OPENAI_API_KEY=sk-...\n</code></pre> <p>Get your API key:</p> <ol> <li>Visit platform.openai.com/api-keys</li> <li>Click \"Create new secret key\"</li> <li>Copy the key (starts with <code>sk-</code>)</li> <li>Set environment variable:</li> </ol> <pre><code># macOS/Linux\nexport OPENAI_API_KEY='sk-your-key-here'\n\n# Windows PowerShell\n$env:OPENAI_API_KEY='sk-your-key-here'\n\n# Windows CMD\nset OPENAI_API_KEY=sk-your-key-here\n</code></pre> <pre><code>pip install 'lumen[ai-anthropic]'\nexport ANTHROPIC_API_KEY=sk-ant-...\n</code></pre> <p>Get your API key:</p> <ol> <li>Visit console.anthropic.com/settings/keys</li> <li>Click \"Create Key\"</li> <li>Copy the key (starts with <code>sk-ant-</code>)</li> <li>Set environment variable:</li> </ol> <pre><code># macOS/Linux\nexport ANTHROPIC_API_KEY='sk-ant-your-key-here'\n\n# Windows PowerShell\n$env:ANTHROPIC_API_KEY='sk-ant-your-key-here'\n\n# Windows CMD\nset ANTHROPIC_API_KEY=sk-ant-your-key-here\n</code></pre> <pre><code>pip install 'lumen[ai-google]'\nexport GEMINI_API_KEY=your-key\n</code></pre> <p>Get your API key:</p> <ol> <li>Visit aistudio.google.com/apikey</li> <li>Click \"Create API key\"</li> <li>Choose \"Create API key in new project\" or select existing project</li> <li>Copy the key (starts with <code>AIza</code>)</li> <li>Set environment variable:</li> </ol> <pre><code># macOS/Linux\nexport GEMINI_API_KEY='your-key-here'\n\n# Windows PowerShell\n$env:GEMINI_API_KEY='your-key-here'\n\n# Windows CMD\nset GEMINI_API_KEY=your-key-here\n</code></pre> <p>Alternative: You can also use <code>GOOGLE_API_KEY</code> instead of <code>GEMINI_API_KEY</code>.</p> <pre><code>pip install 'lumen[ai-mistralai]'\nexport MISTRAL_API_KEY=your-key\n</code></pre> <p>Get your API key:</p> <ol> <li>Visit console.mistral.ai/api-keys</li> <li>Click \"Create new key\"</li> <li>Copy the key</li> <li>Set environment variable:</li> </ol> <pre><code># macOS/Linux\nexport MISTRAL_API_KEY='your-key-here'\n\n# Windows PowerShell\n$env:MISTRAL_API_KEY='your-key-here'\n\n# Windows CMD\nset MISTRAL_API_KEY=your-key-here\n</code></pre> <pre><code>pip install 'lumen[ai-openai]'\nexport AZUREAI_ENDPOINT_KEY=your-key\nexport AZUREAI_ENDPOINT_URL=https://your-resource.openai.azure.com/\n</code></pre> <p>Get your credentials:</p> <ol> <li>Visit portal.azure.com</li> <li>Navigate to your Azure OpenAI resource</li> <li>Go to \"Keys and Endpoint\"</li> <li>Copy KEY 1 or KEY 2 and your endpoint URL</li> <li>Set environment variables:</li> </ol> <pre><code># macOS/Linux\nexport AZUREAI_ENDPOINT_KEY='your-key-here'\nexport AZUREAI_ENDPOINT_URL='https://your-resource.openai.azure.com/'\n\n# Windows PowerShell\n$env:AZUREAI_ENDPOINT_KEY='your-key-here'\n$env:AZUREAI_ENDPOINT_URL='https://your-resource.openai.azure.com/'\n\n# Windows CMD\nset AZUREAI_ENDPOINT_KEY=your-key-here\nset AZUREAI_ENDPOINT_URL=https://your-resource.openai.azure.com/\n</code></pre> <pre><code>pip install 'lumen[ai-mistralai]'\nexport AZUREAI_ENDPOINT_KEY=your-key\nexport AZUREAI_ENDPOINT_URL=https://your-resource-endpoint.com/\n</code></pre> <p>Get your credentials:</p> <ol> <li>Visit portal.azure.com</li> <li>Navigate to your Azure AI resource with Mistral deployment</li> <li>Go to \"Keys and Endpoint\"</li> <li>Copy KEY 1 or KEY 2 and your endpoint URL</li> <li>Set environment variables (same as Azure OpenAI above)</li> </ol>","path":["Installation"],"tags":[]},{"location":"installation/#locally-hosted","level":2,"title":"Locally Hosted","text":"<p>Run open-source LLMs on your own machine. No API keys required, full privacy, free to use.</p> OllamaLlama.cppAI Navigator <pre><code>pip install 'lumen[ai-ollama]'\n</code></pre> <p>Setup Ollama:</p> <ol> <li>Install Ollama from ollama.com</li> <li>Start the Ollama service (usually starts automatically)</li> <li>Pull a model:</li> </ol> <pre><code>ollama pull qwen3:32b\n</code></pre> <ol> <li>(Optional) Set custom endpoint if not using default:</li> </ol> <pre><code>export OLLAMA_BASE_URL=http://localhost:11434\n</code></pre> <p>No additional environment variables needed! Ollama works out of the box.</p> <pre><code>pip install 'lumen[ai-llama]'\n</code></pre> <p>No setup required! The first time you use Llama.cpp, Lumen will automatically download the model you specify. No environment variables needed.</p> <p>Optional: Set a custom model URL:</p> <pre><code>lumen-ai serve data.csv --provider llama-cpp \\\n  --llm-model-url 'https://huggingface.co/unsloth/Qwen2.5-7B-Instruct-GGUF/blob/main/Qwen2.5-7B-Instruct-Q4_K_M.gguf'\n</code></pre> <pre><code>pip install 'lumen[ai-openai]'\n</code></pre> <p>Anaconda AI Navigator runs models locally on your machine. No API key needed!</p> <p>Default endpoint: <code>http://localhost:8080/v1</code></p> <p>Optional: Set custom endpoint:</p> <pre><code>export OPENAI_BASE_URL=http://localhost:8080/v1\n</code></pre>","path":["Installation"],"tags":[]},{"location":"installation/#router-multi-provider","level":2,"title":"Router / Multi-Provider","text":"<p>Use a unified interface to access multiple LLM providers and models.</p> LiteLLMAWS Bedrock <pre><code>pip install 'lumen[ai-litellm]'\n</code></pre> <p>Supports 100+ models across OpenAI, Anthropic, Google, Mistral, and more.</p> <p>Set environment variables for providers you want to use:</p> OpenAIAnthropicGoogleAzureAWS Bedrock <pre><code>export OPENAI_API_KEY='sk-...'\n</code></pre> <pre><code>export ANTHROPIC_API_KEY='sk-ant-...'\n</code></pre> <pre><code>export GEMINI_API_KEY='...'\n</code></pre> <pre><code>export AZUREAI_ENDPOINT_KEY='...'\nexport AZUREAI_ENDPOINT_URL='https://...'\n</code></pre> aws-sso-util (Easiest)AWS CLIAccess Keys <pre><code>pip install aws-sso-util\naws-sso-util login --profile your-profile\n# Credentials auto-exported!\n</code></pre> <pre><code>aws sso login --profile your-profile\nexport AWS_PROFILE=your-profile\nexport AWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code>export AWS_ACCESS_KEY_ID='...'\nexport AWS_SECRET_ACCESS_KEY='...'\nexport AWS_DEFAULT_REGION='us-east-1'\n</code></pre> <p>Then use any supported model:</p> <pre><code>import lumen.ai as lmai\n\nllm = lmai.llm.LiteLLM(\n    model_kwargs={\n        \"default\": {\"model\": \"gpt-4.1-mini\"},                    # OpenAI\n        \"edit\": {\"model\": \"anthropic/claude-sonnet-4-5\"},        # Anthropic\n        \"sql\": {\"model\": \"gemini/gemini-2.5-flash\"}             # Google\n    }\n)\nui = lmai.ExplorerUI(data='data.csv', llm=llm)\nui.servable()\n</code></pre> <p>AWS Bedrock is a managed gateway that provides access to foundation models from Anthropic, Meta, Mistral, Amazon, Cohere, and AI21 through a unified API.</p> <pre><code>pip install 'lumen[ai-anthropic]'  # For AnthropicBedrock\n# OR\npip install boto3  # For Bedrock\n</code></pre> <p>Authentication:</p> aws-sso-util (Easiest)AWS CLIAccess Keys <pre><code>pip install aws-sso-util\naws-sso-util login --profile your-profile\n# Credentials auto-exported!\n</code></pre> <pre><code>aws sso login --profile your-profile\nexport AWS_PROFILE=your-profile\nexport AWS_DEFAULT_REGION=us-east-1\n</code></pre> <pre><code>export AWS_ACCESS_KEY_ID='...'\nexport AWS_SECRET_ACCESS_KEY='...'\nexport AWS_DEFAULT_REGION='us-east-1'\n</code></pre> <p>Choose your Lumen provider:</p> AnthropicBedrockBedrock <p>Optimized for Claude models using Anthropic's SDK.</p> <pre><code>import lumen.ai as lmai\n\nllm = lmai.llm.AnthropicBedrock()\nui = lmai.ExplorerUI(data='data.csv', llm=llm)\nui.servable()\n</code></pre> <p>Universal access to all Bedrock models using boto3.</p> <pre><code>import lumen.ai as lmai\n\nllm = lmai.llm.Bedrock(\n    model_kwargs={\n        \"default\": {\"model\": \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\"},\n    }\n)\nui = lmai.ExplorerUI(data='data.csv', llm=llm)\nui.servable()\n</code></pre> <p>Available models:</p> <ul> <li>Anthropic (Claude), Meta (Llama), Mistral, Amazon (Titan), Cohere, AI21</li> <li>Model IDs: <code>us.anthropic.claude-*</code>, <code>meta.llama3-*</code>, <code>mistral.*</code>, <code>amazon.titan-*</code></li> <li>Full model list</li> </ul> <p>IAM Permissions:</p> <pre><code>{\n  \"Effect\": \"Allow\",\n  \"Action\": [\"bedrock:InvokeModel\", \"bedrock:InvokeModelWithResponseStream\"],\n  \"Resource\": \"*\"\n}\n</code></pre>","path":["Installation"],"tags":[]},{"location":"installation/#making-environment-variables-persistent","level":2,"title":"Making Environment Variables Persistent","text":"<p>Set variables permanently so you don't have to export them every session:</p> macOS/Linux (Bash)macOS (Zsh)Windows (Permanent) <p>Add to <code>~/.bashrc</code> or <code>~/.bash_profile</code>:</p> <pre><code>echo 'export OPENAI_API_KEY=\"sk-your-key-here\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>Add to <code>~/.zshrc</code>:</p> <pre><code>echo 'export OPENAI_API_KEY=\"sk-your-key-here\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre> <ol> <li>Search for \"Environment Variables\" in Start Menu</li> <li>Click \"Edit the system environment variables\"</li> <li>Click \"Environment Variables\"</li> <li>Under \"User variables\", click \"New\"</li> <li>Add variable name (e.g., <code>OPENAI_API_KEY</code>) and value</li> <li>Click OK</li> <li>Restart your terminal</li> </ol>","path":["Installation"],"tags":[]},{"location":"installation/#verify-installation","level":2,"title":"Verify Installation","text":"<pre><code>lumen-ai --version\n</code></pre> <p>Test your LLM connection:</p> <pre><code># Test script\nimport lumen.ai as lmai\n\nllm = lmai.llm.OpenAI()  # or Anthropic(), Google(), etc.\nui = lmai.ExplorerUI(data='test.csv')\nui.servable()\n</code></pre>","path":["Installation"],"tags":[]},{"location":"installation/#next-steps","level":2,"title":"Next Steps","text":"<p>Ready to start? Head to the Quick Start guide to chat with your first dataset.</p>","path":["Installation"],"tags":[]},{"location":"installation/#missing-your-favorite-llm","level":2,"title":"Missing Your Favorite LLM?","text":"<p>Missing your favorite LLM? Let us know by submitting a GitHub issue!</p>","path":["Installation"],"tags":[]},{"location":"quick_start/","level":1,"title":"Quick Start","text":"<p>Get up and running with Lumen in under 30 seconds.</p>","path":["Quick Start"],"tags":[]},{"location":"quick_start/#installation","level":2,"title":"Installation","text":"<p>Other LLM Providers</p> <p>For Anthropic, Google Gemini, Mistral, AWS Bedrock, LlamaCpp, and more, see the Installation guide.</p> <pre><code>pip install 'lumen[ai-openai]'\n\nexport OPENAI_API_KEY=sk-...\n</code></pre>","path":["Quick Start"],"tags":[]},{"location":"quick_start/#start-chatting-with-data","level":2,"title":"Start Chatting with Data","text":"Command LinePython <pre><code>lumen-ai serve https://datasets.holoviz.org/penguins/v1/penguins.csv --show\n</code></pre> <pre><code>from lumen.ai import ExplorerUI\n\nui = ExplorerUI(\n    data='https://datasets.holoviz.org/penguins/v1/penguins.csv'\n)\nui.servable()\n</code></pre> <pre><code>panel serve app.py --show\n</code></pre> <p>If a browser tab doesn't automatically open, visit https://localhost:5006 and start chatting with your data.</p> <p>Try these questions:</p> <ul> <li> <p>What datasets are available?</p> </li> <li> <p>Show me a summary of the data</p> </li> <li> <p>Which species has the largest average body mass? Show as a bar chart.</p> </li> <li> <p>Create a scatter plot of bill length vs flipper length, colored by island</p> </li> <li> <p>Filter for penguins over 4kg and show me the distribution by species</p> </li> </ul> <p></p>","path":["Quick Start"],"tags":[]},{"location":"quick_start/#how-it-works","level":2,"title":"How It Works","text":"<p>You don't need to write SQL or Python; just write your request:</p> <p>Which islands have the most penguins? Plot as a horizontal bar chart.</p> <p></p> <p>1. Lumen creates a plan:</p> <ul> <li>üü¢ Query the dataset to find the total number of penguins per island by grouping and summing the penguin counts for each island. Provide the resulting table with island names and penguin counts.</li> <li>üü¢ Create a horizontal bar chart to visualize the number of penguins per island using the table data provided by the previous step. The x-axis should represent the number of penguins and the y-axis the island names.</li> <li>üü¢ Validate whether the executed plan fully answered the user's original query.</li> </ul> <p>2. Generates SQL to query the data:</p> <pre><code>SELECT \"island\", COUNT(*) AS \"penguin_count\" \nFROM penguins \nGROUP BY \"island\" \nORDER BY \"penguin_count\" DESC\n</code></pre> island penguin_count Biscoe 168 Dream 124 Torgersen 52 <p>3. Creates a Vega-Lite visualization:</p> <pre><code>$schema: https://vega.github.io/schema/vega-lite/v5.json\ndata:\n  name: penguin_count_by_island\nheight: container\nlayer:\n- encoding:\n    color:\n      value: '#4682b4'\n    x:\n      axis:\n        title: Penguin Count\n      field: penguin_count\n      type: quantitative\n    y:\n      axis:\n        title: Island\n      field: island\n      sort: -x\n      type: nominal\n  mark: bar\ntitle:\n  anchor: start\n  fontSize: 20\n  subtitle: Biscoe island has the highest penguin count, followed by Dream and Torgersen\n  subtitleColor: '#666666'\n  subtitleFontSize: 16\n  text: Penguin Counts by Island\nwidth: container\n</code></pre> <p>4. Renders the result:</p> <p>All of this happens automatically when you just ask a question.</p>","path":["Quick Start"],"tags":[]},{"location":"quick_start/#your-work-is-saved-automatically","level":2,"title":"Your Work is Saved Automatically","text":"<p>Behind the scenes, Lumen organizes your work into Explorations ‚Äî think of them as saved workspaces for each dataset or analysis thread.</p> <p>When you ask your first question that queries data, Lumen creates an exploration to capture everything:</p> <ul> <li>Your conversation history</li> <li>The SQL queries generated</li> <li>Charts and visualizations</li> <li>Results and data tables</li> </ul> <p>Follow-up questions stay together: Ask \"Can you make that chart show only the top 5?\" and your new chart appears in the same exploration.</p> <p>New topics create new explorations: Ask about a different dataset or unrelated question, and Lumen starts a fresh exploration.</p> <p>This means you can:</p> <ul> <li>Return to any analysis later</li> <li>Export your work as a Jupyter notebook</li> <li>Keep multiple investigations organized</li> <li>Build on previous results without losing context</li> </ul>","path":["Quick Start"],"tags":[]},{"location":"quick_start/#try-with-your-own-data","level":2,"title":"Try with Your Own Data","text":"CSV FilesDatabases <pre><code>lumen serve data/sales.csv\nlumen serve https://example.com/data.csv\n</code></pre> <pre><code>lumen serve postgresql://user:pass@localhost/mydb\nlumen serve mysql://user:pass@localhost/mydb\nlumen serve sqlite:///data.db\n</code></pre>","path":["Quick Start"],"tags":[]},{"location":"quick_start/#next-steps","level":2,"title":"Next Steps","text":"<ul> <li>Navigating the UI - Learn the chat interface</li> <li>Using Lumen AI - Master natural language queries</li> <li>Examples - Step-by-step tutorials</li> <li>Configure LLM Providers - Customize your AI model</li> </ul>","path":["Quick Start"],"tags":[]},{"location":"configuration/agents/","level":1,"title":"Agents","text":"<p>Agents are specialized workers that answer different types of questions.</p> <p>SQLAgent writes queries. VegaLiteAgent creates charts. ChatAgent answers questions. Each agent has a specific job.</p> <p>Most users never customize agents. The eight default agents handle typical data exploration needs.</p> <p>See also: Using Lumen AI ‚Äî Guide to asking effective questions and exploring data.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#skip-to","level":2,"title":"Skip to","text":"<ul> <li>See which agents exist - What each agent does</li> <li>Add custom agents - Extend Lumen with new capabilities  </li> <li>Remove agents - Use only some agents</li> <li>Configure agent models - Control which LLM each agent uses</li> </ul>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#default-agents","level":2,"title":"Default agents","text":"<p>Lumen includes eight agents automatically. You don't need to configure anything.</p> Agent What it does SQLAgent Writes and runs SQL queries VegaLiteAgent Creates charts and visualizations DeckGLAgent Creates 3D map visualizations for geographic data ChatAgent Answers questions and provides guidance TableListAgent Lists available tables and columns DocumentListAgent Manages uploaded documents ValidationAgent Checks if results answer the question <p>These agents work together automatically. The coordinator picks which agents to use for each question.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#use-specific-agents-only","level":2,"title":"Use specific agents only","text":"<p>Include only the agents you need:</p> Limit to specific agents<pre><code>import lumen.ai as lmai\nfrom lumen.ai.agents import ChatAgent, SQLAgent, VegaLiteAgent, DeckGLAgent\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    default_agents=[ChatAgent, SQLAgent, VegaLiteAgent, DeckGLAgent]\n)\nui.servable()\n</code></pre> <p>Why limit agents?</p> <ul> <li>Faster planning (fewer options to consider)</li> <li>Lower costs (fewer agents = fewer LLM calls during planning)</li> <li>Simpler behavior (predictable agent selection)</li> </ul> <p>Most users should keep all default agents. Only customize if you have specific needs.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#add-a-custom-agent","level":2,"title":"Add a custom agent","text":"<p>Add your own agent for specialized tasks:</p> Minimal custom agent<pre><code>import lumen.ai as lmai\nfrom lumen.ai.context import ContextModel\nfrom pydantic import Field\n\nclass MyInputs(ContextModel):\n    data: dict = Field(description=\"The data to process\")\n\nclass MyOutputs(ContextModel):\n    summary: str = Field(description=\"Summary result\")\n\nclass SummaryAgent(lmai.agents.Agent):\n    purpose = \"Creates executive summaries of data\"\n\n    input_schema = MyInputs\n    output_schema = MyOutputs\n\n    async def respond(self, messages, context, **kwargs):\n        # Your logic here\n        return [outputs], context\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    agents=[SummaryAgent()]  # (1)!\n)\nui.servable()\n</code></pre> <ol> <li>Adds your agent alongside the default agents</li> </ol> <p>See Creating custom agents below for complete examples.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#use-different-models-per-agent","level":2,"title":"Use different models per agent","text":"<p>Configure which LLM model each agent uses:</p> Different models per agent<pre><code>import lumen.ai as lmai\n\nmodel_config = {\n    \"default\": {\"model\": \"gpt-4o-mini\"},  # Cheap model for most agents\n    \"sql\": {\"model\": \"gpt-4o\"},           # Powerful model for SQL\n    \"vega_lite\": {\"model\": \"gpt-4o\"},     # Powerful model for charts\n    \"deck_gl\": {\"model\": \"gpt-4o\"},       # Powerful model for 3D maps\n    \"chat\": {\"model\": \"gpt-4o\"},          # Powerful model for analysis\n}\n\nllm = lmai.llm.OpenAI(model_kwargs=model_config)\n\nui = lmai.ExplorerUI(data='penguins.csv', llm=llm)\nui.servable()\n</code></pre> <p>Model types match agent names:</p> <ul> <li>SQLAgent uses the <code>\"sql\"</code> model</li> <li>VegaLiteAgent uses the <code>\"vega_lite\"</code> model</li> <li>DeckGLAgent uses the <code>\"deck_gl\"</code> model</li> <li>ChatAgent uses the <code>\"chat\"</code> model (falls back to <code>\"default\"</code> if not specified)</li> </ul> <p>Agent class names are converted to model keys automatically (e.g., <code>SQLAgent</code> ‚Üí <code>\"sql\"</code>, <code>VegaLiteAgent</code> ‚Üí <code>\"vega_lite\"</code>, <code>DeckGLAgent</code> ‚Üí <code>\"deck_gl\"</code>).</p> <p>See LLM Providers for complete details.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#creating-custom-agents","level":2,"title":"Creating custom agents","text":"<p>Custom agents let you add specialized capabilities to Lumen.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#when-to-create-a-custom-agent","level":3,"title":"When to create a custom agent","text":"<p>Create a custom agent when:</p> <ul> <li>You need domain-specific analysis (financial metrics, scientific calculations)</li> <li>You want to integrate external APIs or services</li> <li>You need specialized data transformations</li> <li>Built-in agents don't match your workflow</li> </ul> <p>Don't create a custom agent when:</p> <ul> <li>You can solve it with custom analyses (simpler approach)</li> <li>You can use tools instead (tools don't require async/await)</li> <li>A built-in agent already handles it</li> </ul>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#basic-custom-agent-structure","level":3,"title":"Basic custom agent structure","text":"Custom agent structure<pre><code>import lumen.ai as lmai\nfrom lumen.ai.context import ContextModel\nfrom pydantic import Field\n\n# Define what the agent needs\nclass MyInputs(ContextModel):\n    pipeline: object = Field(description=\"Data pipeline to process\")\n\n# Define what the agent provides\nclass MyOutputs(ContextModel):\n    summary: str = Field(description=\"Summary of findings\")\n\nclass MyAgent(lmai.agents.Agent):\n    purpose = \"Summarizes data in executive format\"\n\n    input_schema = MyInputs  # (1)!\n    output_schema = MyOutputs  # (2)!\n\n    prompts = {\n        \"main\": {\n            \"template\": \"Summarize this data: {{ memory['data'] }}\"\n        }\n    }\n\n    async def respond(self, messages, context, **kwargs):\n        # Render prompt\n        system = await self._render_prompt(\"main\", messages, context)\n\n        # Get LLM response\n        response = await self.llm.invoke(messages, system=system)\n\n        # Return outputs and updated context\n        return [response], {\"summary\": str(response)}\n</code></pre> <ol> <li>Agent requires <code>pipeline</code> in context to run</li> <li>Agent adds <code>summary</code> to context after running</li> </ol>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#complete-working-example","level":3,"title":"Complete working example","text":"<p>This agent calculates statistical metrics:</p> Statistics agent<pre><code>import lumen.ai as lmai\nfrom lumen.ai.context import ContextModel\nfrom pydantic import Field\nimport pandas as pd\n\nclass StatsInputs(ContextModel):\n    pipeline: object = Field(description=\"Data pipeline\")\n\nclass StatsOutputs(ContextModel):\n    statistics: str = Field(description=\"Statistical summary\")\n\nclass StatisticsAgent(lmai.agents.Agent):\n    purpose = \"Calculates descriptive statistics for numerical columns\"\n\n    input_schema = StatsInputs\n    output_schema = StatsOutputs\n\n    prompts = {\n        \"main\": {\n            \"template\": \"\"\"\nAnalyze these statistics and explain key findings:\n\n{{ stats }}\n\nFocus on:\n\n- Notable values (very high/low)\n- Spread and variability  \n- Potential outliers\n\"\"\"\n        }\n    }\n\n    async def respond(self, messages, context, **kwargs):\n        # Get data\n        pipeline = context['pipeline']\n        df = pipeline.data\n\n        # Calculate stats\n        stats = df.describe().to_string()\n\n        # Get LLM interpretation\n        system = await self._render_prompt(\"main\", messages, context, stats=stats)\n        interpretation = await self.llm.invoke(messages, system=system)\n\n        # Return results\n        return [interpretation], {\"statistics\": str(interpretation)}\n\n# Use the agent\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    agents=[StatisticsAgent()]\n)\nui.servable()\n</code></pre> <p>Now you can ask \"What are the statistics for this dataset?\" and the agent will run.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#agent-components-explained","level":3,"title":"Agent components explained","text":"<p><code>purpose</code> - One-sentence description of what the agent does. The coordinator uses this to decide when to invoke the agent.</p> <p><code>input_schema</code> - TypedDict defining what data the agent needs from context. The agent can only run when these requirements are met.</p> <p><code>output_schema</code> - TypedDict defining what data the agent adds to context. Other agents can use these outputs.</p> <p><code>prompts</code> - Dictionary of prompt templates. Most agents only need a \"main\" prompt. See Prompts guide for customization options.</p> <p><code>respond()</code> - The async method that does the work. Must return <code>(outputs_list, updated_context_dict)</code>.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#control-when-agents-are-used","level":3,"title":"Control when agents are used","text":"<p>Use <code>conditions</code> to specify when the agent should run:</p> Agent with conditions<pre><code>import param\n\nclass ReportAgent(lmai.agents.Agent):\n    purpose = \"Creates PDF reports\"\n\n    conditions = param.List(default=[\n        \"Use when user explicitly asks for a report or PDF\",\n        \"Use after data analysis is complete\",\n        \"NOT for simple questions or queries\"\n    ])\n\n    input_schema = MyInputs\n    output_schema = MyOutputs\n</code></pre> <p>The coordinator reads these conditions when deciding which agent to use.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#prevent-agent-conflicts","level":3,"title":"Prevent agent conflicts","text":"<p>Use <code>not_with</code> to prevent agents from being used together:</p> Prevent conflicting agents<pre><code>class FastSummaryAgent(lmai.agents.Agent):\n    purpose = \"Quick data summaries\"\n\n    not_with = param.List(default=[\"DetailedAnalysisAgent\"])\n</code></pre>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#common-patterns","level":3,"title":"Common patterns","text":"API IntegrationFile ProcessingExternal Library Call external APIs<pre><code>import httpx\n\nclass WeatherAgent(lmai.agents.Agent):\n    purpose = \"Fetches current weather data\"\n\n    async def respond(self, messages, context, **kwargs):\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\"https://api.weather.gov/...\")\n            weather_data = response.json()\n\n        summary = f\"Current temperature: {weather_data['temp']}¬∞F\"\n        return [summary], {\"weather\": summary}\n</code></pre> Extract PDF text<pre><code>class PDFAgent(lmai.agents.Agent):\n    purpose = \"Extracts text from PDF documents\"\n\n    async def respond(self, messages, context, **kwargs):\n        documents = context.get('documents', [])\n\n        extracted_text = []\n        for doc in documents:\n            if doc['type'] == 'pdf':\n                text = extract_pdf_text(doc['content'])\n                extracted_text.append(text)\n\n        return [extracted_text], {\"pdf_text\": extracted_text}\n</code></pre> Data quality checks<pre><code>import great_expectations as gx\n\nclass DataQualityAgent(lmai.agents.Agent):\n    purpose = \"Checks data quality using Great Expectations\"\n\n    async def respond(self, messages, context, **kwargs):\n        df = context['pipeline'].data\n\n        # Run validations\n        results = run_quality_checks(df)\n\n        # Summarize findings\n        system = await self._render_prompt(\n            \"main\", messages, context, results=results\n        )\n        summary = await self.llm.invoke(messages, system=system)\n\n        return [summary], {\"quality_report\": str(summary)}\n</code></pre>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#common-issues","level":2,"title":"Common issues","text":"","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#agent-has-unmet-requirements","level":3,"title":"\"Agent has unmet requirements\"","text":"<p>The agent's <code>input_schema</code> requires data that doesn't exist in context.</p> <p>How to fix:</p> Make fields optional<pre><code>from typing import NotRequired\n\nclass MyInputs(ContextModel):\n    pipeline: object  # Required\n    analysis: NotRequired[str]  # Optional\n</code></pre> <p>Or ensure another agent provides the required data first.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#agent-never-gets-invoked","level":3,"title":"Agent never gets invoked","text":"<p>The coordinator doesn't think the agent is relevant.</p> <p>How to fix:</p> <ol> <li>Make the <code>purpose</code> more specific and clear</li> <li>Add <code>conditions</code> that describe when to use it</li> <li>Check that <code>input_schema</code> requirements can be satisfied</li> <li>Enable <code>log_level='DEBUG'</code> in the UI to see coordinator decisions</li> </ol>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#agent-fails-with-keyerror","level":3,"title":"Agent fails with \"KeyError\"","text":"<p>The agent tried to access context data that doesn't exist.</p> <p>Always check before accessing context</p> <pre><code># Bad - assumes 'data' exists\ndata = context['data']  # ‚ùå KeyError if missing\n\n# Good - checks first\ndata = context.get('data')  # ‚úÖ Returns None if missing\nif data is None:\n    return [{\"error\": \"No data available\"}], context\n</code></pre>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/agents/#best-practices","level":2,"title":"Best practices","text":"<p>Keep agents focused. One agent should do one thing well. Don't create a \"do everything\" agent.</p> <p>Write clear purposes. The coordinator uses <code>purpose</code> to decide when to invoke agents. Make it specific and actionable.</p> <p>Test with real queries. Different LLM models behave differently. Test your agent with your actual LLM.</p> <p>Handle missing data gracefully. Always check for required data before using it. Provide helpful error messages.</p> <p>Use tools for simple functions. If your agent doesn't need async/await or complex prompting, use a tool instead.</p> <p>Don't duplicate built-ins. Check if a built-in agent already does what you need before creating a custom one.</p>","path":["Configuration","Agents"],"tags":[]},{"location":"configuration/analyses/","level":1,"title":"Analyses","text":"<p>Analyses are functions that run deterministically with code instead of LLM generation.</p> <p>Like tools or hooks, analyses give you control over specific calculations. Use them when you need reliable, repeatable results‚Äîfinancial metrics, scientific formulas, or statistical tests that must be calculated exactly the same way every time.</p> <p>Difference from Views: Views are interactive visualizations that display data. Analyses are computational functions that calculate new insights from data. You can think of views as \"how it looks\" and analyses as \"what it means.\"</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#quick-example","level":2,"title":"Quick example","text":"Summary statistics analysis<pre><code>import lumen.ai as lmai\nimport pandas as pd\nimport panel as pn\n\nclass SummaryStats(lmai.Analysis):\n    \"\"\"Calculate summary statistics.\"\"\"\n\n    columns = [\"value\"]  # (1)!\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data\n        stats = df.describe()\n        return pn.widgets.Tabulator(stats)\n\n# Pass analyses directly to ExplorerUI\nui = lmai.ExplorerUI(\n    data='data.csv',\n    analyses=[SummaryStats]\n)\nui.servable()\n</code></pre> <ol> <li>Analysis only runs when data has a \"value\" column</li> </ol> <p>When the data has a \"value\" column, a suggestion button appears for the analysis. Users can click it or ask \"Show me summary statistics\" to run it.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#when-to-use-analyses","level":2,"title":"When to use analyses","text":"<p>Use analyses for:</p> <ul> <li>Domain-specific calculations (wind speed from components, ROI formulas)</li> <li>Statistical tests (t-tests, ANOVA, correlation)</li> <li>Custom visualizations (domain-specific charts)</li> <li>Repeated calculations across datasets</li> </ul> <p>Don't use analyses for:</p> <ul> <li>One-off queries (just ask in chat)</li> <li>Simple aggregations (SQL handles these)</li> <li>Generic operations (built-in agents cover common tasks)</li> </ul>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#basic-structure","level":2,"title":"Basic structure","text":"Analysis structure<pre><code>import param\nimport lumen.ai as lmai\n\nclass MyAnalysis(lmai.Analysis):\n    \"\"\"What this analysis does.\"\"\"\n\n    autorun = param.Boolean(default=True)  # (1)!\n\n    columns = param.List(default=[\"col1\", \"col2\"])  # (2)!\n\n    def __call__(self, pipeline, *args, **kwargs):\n        # Your calculation logic\n        df = pipeline.data\n        result = df[\"col1\"] * df[\"col2\"]\n\n        # Return any Panel viewable\n        return result.hvplot(kind=\"line\")\n</code></pre> <ol> <li>Whether to run automatically when conditions are met</li> <li>Required columns - analysis only applies when these exist</li> </ol>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#complete-example-wind-analysis","level":2,"title":"Complete example: Wind analysis","text":"Wind pattern analysis<pre><code>import numpy as np\nimport pandas as pd\nimport param\nimport panel as pn\nimport lumen.ai as lmai\nfrom lumen.transforms import Transform\nimport hvplot.pandas\n\nclass WindSpeedDirection(Transform):\n    \"\"\"Calculate wind speed and direction from u,v components.\"\"\"\n\n    u_component = param.String(default=\"u\")\n    v_component = param.String(default=\"v\")\n\n    def apply(self, df):\n        df[\"wind_speed\"] = np.sqrt(\n            df[self.u_component]**2 + df[self.v_component]**2\n        )  # (1)!\n        df[\"wind_direction\"] = np.degrees(\n            np.arctan2(df[self.v_component], df[self.u_component])\n        )\n        df[\"wind_direction\"] = (df[\"wind_direction\"] + 360) % 360\n        return df\n\nclass WindAnalysis(lmai.Analysis):\n    \"\"\"Analyze wind patterns from u,v components.\"\"\"\n\n    autorun = param.Boolean(default=True)\n\n    columns = param.List(default=[\"time\", \"u\", \"v\"])  # (2)!\n\n    def __call__(self, pipeline, *args, **kwargs):\n        # Apply calculation\n        wind_pipeline = pipeline.chain(transforms=[WindSpeedDirection()])\n\n        # Create visualizations\n        speed_plot = wind_pipeline.data.hvplot(\n            x=\"time\", y=\"wind_speed\", title=\"Wind Speed\"\n        )\n        direction_plot = wind_pipeline.data.hvplot(\n            x=\"time\", y=\"wind_direction\", kind=\"scatter\", title=\"Wind Direction\"\n        )\n\n        # Return combined view\n        return pn.Column(speed_plot, direction_plot)\n\n# Pass analyses directly to ExplorerUI\nui = lmai.ExplorerUI(\n    data='weather.csv',\n    analyses=[WindAnalysis]\n)\nui.servable()\n</code></pre> <ol> <li>Deterministic calculation - same inputs always give same outputs</li> <li>Only runs when data has time, u, and v columns</li> </ol> <p>Now users can ask \"Analyze wind patterns\" and get both charts automatically.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#real-world-example-weather-data-explorer","level":2,"title":"Real-world example: Weather data explorer","text":"<p>For a complete real-world example, see the Weather Data AI Explorer tutorial. It demonstrates:</p> <ul> <li>Building a <code>SkewTAnalysis</code> class that creates atmospheric Skew-T diagrams</li> <li>Using template overrides to add meteorological domain knowledge</li> <li>Combining analyses with custom agents for specialized applications</li> <li>Creating configurable parameters for analysis customization</li> </ul> <p>The tutorial walks through building a domain-specific data exploration application from start to finish.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#control-when-analyses-run","level":2,"title":"Control when analyses run","text":"Manual trigger only<pre><code>class ExpensiveAnalysis(lmai.Analysis):\n    \"\"\"Complex calculation.\"\"\"\n\n    columns = param.List(default=[\"data\"])\n    autorun = param.Boolean(default=False)  # (1)!\n\n    def __call__(self, pipeline, *args, **kwargs):\n        # Expensive computation\n        return result\n</code></pre> <ol> <li>Only runs when user explicitly requests it</li> </ol> <p>Set <code>autorun = False</code> for analyses that take a long time or should only run on explicit request.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#add-configurable-parameters","level":2,"title":"Add configurable parameters","text":"Analysis with parameters<pre><code>import param\n\nclass ThresholdAnalysis(lmai.Analysis):\n    \"\"\"Filter data by threshold.\"\"\"\n\n    columns = param.List(default=[\"value\"])\n    threshold = param.Number(default=50)  # (1)!\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data\n        filtered = df[df[\"value\"] &gt; self.threshold]\n\n        return filtered.hvplot(y=\"value\", kind=\"hist\")\n</code></pre> <ol> <li>User can adjust the threshold value through UI controls</li> </ol>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#configuring-parameter-defaults","level":3,"title":"Configuring parameter defaults","text":"<p>To use different default parameter values, call .instance and override the defaults:</p> Configuring defaults via subclass<pre><code># Base analysis with default threshold of 50\nclass ThresholdAnalysis(lmai.Analysis):\n    columns = param.List(default=[\"value\"])\n    threshold = param.Number(default=50)\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data\n        return df[df[\"value\"] &gt; self.threshold].hvplot(y=\"value\", kind=\"hist\")\n\nui = lmai.ExplorerUI(\n    data='data.csv',\n    analyses=[HighThresholdAnalysis.instance(threshold=100)]\n)\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#multiple-analyses","level":2,"title":"Multiple analyses","text":"Multiple analyses<pre><code>ui = lmai.ExplorerUI(\n    data='data.csv',\n    analyses=[\n        WindAnalysis,\n        TemperatureAnalysis,\n        PressureAnalysis,\n    ]\n)\nui.servable()\n</code></pre> <p>Lumen automatically picks the right analysis based on available columns and the user's question.</p> <p>Pass classes, not instances</p> <p>Always pass analysis classes to the <code>analyses</code> parameter, not instances:</p> <pre><code># ‚úÖ Correct - pass the class\nanalyses=[WindAnalysis]\n\n# ‚ùå Wrong - don't instantiate\nanalyses=[WindAnalysis()]  # This will error!\n</code></pre> <p>Analysis is a <code>ParameterizedFunction</code>, so calling <code>WindAnalysis()</code> invokes <code>__call__</code> instead of creating an instance.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#common-patterns","level":2,"title":"Common patterns","text":"Statistical AnalysisFinancial CalculationsData Quality Correlation analysis<pre><code>class CorrelationAnalysis(lmai.Analysis):\n    \"\"\"Show correlation between variables.\"\"\"\n\n    columns = param.List(default=[\"x\", \"y\"])\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data\n        correlation = df[\"x\"].corr(df[\"y\"])\n\n        plot = df.hvplot.scatter(\n            x=\"x\", y=\"y\",\n            title=f\"Correlation: {correlation:.2f}\"\n        )\n        return plot\n</code></pre> ROI analysis<pre><code>class ROIAnalysis(lmai.Analysis):\n    \"\"\"Calculate return on investment.\"\"\"\n\n    columns = param.List(default=[\"revenue\", \"cost\"])\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data.copy()\n        df[\"roi\"] = ((df[\"revenue\"] - df[\"cost\"]) / df[\"cost\"]) * 100\n\n        return df.hvplot.hist(y=\"roi\", title=\"ROI Distribution\")\n</code></pre> Quality check<pre><code>import pandas as pd\nimport panel as pn\n\nclass QualityCheck(lmai.Analysis):\n    \"\"\"Check for missing and duplicate data.\"\"\"\n\n    columns = param.List(default=[])  # Works with any columns\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data\n\n        report = pd.DataFrame([{\n            \"total_rows\": len(df),\n            \"missing_values\": df.isnull().sum().sum(),\n            \"duplicates\": df.duplicated().sum(),\n        }])\n\n        return pn.widgets.Tabulator(report)\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#return-types","level":2,"title":"Return types","text":"<p>Analyses can return any Panel viewable:</p> Different return types<pre><code>def __call__(self, pipeline, *args, **kwargs):\n    df = pipeline.data\n\n    # HoloViews/hvPlot charts\n    return df.hvplot(x=\"time\", y=\"value\")\n\n    # Panel widgets\n    return pn.widgets.Tabulator(df)\n\n    # Matplotlib figures\n    fig, ax = plt.subplots()\n    ax.plot(df[\"x\"], df[\"y\"])\n    return pn.pane.Matplotlib(fig)\n\n    # Multiple components\n    return pn.Column(chart, table, summary)\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#troubleshooting","level":2,"title":"Troubleshooting","text":"","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#analysis-never-runs","level":3,"title":"Analysis never runs","text":"<p>Check that required columns exist in your data with exact names (case-sensitive).</p> Debug available columns<pre><code>def __call__(self, pipeline, *args, **kwargs):\n    print(\"Available columns:\", pipeline.data.columns.tolist())\n    # Your logic\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#analysis-fails-silently","level":3,"title":"Analysis fails silently","text":"<p>Add error handling:</p> Error handling in analysis<pre><code>def __call__(self, pipeline, *args, **kwargs):\n    try:\n        df = pipeline.data\n        # Your logic\n        return result\n    except Exception as e:\n        return pn.pane.Alert(f\"Analysis failed: {e}\", alert_type=\"danger\")\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#wrong-columns","level":3,"title":"Wrong columns","text":"<p>Column names are case-sensitive. Check your data:</p> <pre><code># If data has \"Value\" (capital V)\ncolumns = param.List(default=[\"value\"])  # ‚ùå Won't match\ncolumns = param.List(default=[\"Value\"])  # ‚úÖ Matches\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#best-practices","level":2,"title":"Best practices","text":"<p>Keep analyses focused. One analysis should perform one calculation or produce one type of output.</p> <p>Declare required columns. Use <code>param.List(default=[...])</code> to specify what columns your analysis needs.</p> <p>Use param for configurability. Add <code>param.Number</code>, <code>param.Integer</code>, etc. for values users might want to adjust.</p> <p>Return Panel viewables. Use <code>pn.widgets.Tabulator</code>, <code>hvplot</code>, <code>pn.pane.Matplotlib</code>, or <code>pn.Column</code> to combine multiple outputs.</p> <p>Handle missing data. Check for NaN values and handle them appropriately in your calculations.</p> <p>Test with real data. Different datasets may have different distributions or edge cases.</p> <p>Document what it does. Write clear docstrings explaining the calculation and when to use it.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#working-with-global-context","level":2,"title":"Working with global context","text":"<p>You can add domain knowledge that all agents see by setting template overrides on the base Actor class:</p> Global context for all agents<pre><code>global_context = \"\"\"\n{{ super() }}\n\nDomain knowledge:\n\n- Inversions occur when temperature increases with altitude\n- Standard lapse rate is 6.5¬∞C per km\n\"\"\"\nlmai.actor.Actor.template_overrides = {\"main\": {\"global\": global_context}}\n\nui = lmai.ExplorerUI(\n    data='weather.csv',\n    analyses=[MyAnalysis]\n)\nui.servable()\n</code></pre> <p>This adds the context to all agents' prompts, helping them understand your domain.</p>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/analyses/#per-agent-customization-with-analyses","level":2,"title":"Per-agent customization with analyses","text":"<p>Combine analyses with agent-specific template overrides for domain-specific behavior:</p> Domain-specific agent behavior<pre><code># Make ChatAgent use meteorological terminology\nchat_instructions = \"\"\"\n{{ super() }}\n\nYou are a meteorologist. Use proper meteorological terminology \nand explain atmospheric concepts clearly.\n\"\"\"\nlmai.agents.ChatAgent.template_overrides = {\n    \"main\": {\"instructions\": chat_instructions}\n}\n\n# Pass analyses to ExplorerUI\nui = lmai.ExplorerUI(\n    data='soundings.csv',\n    analyses=[SkewTAnalysis],\n    suggestions=[\n        (\"question_answer\", \"What is a Skew-T diagram?\"),\n        (\"vertical_align_top\", \"Generate a Skew-T diagram.\"),\n    ]\n)\nui.servable()\n</code></pre> <p>The <code>columns</code> attribute on your Analysis class automatically informs upstream agents about required columns‚Äîno need to manually configure SQLAgent. For optional columns that enhance the analysis, mention them in the docstring:</p> Optional columns in docstring<pre><code>class SkewTAnalysis(lmai.Analysis):\n    \"\"\"\n    Creates a Skew-T log-P diagram from upper air sounding data.\n\n    To include wind barbs, also include speed_kts and drct columns.\n    \"\"\"\n\n    columns = [\"validUTC\", \"pressure_mb\", \"tmpc\", \"dwpc\"]  # Required\n\n    def __call__(self, pipeline, *args, **kwargs):\n        # speed_kts and drct are optional - checked at runtime\n        if \"drct\" in df.columns and \"speed_kts\" in df.columns:\n            # Add wind barbs\n            ...\n</code></pre>","path":["Configuration","Analyses"],"tags":[]},{"location":"configuration/cli/","level":1,"title":"Command-Line Interface","text":"<p>Launch Lumen AI from the command line with <code>lumen-ai serve</code>.</p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#basic-usage","level":2,"title":"Basic usage","text":"<pre><code>lumen-ai serve\n</code></pre> <p>Starts the server at <code>localhost:5006</code>.</p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#load-data","level":2,"title":"Load data","text":"Single file<pre><code>lumen-ai serve penguins.csv\n</code></pre> Multiple files<pre><code>lumen-ai serve customers.csv orders.csv\n</code></pre> From URL<pre><code>lumen-ai serve https://datasets.holoviz.org/penguins/v1/penguins.csv\n</code></pre> With wildcards<pre><code>lumen-ai serve data/*.csv\n</code></pre>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#database-connections","level":3,"title":"Database connections","text":"<p>Connect to databases using SQLAlchemy URLs:</p> SQLite database<pre><code>lumen-ai serve sqlite:///path/to/database.db\n</code></pre> DuckDB database<pre><code>lumen-ai serve duckdb:///path/to/database.db\n</code></pre> Auto-detect database type<pre><code>lumen-ai serve database.db\n</code></pre> PostgreSQL<pre><code>lumen-ai serve postgresql://user:password@localhost:5432/mydb\n</code></pre> MySQL<pre><code>lumen-ai serve mysql+pymysql://user:password@localhost:3306/mydb\n</code></pre> Multiple sources<pre><code>lumen-ai serve data.csv postgresql://localhost/mydb\n</code></pre>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#automatic-database-detection","level":4,"title":"Automatic database detection","text":"<p>For <code>.db</code> files, Lumen automatically detects whether they're SQLite or DuckDB databases:</p> Auto-detected .db files<pre><code>lumen-ai serve test.db\n</code></pre> <p>Lumen reads the file header to determine the database type:</p> <ul> <li>SQLite files start with <code>\"SQLite format 3\"</code></li> <li>DuckDB files start with <code>\"DUCK\"</code></li> </ul> <p>You can still use explicit URLs if preferred:</p> Explicit SQLite<pre><code>lumen-ai serve sqlite:///test.db\n</code></pre> Explicit DuckDB<pre><code>lumen-ai serve duckdb:///test.db\n</code></pre> <p>Tables auto-discovered</p> <p>When connecting to a database, Lumen automatically discovers all available tables. No need to specify individual table names.</p> <p>Supported databases:</p> <ul> <li>SQLite: <code>sqlite:///path/to/file.db</code> (or just <code>file.db</code> for auto-detection)</li> <li>DuckDB: <code>duckdb:///path/to/file.db</code> (or just <code>file.db</code> for auto-detection)</li> <li>PostgreSQL: <code>postgresql://user:pass@host:port/db</code></li> <li>MySQL: <code>mysql+pymysql://user:pass@host:port/db</code></li> <li>Oracle: <code>oracle://user:pass@host:port/db</code></li> <li>SQL Server: <code>mssql+pyodbc://user:pass@host:port/db</code></li> </ul> <p>See SQLAlchemy documentation for full URL syntax.</p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#configure-llm","level":2,"title":"Configure LLM","text":"","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#choose-provider","level":3,"title":"Choose provider","text":"Specify provider<pre><code>lumen-ai serve --provider anthropic\n</code></pre> <p>If not specified, Lumen auto-detects from environment variables.</p> <p>Supported providers:</p> <ul> <li><code>openai</code> - Requires <code>OPENAI_API_KEY</code></li> <li><code>anthropic</code> - Requires <code>ANTHROPIC_API_KEY</code></li> <li><code>google</code> - Requires <code>GEMINI_API_KEY</code></li> <li><code>mistral</code> - Requires <code>MISTRAL_API_KEY</code></li> <li><code>azure-openai</code> - Requires <code>AZUREAI_ENDPOINT_KEY</code></li> <li><code>ollama</code> - Local models</li> <li><code>llama-cpp</code> - Local models</li> <li><code>litellm</code> - Multi-provider</li> </ul>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#set-api-key","level":3,"title":"Set API key","text":"Pass API key directly<pre><code>lumen-ai serve --provider openai --api-key sk-...\n</code></pre> <p>Or use environment variables:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\nlumen-ai serve\n</code></pre>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#configure-models","level":3,"title":"Configure models","text":"","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#quick-model-selection","level":4,"title":"Quick model selection","text":"<p>For simple cases, use <code>--model</code> to set the default model:</p> Set default model<pre><code>lumen-ai serve --provider ollama --model 'qwen3:32b'\n</code></pre> Different providers<pre><code>lumen-ai serve --provider openai --model 'gpt-4o-mini'\nlumen-ai serve --provider anthropic --model 'claude-sonnet-4-5'\nlumen-ai serve --provider google --model 'gemini-2.0-flash'\n</code></pre> <p>The <code>--model</code> argument automatically sets <code>model_kwargs['default']['model']</code> for you.</p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#advanced-model-configuration","level":4,"title":"Advanced model configuration","text":"<p>For multiple models or additional parameters, use <code>--model-kwargs</code> with JSON:</p> Multiple models for different tasks<pre><code>lumen-ai serve --model-kwargs '{\n  \"default\": {\"model\": \"gpt-4o-mini\"},\n  \"sql\": {\"model\": \"gpt-4o\"},\n  \"edit\": {\"model\": \"gpt-4o\"}\n}'\n</code></pre> Combine --model with --model-kwargs<pre><code>lumen-ai serve --provider ollama \\\n  --model 'qwen3:32b' \\\n  --model-kwargs '{\"edit\": {\"model\": \"mistral-small3.2:24b\"}}'\n</code></pre> <p>This sets <code>qwen3:32b</code> as the default model and <code>mistral-small3.2:24b</code> for editing tasks.</p> <p>Escape JSON properly</p> <p>The JSON string must be properly quoted. Use single quotes around the entire JSON, double quotes inside.</p> <p>Model types</p> <p>Common model types in <code>model_kwargs</code>:</p> <ul> <li><code>default</code> - General queries and analysis</li> <li><code>sql</code> - SQL query generation (some providers use specialized models)</li> <li><code>edit</code> - Code/chart editing (may use more capable models)</li> <li><code>ui</code> - UI responsive check (lightweight models)</li> </ul>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#adjust-temperature","level":3,"title":"Adjust temperature","text":"Control randomness<pre><code>lumen-ai serve --temperature 0.5\n</code></pre> <p>Lower (0.1) = deterministic. Higher (0.7) = creative. Range: 0.0-2.0</p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#select-agents","level":2,"title":"Select agents","text":"Use specific agents<pre><code>lumen-ai serve --agents SQLAgent ChatAgent VegaLiteAgent\n</code></pre> <p>Agent names are case-insensitive. The \"Agent\" suffix is optional: <code>sql</code> = <code>sqlagent</code> = <code>SQLAgent</code></p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#common-flags","level":2,"title":"Common flags","text":"Flag Purpose Example <code>--code-execution</code> Code execution mode <code>--code-execution prompt</code> <code>--provider</code> LLM provider <code>--provider anthropic</code> <code>--api-key</code> API key <code>--api-key sk-...</code> <code>--model</code> Default model <code>--model 'qwen3:32b'</code> <code>--model-kwargs</code> Advanced model config <code>--model-kwargs '{\"sql\": {\"model\": \"gpt-4o\"}}'</code> <code>--temperature</code> Randomness <code>--temperature 0.5</code> <code>--agents</code> Active agents <code>--agents SQLAgent ChatAgent</code> <code>--port</code> Server port <code>--port 8080</code> <code>--address</code> Network address <code>--address 0.0.0.0</code> <code>--show</code> Auto-open browser <code>--show</code> <code>--log-level</code> Verbosity <code>--log-level DEBUG</code>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#full-example","level":2,"title":"Full example","text":"Complete configuration<pre><code>lumen-ai serve penguins.csv \\\n  --provider openai \\\n  --model 'gpt-4o-mini' \\\n  --model-kwargs '{\"sql\": {\"model\": \"gpt-4o\"}}' \\\n  --temperature 0.5 \\\n  --agents SQLAgent ChatAgent VegaLiteAgent \\\n  --port 8080 \\\n  --show\n</code></pre> Using Ollama locally<pre><code>lumen-ai serve data/*.csv \\\n  --provider ollama \\\n  --model 'qwen3:32b' \\\n  --temperature 0.4 \\\n  --log-level debug \\\n  --show\n</code></pre>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/cli/#view-all-options","level":2,"title":"View all options","text":"<pre><code>lumen-ai serve --help\n</code></pre> <p>Shows all available flags including Panel server options.</p>","path":["Configuration","Command-Line Interface"],"tags":[]},{"location":"configuration/context/","level":1,"title":"Context","text":"<p>Context is shared memory between agents. When SQLAgent creates a pipeline, it adds it to context. When AnalystAgent runs, it reads that pipeline from context.</p> <p>See also: Agents ‚Äî Agents communicate through context using input and output schemas.</p>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#how-context-works","level":2,"title":"How context works","text":"<p>Agents communicate by reading from and writing to a shared dictionary:</p> Agent adds to context<pre><code>async def respond(self, messages, context, **kwargs):\n    # Do work\n    result = \"Sales increased 20%\"\n\n    # Return what to show user + what to add to context\n    return [result], {\"summary\": result}  # (1)!\n</code></pre> <ol> <li>Context update gets merged into shared memory</li> </ol> <p>Other agents can then access <code>context[\"summary\"]</code>.</p>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#define-requirements","level":2,"title":"Define requirements","text":"<p>Agents declare what they need using schemas:</p> Input and output schemas<pre><code>from lumen.ai.context import ContextModel\nfrom typing import NotRequired\n\nclass MyInputs(ContextModel):\n    pipeline: object  # Required - agent won't run without this\n    sql: NotRequired[str]  # Optional\n\nclass MyOutputs(ContextModel):\n    summary: str  # Agent adds this to context\n    metrics: dict\n</code></pre> <p>Fields without <code>NotRequired</code> are required. The agent only runs when required fields exist in context.</p>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#common-context-keys","level":2,"title":"Common context keys","text":"Key Added by Used by <code>source</code> Initial setup SQLAgent <code>pipeline</code> SQLAgent VegaLiteAgent <code>sql</code> SQLAgent ChatAgent <code>data</code> SQLAgent ChatAgent <code>metaset</code> TableListAgent SQLAgent","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#safe-context-access","level":2,"title":"Safe context access","text":"<p>Always use <code>.get()</code> for optional keys:</p> Check before accessing<pre><code># Bad - crashes if missing\nanalysis = context['analysis']  # ‚ùå\n\n# Good - returns None if missing\nanalysis = context.get('analysis')  # ‚úÖ\nif analysis is None:\n    return [\"No analysis yet\"], {}\n</code></pre>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#examples","level":2,"title":"Examples","text":"","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#agent-requiring-previous-results","level":3,"title":"Agent requiring previous results","text":"Requires analysis from AnalystAgent<pre><code>from lumen.ai.context import ContextModel\n\nclass ReportInputs(ContextModel):\n    pipeline: object\n    analysis: str  # Must exist before agent runs\n\nasync def respond(self, messages, context, **kwargs):\n    pipeline = context['pipeline']\n    analysis = context['analysis']\n\n    report = f\"Results: {len(pipeline.data)} rows\\n\\n{analysis}\"\n    return [report], {\"report\": report}\n</code></pre>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#tool-providing-context","level":3,"title":"Tool providing context","text":"Tool adds to context<pre><code>from lumen.ai.tools import FunctionTool\n\ntool = FunctionTool(\n    function=calculate_totals,\n    requires=[\"pipeline\"],\n    provides=[\"total_sales\"]  # (1)!\n)\n</code></pre> <ol> <li>Other agents can access <code>context[\"total_sales\"]</code></li> </ol>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#accumulating-values","level":3,"title":"Accumulating values","text":"<p>Collect values from multiple agents into a list:</p> Accumulate sources<pre><code>from typing import Annotated\n\nclass MyInputs(ContextModel):\n    sources: Annotated[list[object], (\"accumulate\", \"source\")]  # (1)!\n</code></pre> <ol> <li>Gathers all <code>source</code> values into <code>sources</code> list</li> </ol> <p>If Agent A adds <code>{\"source\": s1}</code> and Agent B adds <code>{\"source\": s2}</code>, your agent sees <code>sources: [s1, s2]</code>.</p>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#best-practices","level":2,"title":"Best practices","text":"<p>Use NotRequired for optional fields. Most fields should be optional - only require what's absolutely necessary.</p> <p>Use meaningful key names. <code>sales_summary</code> is better than <code>data</code>.</p> <p>Don't pollute context. Only add keys other agents might use. Skip temporary/internal values.</p> <p>Check before accessing. Always use <code>.get()</code> for optional keys.</p> <p>Document your schemas. Add Field descriptions to help others understand what the data represents.</p>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/context/#debug-context","level":2,"title":"Debug context","text":"<p>Enable debug logging to see context updates:</p> <pre><code>ui = lmai.ExplorerUI(data='penguins.csv', log_level='DEBUG')\n</code></pre> <p>Check console output for context keys and values.</p>","path":["Configuration","Context"],"tags":[]},{"location":"configuration/coordinators/","level":1,"title":"Coordinators","text":"<p>Coordinators decide which agents answer your questions and in what order.</p> <p>Most users never need to change the coordinator. The default works well for typical data exploration.</p>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#should-you-customize-the-coordinator","level":2,"title":"Should you customize the coordinator?","text":"<p>Probably not. The default Planner handles most cases well.</p> <p>Consider customizing only if:</p> <ul> <li>Planning is too slow for simple queries (try DependencyResolver)</li> <li>You want to see detailed planning steps (enable verbose mode)</li> <li>Plans include too many unnecessary steps</li> </ul>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#change-coordinators","level":2,"title":"Change coordinators","text":"","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#use-dependencyresolver-for-faster-planning","level":3,"title":"Use DependencyResolver for faster planning","text":"<p>The DependencyResolver skips comprehensive planning and jumps straight to execution:</p> Use DependencyResolver<pre><code>import lumen.ai as lmai\nfrom lumen.ai.coordinator import DependencyResolver\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    coordinator=DependencyResolver\n)\nui.servable()\n</code></pre> <p>When to use DependencyResolver:</p> <ul> <li>Simple, single-purpose queries (\"Show me a chart of X\")</li> <li>When planning takes longer than execution</li> <li>When you don't need automatic validation</li> </ul> <p>When to keep the default Planner:</p> <ul> <li>Complex multi-step analysis</li> <li>When you want to see the full plan before execution</li> <li>When automatic validation is valuable</li> </ul>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#adjust-planning-behavior","level":2,"title":"Adjust planning behavior","text":"","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#show-detailed-planning-steps","level":3,"title":"Show detailed planning steps","text":"<p>See exactly how Lumen creates and executes plans:</p> Enable verbose mode<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    coordinator_params={'verbose': True}\n)\nui.servable()\n</code></pre> <p>This shows which agents are considered, why each is selected, and what data flows between steps.</p>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#disable-automatic-validation","level":3,"title":"Disable automatic validation","text":"<p>Skip the validation step to get results faster:</p> Disable validation<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    coordinator_params={'validation_enabled': False}\n)\nui.servable()\n</code></pre> <p>Only disable validation if you trust the results</p> <p>Validation catches errors and confirms queries were answered correctly. Only disable during rapid development iteration.</p>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#control-pre-planning-data-lookup","level":3,"title":"Control pre-planning data lookup","text":"<p>The Planner looks up table information before creating a plan. Disable this if you already know what data is available:</p> Skip table lookup<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    coordinator_params={'planner_tools': []}\n)\nui.servable()\n</code></pre>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#how-coordinators-work","level":2,"title":"How coordinators work","text":"","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#planner-creates-a-complete-plan-upfront","level":3,"title":"Planner creates a complete plan upfront","text":"<p>The Planner is Lumen's default coordinator:</p> <pre><code>graph TB\n    A[User Query] --&gt; B[Gather Context]\n    B --&gt; C[Create Plan]\n    C --&gt; D[Show Checklist]\n    D --&gt; E[Execute Step 1]\n    E --&gt; F[Execute Step 2]\n    F --&gt; G[Execute Step N]\n    G --&gt; H[Validate Results]\n</code></pre> <p>Example: \"Show me average bill length by species as a bar chart\"</p> <p>The Planner creates this checklist: <pre><code>‚òê Find tables with penguin data\n‚òê Query data and calculate averages by species\n‚òê Create a bar chart\n‚òê Summarize the findings\n‚òê Verify the query was answered\n</code></pre></p> <p>Then executes each step in order, checking them off as it goes.</p>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#dependencyresolver-works-backward-from-the-goal","level":3,"title":"DependencyResolver works backward from the goal","text":"<p>The DependencyResolver picks the final agent first, then figures out what it needs:</p> <pre><code>graph BT\n    A[TableLookup] --&gt; B[SQLAgent]\n    B --&gt; C[VegaLiteAgent]\n    C --&gt; D[Goal Achieved]\n</code></pre> <p>Same example: \"Show me average bill length by species as a bar chart\"</p> <p>DependencyResolver thinks: <pre><code>Goal: VegaLiteAgent (needs pipeline)\n  ‚Üë SQLAgent (needs metaset)\n    ‚Üë TableLookup (no dependencies)\n\nExecution: TableLookup ‚Üí SQLAgent ‚Üí VegaLiteAgent\n</code></pre></p> <p>No planning phase, just direct execution.</p>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#common-issues","level":2,"title":"Common issues","text":"","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#planner-failed-to-come-up-with-viable-plan","level":3,"title":"\"Planner failed to come up with viable plan\"","text":"<p>The planner couldn't create a valid plan after multiple attempts.</p> <p>How to fix:</p> <ol> <li>Rephrase your question more specifically</li> <li>Check that required data sources are loaded</li> <li>Try with <code>verbose=True</code> to see what went wrong</li> <li>Use DependencyResolver for simpler queries</li> </ol>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#plans-include-too-many-steps","level":3,"title":"Plans include too many steps","text":"<p>The planner is being overly cautious.</p> <p>How to fix:</p> <ol> <li>Ask follow-up questions to reuse existing data</li> <li>Disable validation: <code>coordinator_params={'validation_enabled': False}</code></li> <li>Use DependencyResolver for straightforward queries</li> </ol>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#planning-takes-too-long","level":3,"title":"Planning takes too long","text":"<p>The Planner is gathering too much context upfront.</p> <p>How to fix:</p> <ol> <li>Switch to DependencyResolver</li> <li>Disable pre-planning lookup: <code>coordinator_params={'planner_tools': []}</code></li> </ol>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#agents-run-in-wrong-order","level":3,"title":"Agents run in wrong order","text":"<p>Dependencies weren't resolved correctly.</p> <p>How to fix:</p> <ol> <li>Enable verbose mode to see the dependency chain</li> <li>Report the issue on GitHub with a reproducible example</li> </ol>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#coordinator-comparison","level":2,"title":"Coordinator comparison","text":"Feature Planner (default) DependencyResolver Planning speed Slower (creates plan first) Faster (no planning phase) Best for Complex queries Simple queries Shows plan Yes, with checklist No, executes directly Validation Automatic Not included LLM calls More (comprehensive) Fewer (minimal) Recommended for Most use cases Speed-critical simple queries","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/coordinators/#when-to-create-a-custom-coordinator","level":2,"title":"When to create a custom coordinator","text":"<p>Almost never. The built-in coordinators handle nearly all use cases.</p> <p>Only create a custom coordinator if:</p> <ul> <li>You have very specific orchestration requirements</li> <li>You're building a specialized application with unique workflows</li> <li>You've exhausted all configuration options</li> </ul> <p>See the Contributing guide if you think Lumen needs a new coordinator type.</p>","path":["Configuration","Coordinators"],"tags":[]},{"location":"configuration/embeddings/","level":1,"title":"Embeddings","text":"<p>Convert text into numerical vectors for semantic search.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#quick-start","level":2,"title":"Quick start","text":"<p>By default, Lumen uses simple Numpy-based embeddings:</p> Default embeddings (no setup needed)<pre><code>import lumen.ai as lmai\n\nui = lmai.ExplorerUI(data='penguins.csv')\nui.servable()\n</code></pre> <p>For better semantic search, use OpenAI:</p> OpenAI embeddings<pre><code>import lumen.ai as lmai\nfrom lumen.ai.embeddings import OpenAIEmbeddings\nfrom lumen.ai.vector_store import DuckDBVectorStore\n\nvector_store = DuckDBVectorStore(embeddings=OpenAIEmbeddings())\nui = lmai.ExplorerUI(data='penguins.csv', vector_store=vector_store)\nui.servable()\n</code></pre> <p>See Vector Stores for how to use embeddings with storage backends.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#providers","level":2,"title":"Providers","text":"","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#openai","level":3,"title":"OpenAI","text":"OpenAI embeddings<pre><code>from lumen.ai.embeddings import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # Fast\n# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")  # Higher quality\n</code></pre> <p>Setup:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre> <p>See LLM Providers for more on OpenAI configuration.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#azure-openai","level":3,"title":"Azure OpenAI","text":"Azure embeddings<pre><code>from lumen.ai.embeddings import AzureOpenAIEmbeddings\n\nembeddings = AzureOpenAIEmbeddings(\n    api_key='...',\n    endpoint='https://your-resource.openai.azure.com/'\n)\n</code></pre> <p>See LLM Providers - Azure OpenAI for authentication details.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#huggingface","level":3,"title":"HuggingFace","text":"<p>Run locally with Sentence Transformers:</p> Local embeddings<pre><code>from lumen.ai.embeddings import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings(\n    model=\"ibm-granite/granite-embedding-107m-multilingual\",\n    device=\"cpu\"  # or \"cuda\" for GPU\n)\n</code></pre> <p>Install:</p> <pre><code>pip install sentence-transformers\n</code></pre>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#llamacpp","level":3,"title":"Llama.cpp","text":"<p>Run GGUF models locally:</p> GGUF embeddings<pre><code>from lumen.ai.embeddings import LlamaCppEmbeddings\n\nembeddings = LlamaCppEmbeddings(\n    model_kwargs={\n        \"default\": {\n            \"repo_id\": \"Qwen/Qwen3-Embedding-4B-GGUF\",\n            \"filename\": \"Qwen3-Embedding-4B-Q4_K_M.gguf\",\n        }\n    }\n)\n</code></pre> <p>See LLM Providers - Llama.cpp for model configuration.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#numpy-default","level":3,"title":"Numpy (default)","text":"<p>Hash-based embeddings for prototyping:</p> Simple embeddings<pre><code>from lumen.ai.embeddings import NumpyEmbeddings\n\nembeddings = NumpyEmbeddings()\n</code></pre> <ul> <li>‚úÖ No API calls, works offline</li> <li>‚ö†Ô∏è Lower quality than neural embeddings</li> </ul>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#configuration","level":2,"title":"Configuration","text":"","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#chunk-size","level":3,"title":"Chunk size","text":"<p>Control how documents are split:</p> Custom chunking<pre><code>vector_store = DuckDBVectorStore(\n    embeddings=OpenAIEmbeddings(),\n    chunk_size=512,  # Smaller chunks = more precise\n)\n</code></pre> <p>Guidelines:</p> <ul> <li>Small (256-512): Precise answers, higher cost</li> <li>Medium (1024): Balanced (default)</li> <li>Large (2048): Broader context, lower cost</li> </ul> <p>See Vector Stores - Chunk size for implementation details.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#exclude-metadata","level":3,"title":"Exclude metadata","text":"<p>Prevent fields from being embedded:</p> Exclude metadata<pre><code>vector_store = DuckDBVectorStore(\n    embeddings=OpenAIEmbeddings(),\n    excluded_metadata=['file_size', 'upload_date']\n)\n</code></pre>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#when-embeddings-are-used","level":2,"title":"When embeddings are used","text":"<p>Embeddings power three features:</p> <p>Document search - Queries find semantically similar text:</p> <pre><code>results = await vector_store.query('authentication setup')\n</code></pre> <p>See Vector Stores - Searching for query examples.</p> <p>Contextual augmentation - Chunks get context descriptions:</p> <pre><code>vector_store = DuckDBVectorStore(situate=True)  # Adds context to chunks\n</code></pre> <p>See Vector Stores - Contextual augmentation for details on situate.</p>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#best-practices","level":2,"title":"Best practices","text":"<p>Match embeddings to data:</p> <ul> <li>English-only ‚Üí <code>sentence-transformers/all-MiniLM-L6-v2</code></li> <li>Multilingual ‚Üí <code>ibm-granite/granite-embedding-107m-multilingual</code></li> <li>Best quality ‚Üí <code>text-embedding-3-large</code></li> </ul> <p>Optimize chunk size:</p> <ul> <li>FAQ/short answers ‚Üí 256-512 tokens</li> <li>General documents ‚Üí 1024 tokens (default)</li> <li>Long-form content ‚Üí 2048 tokens</li> </ul> <p>Use situate selectively:</p> <ul> <li>Enable for technical docs, books, research papers</li> <li>Disable for simple content (FAQs, short articles)</li> <li>Requires LLM access (uses additional API calls)</li> </ul>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/embeddings/#see-also","level":2,"title":"See also","text":"<ul> <li>Vector Stores - Storage and retrieval using embeddings</li> <li>LLM Providers - Configure API keys and models</li> <li>Tools - Built-in tools that use embeddings</li> </ul>","path":["Configuration","Embeddings"],"tags":[]},{"location":"configuration/llm_providers/","level":1,"title":"LLM Providers","text":"<p>Configure which AI model powers Lumen.</p> <p>First time setup?</p> <p>See the Installation guide for step-by-step instructions on setting up API keys and environment variables for each provider.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#quick-start","level":2,"title":"Quick start","text":"<p>Set your API key and launch:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\nlumen-ai serve penguins.csv\n</code></pre> <p>Lumen auto-detects the provider from environment variables.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#different-models-per-agent","level":2,"title":"Different models per agent","text":"<p>Use cheap models for simple tasks, powerful models for complex tasks:</p> Cost-optimized configuration<pre><code>import lumen.ai as lmai\n\nmodel_config = {\n    \"default\": {\"model\": \"gpt-4.1-mini\"},  # Cheap for most agents\n    \"sql\": {\"model\": \"gpt-4.1\"},           # Powerful for SQL\n    \"vega_lite\": {\"model\": \"gpt-4.1\"},     # Powerful for charts\n    \"deck_gl\": {\"model\": \"gpt-4.1\"},       # Powerful for 3D maps\n    \"analyst\": {\"model\": \"gpt-4.1\"},       # Powerful for analysis\n}\n\nllm = lmai.llm.OpenAI(model_kwargs=model_config)\nui = lmai.ExplorerUI(data='penguins.csv', llm=llm)\nui.servable()\n</code></pre> <p>Agent names map to model types: <code>SQLAgent</code> ‚Üí <code>\"sql\"</code>, <code>VegaLiteAgent</code> ‚Üí <code>\"vega_lite\"</code>, etc.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#configure-temperature","level":2,"title":"Configure temperature","text":"<p>Lower temperature = more deterministic. Higher = more creative.</p> Temperature by task<pre><code>model_config = {\n    \"sql\": {\n        \"model\": \"gpt-4.1\",\n        \"temperature\": 0.1,  # Deterministic SQL\n    },\n    \"chat\": {\n        \"model\": \"gpt-4.1-mini\",\n        \"temperature\": 0.4,  # Natural conversation\n    },\n}\n</code></pre> <p>Recommended ranges: 0.1 (SQL) to 0.4 (chat).</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#supported-providers","level":2,"title":"Supported providers","text":"<p>For installation and API key setup instructions, see the Installation guide.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#cloud-providers","level":3,"title":"Cloud providers","text":"Provider Default Model Popular Models OpenAI <code>gpt-4.1-mini</code> <code>gpt-4.1</code>, <code>gpt-4-turbo</code>, <code>gpt-4</code> Anthropic <code>claude-haiku-4-5</code> <code>claude-sonnet-4-5</code>, <code>claude-opus-4-5</code> Google <code>gemini-3-flash-preview</code> <code>gemini-3-pro-preview</code>, <code>gemini-2.5-flash</code>, <code>gemini-2.0-flash</code> Mistral <code>mistral-small-latest</code> <code>mistral-large-latest</code>, <code>ministral-8b-latest</code> Azure OpenAI <code>gpt-4.1-mini</code> <code>gpt-4.1</code>, <code>gpt-4-turbo</code>, <code>gpt-4</code> Azure Mistral <code>azureai</code> <code>mistral-large</code>, <code>mistral-small</code> <p>Reasoning Models Not Suitable for Dialog</p> <p>Reasoning models like <code>gpt-5</code>, <code>o4-mini</code>, and <code>gemini-2.0-flash-thinking</code> are significantly slower than standard models. They are designed for single, complex queries that require deep thinking, not interactive chat interfaces. For dialog-based applications like Lumen, use standard models for better user experience.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#local-providers","level":3,"title":"Local providers","text":"Provider Default Model Notes Ollama <code>qwen3:32b</code> Requires Ollama installed, models pulled locally Llama.cpp <code>unsloth/Qwen3-32B-GGUF</code> Auto-downloads models on first use <p>Recommended local models:</p> <ul> <li>General purpose: <code>qwen3:32b</code>, <code>llama3.3:70b</code>, <code>qwen3:30b-a3b</code>, <code>nemotron-3-nano:30b</code></li> <li>Coding: <code>qwen3-coder:32b</code>, <code>qwen2.5-coder:32b</code></li> <li>Reasoning: <code>nemotron-3-nano:30b</code></li> </ul>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#router-gateway-providers","level":3,"title":"Router / Gateway providers","text":"Provider Purpose Setup AWS Bedrock Gateway to Anthropic, Meta, Mistral, Amazon models Installation guide LiteLLM Router for 100+ models across all providers Installation guide <p>AWS Bedrock options:</p> <ul> <li>AnthropicBedrock - Optimized for Claude models using Anthropic's SDK</li> <li>Bedrock - Universal access to all Bedrock models (Claude, Llama, Mistral, Titan, etc.)</li> </ul>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#advanced-configuration","level":2,"title":"Advanced configuration","text":"","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#custom-endpoints","level":3,"title":"Custom endpoints","text":"<p>Override default API endpoints:</p> Custom endpoint<pre><code>llm = lmai.llm.OpenAI(\n    api_key='...',\n    endpoint='https://your-custom-endpoint.com/v1'\n)\n</code></pre>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#managed-identity-azure","level":3,"title":"Managed Identity (Azure)","text":"<p>Use Azure Active Directory authentication:</p> Azure Managed Identity<pre><code>from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n\ntoken_provider = get_bearer_token_provider(\n    DefaultAzureCredential(),\n    \"https://cognitiveservices.azure.com/.default\"\n)\n\nllm = lmai.llm.AzureOpenAI(\n    api_version=\"2024-02-15-preview\",\n    endpoint=\"https://your-resource.openai.azure.com/\",\n    model_kwargs={\n        \"default\": {\n            \"model\": \"gpt4o-mini\",\n            \"azure_ad_token_provider\": token_provider\n        }\n    }\n)\n</code></pre>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#fallback-models-litellm","level":3,"title":"Fallback models (LiteLLM)","text":"<p>Automatically retry with backup models if primary fails:</p> Fallback configuration<pre><code>llm = lmai.llm.LiteLLM(\n    model_kwargs={\n        \"default\": {\"model\": \"gpt-4.1-mini\"}\n    },\n    fallback_models=[\n        \"gpt-4.1-mini\",\n        \"claude-haiku-4-5\",\n        \"gemini/gemini-2.5-flash\"\n    ]\n)\n</code></pre>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#remote-ollama-server","level":3,"title":"Remote Ollama server","text":"<p>Connect to Ollama running on another machine:</p> Remote Ollama<pre><code>llm = lmai.llm.Ollama(\n    endpoint='http://your-server:11434/v1',\n    model_kwargs={\"default\": {\"model\": \"qwen3:32b\"}}\n)\n</code></pre>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#model-types","level":2,"title":"Model types","text":"<p>Agent class names convert to model types automatically:</p> Agent Model type SQLAgent <code>sql</code> VegaLiteAgent <code>vega_lite</code> DeckGLAgent <code>deck_gl</code> ChatAgent <code>chat</code> AnalysisAgent <code>analysis</code> (others) <code>default</code> <p>Conversion rule: remove \"Agent\" suffix, convert to snake_case.</p> <p>Additional model types:</p> <ul> <li><code>edit</code> - Used when fixing errors</li> <li><code>ui</code> - Used for UI initialization</li> </ul>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#model-string-formats","level":2,"title":"Model string formats","text":"<p>Different providers use different model string formats:</p> <ul> <li>OpenAI: <code>\"gpt-4.1\"</code>, <code>\"gpt-4.1-mini\"</code>, <code>\"gpt-4-turbo\"</code>, <code>\"gpt-4\"</code></li> <li>Anthropic: <code>\"claude-sonnet-4-5\"</code>, <code>\"claude-haiku-4-5\"</code>, <code>\"claude-opus-4-5\"</code></li> <li>Google: <code>\"gemini-3-flash-preview\"</code>, <code>\"gemini-2.5-flash\"</code></li> <li>Mistral: <code>\"mistral-large-latest\"</code>, <code>\"mistral-small-latest\"</code></li> <li>Azure: <code>\"your-deployment-name\"</code> (use your Azure deployment name)</li> <li>Bedrock: <code>\"us.anthropic.claude-sonnet-4-5-20250929-v1:0\"</code>, <code>\"meta.llama3-70b-instruct-v1:0\"</code></li> <li>LiteLLM: <code>\"gpt-4.1-mini\"</code> (OpenAI), <code>\"anthropic/claude-sonnet-4-5\"</code> (Anthropic), <code>\"gemini/gemini-2.5-flash\"</code> (Google)</li> </ul> <p>For LiteLLM, use the <code>provider/model</code> format for non-OpenAI models.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#troubleshooting","level":2,"title":"Troubleshooting","text":"<p>\"API key not found\" - Set environment variable or pass <code>api_key=</code> in Python.</p> <p>Wrong model used - Model type names must be snake_case: <code>\"sql\"</code> not <code>\"SQLAgent\"</code>.</p> <p>High costs - Use <code>gpt-4.1-mini</code> or <code>claude-haiku-4-5</code> for <code>default</code>, reserve <code>gpt-4.1</code> or <code>claude-sonnet-4-5</code> for critical tasks (<code>sql</code>, <code>vega_lite</code>, <code>analyst</code>).</p> <p>Slow responses - Local models are slower than cloud APIs. Use cloud providers when speed matters.</p> <p>AWS credentials not found - For Bedrock, ensure AWS credentials are configured. See Installation guide.</p>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/llm_providers/#best-practices","level":2,"title":"Best practices","text":"<p>Use efficient models elsewhere:</p> <ul> <li><code>default</code> - Simple tasks work well with <code>gpt-4.1-mini</code> or <code>claude-haiku-4-5</code></li> <li><code>chat</code> - Conversation works with smaller models</li> </ul> <p>Avoid reasoning models in dialog interfaces:</p> <ul> <li>Reasoning models (<code>o1</code>, <code>o1-mini</code>, <code>gemini-3.0-pro</code>) are significantly slower</li> <li>They're designed for single, complex queries, not interactive chat</li> <li>For Lumen's dialog interface, use standard models (<code>mistral-small-latest</code>, <code>gpt-4.1-mini</code>, <code>claude-sonnet-4-5</code>)</li> <li>Reserve reasoning models for batch processing or one-off complex analyses</li> </ul> <p>Set temperature by task:</p> <ul> <li>0.1 for SQL (deterministic)</li> <li>0.3-0.4 for analysis and chat</li> <li>0.5-0.7 for creative tasks</li> </ul> <p>Test before deploying:</p> <ul> <li>Different models behave differently. Test with real queries.</li> </ul>","path":["Configuration","LLM Providers"],"tags":[]},{"location":"configuration/prompts/","level":1,"title":"Prompts","text":"<p>Prompts control what agents say and how they behave.</p> <p>Most users don't need to customize prompts. Customize only if agents consistently make mistakes you can fix with instructions.</p> <p>See also: Agents ‚Äî Prompts are used by custom and built-in agents. Each agent type can have its prompts customized.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#how-prompts-work","level":2,"title":"How Prompts Work","text":"<p>Lumen uses Jinja2 template inheritance. All agents extend from <code>Actor/main.jinja2</code>:</p> <pre><code>{% extends 'Actor/main.jinja2' %}\n</code></pre> <p>This inheritance is why <code>{{ super() }}</code> works‚Äîit calls the parent block's content.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#quick-examples","level":2,"title":"Quick examples","text":"","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#change-agent-tone","level":3,"title":"Change agent tone","text":"Add personality<pre><code>import lumen.ai as lmai\n\ninstructions = \"\"\"\n{{ super() }}\n\nBe warm and enthusiastic.\n\"\"\"\n\ntemplate_overrides = {\n    \"main\": {\n        \"instructions\": instructions\n    }\n}\n\nagent = lmai.agents.ChatAgent(template_overrides=template_overrides)\nui = lmai.ExplorerUI(data='penguins.csv', agents=[agent])\nui.servable()\n</code></pre> <p><code>{{ super() }}</code> keeps original instructions and adds yours after.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#add-sql-rules","level":3,"title":"Add SQL rules","text":"SQL guidelines<pre><code>instructions = \"\"\"\n{{ super() }}\n\nAdditional rules:\n\n- Use explicit JOIN syntax\n- Format dates as YYYY-MM-DD\n- Use meaningful table aliases\n\"\"\"\n\ntemplate_overrides = {\n    \"main\": {\n        \"instructions\": instructions\n    }\n}\n\nagent = lmai.agents.SQLAgent(template_overrides=template_overrides)\n</code></pre>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#add-domain-knowledge","level":3,"title":"Add domain knowledge","text":"Domain context<pre><code>context = \"\"\"\n{{ super() }}\n\nIn our database:\n\n- \"Accounts\" means customer accounts\n- Q1 = Jan-Mar, Q2 = Apr-Jun, Q3 = Jul-Sep, Q4 = Oct-Dec\n\"\"\"\n\ntemplate_overrides = {\n    \"main\": {\n        \"context\": context\n    }\n}\n</code></pre>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#override-blocks","level":2,"title":"Override blocks","text":"","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#block-execution-order","level":3,"title":"Block Execution Order","text":"<p>Blocks render in this order (top to bottom = what the LLM sees):</p> # Block Purpose Auto-populated? Common Use 1 <code>global</code> Domain knowledge for all agents No Rarely used 2 <code>datetime</code> Current timestamp Yes Keep default 3 <code>instructions</code> Main task rules No Most common 4 <code>examples</code> Example outputs No Common 5 <code>tools</code> Tool-specific contexts Yes Rarely override 6 <code>context</code> Agent-specific knowledge No Common 7 <code>errors</code> Previous errors to fix Yes Rarely override 8 <code>footer</code> Closing notes No Occasional <p>Auto-populated blocks:</p> <ul> <li><code>datetime</code>: Always includes current time</li> <li><code>tools</code>: Populated from <code>memory[\"agent_tool_contexts\"]</code> and <code>tool_context</code></li> <li><code>errors</code>: Only appears when previous execution failed (shows <code>last_output</code> and error messages)</li> </ul>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#most-useful-blocks","level":3,"title":"Most Useful Blocks","text":"<p>Three blocks cover most needs:</p> <ul> <li><code>instructions</code> - Main task rules</li> <li><code>examples</code> - Show desired output format</li> <li><code>context</code> - Add domain knowledge</li> </ul>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#multiple-agents","level":2,"title":"Multiple agents","text":"Customize multiple agents<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    agents=[\n        lmai.agents.ChatAgent(template_overrides=chat_overrides),\n    ]\n)\nui.servable()\n</code></pre>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#agents-with-multiple-prompts","level":2,"title":"Agents with multiple prompts","text":"<p>Most agents have one prompt. Some have more:</p> <ul> <li>SQLAgent: <code>main</code>, <code>select_discoveries</code>, <code>check_sufficiency</code>, <code>revise_output</code></li> <li>VegaLiteAgent: <code>main</code>, <code>interaction_polish</code>, <code>annotate_plot</code>, <code>revise_output</code></li> </ul> <p>Override specific prompts:</p> Multiple prompt overrides<pre><code>main_instructions = \"{{ super() }} Generate optimized SQL.\"\nrevise_instructions = \"{{ super() }} When fixing errors, explain what went wrong.\"\n\ntemplate_overrides = {\n    \"main\": {\n        \"instructions\": main_instructions\n    },\n    \"revise_output\": {\n        \"instructions\": revise_instructions\n    }\n}\n</code></pre>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#replace-entire-prompt","level":2,"title":"Replace entire prompt","text":"<p>Only do this if block overrides don't work:</p> Full prompt replacement<pre><code>full_template = \"\"\"\nYou are a retail analytics assistant.\n\nData: {{ memory['data'] }}\nQuestion: {{ messages[-1]['content'] }}\n\nFocus on customer segments and purchase patterns. Be concise.\n\"\"\"\n\nprompts = {\n    \"main\": {\n        \"template\": full_template\n    }\n}\n\nagent = lmai.agents.ChatAgent(prompts=prompts)\n</code></pre> <p>You lose all defaults</p> <p>Full replacement discards all built-in instructions. Use block overrides with <code>{{ super() }}</code> instead.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#load-prompts-from-files","level":2,"title":"Load prompts from files","text":"<p>For complex prompts, load from external files using absolute paths:</p> Load from file (absolute path)<pre><code>from pathlib import Path\n\ntemplate_overrides = {\n    \"main\": {\n        \"instructions\": str(Path(__file__).parent / 'agents.py')\n    }\n}\n\nagent = lmai.agents.SQLAgent(template_overrides=template_overrides)\n</code></pre> <p>Create <code>agents.py</code> with your instructions:</p> agents.py<pre><code>Your SQL agent handles customer data queries.\n\nRules:\n\n- Always use INNER JOIN for relationships\n- Sanitize date inputs to YYYY-MM-DD format\n- Group by customer segments first\n\nExamples:\n\n- \"Top customers\" ‚Üí Order by revenue DESC\n- \"Monthly trends\" ‚Üí Use DATE_TRUNC\n</code></pre> <p>Use absolute paths</p> <p>Always use absolute paths (e.g., <code>/home/user/prompts/agents.py</code> or <code>Path(__file__).parent / 'agents.py'</code>) to avoid issues with working directory changes.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#global-context-for-all-agents","level":2,"title":"Global context for all agents","text":"<p>Add domain knowledge visible to all agents:</p> Global template overrides<pre><code>global_context = \"\"\"\n{{ super() }}\n\nDomain knowledge:\n\n- Inversions occur when temperature increases with altitude\n- Standard lapse rate is 6.5¬∞C per km\n\"\"\"\n\n# Apply to base Actor class\nlmai.actor.Actor.template_overrides = {\n    \"main\": {\n        \"global\": global_context\n    }\n}\n\nui = lmai.ExplorerUI(data='weather.csv')\nui.servable()\n</code></pre>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#debug-prompts","level":2,"title":"Debug prompts","text":"<p>See what the LLM receives:</p> Enable debug logging<pre><code>ui = lmai.ExplorerUI(data='penguins.csv', log_level='DEBUG')\nui.servable()\n</code></pre> <p>Check console for full prompts sent to the LLM.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#advanced-override-all-blocks","level":2,"title":"Advanced: Override All Blocks","text":"<p>For complete control over prompt structure:</p> All blocks<pre><code>global_block = \"{{ super() }} Shared across all agents\"\ndatetime_block = \"{{ super() }}\"  # Keep default\ninstructions_block = \"\"\"\n{{ super() }}\n\nAdditional rules here\n\"\"\"\nexamples_block = \"\"\"\n{{ super() }}\n\nMore examples here\n\"\"\"\ntools_block = \"{{ super() }} Tool-specific notes\"\ncontext_block = \"\"\"\n{{ super() }}\n\nDomain-specific knowledge\n\"\"\"\nerrors_block = \"{{ super() }} Custom error handling\"\nfooter_block = \"Remember to be concise and accurate.\"\n\ntemplate_overrides = {\n    \"main\": {\n        \"global\": global_block,\n        \"datetime\": datetime_block,\n        \"instructions\": instructions_block,\n        \"examples\": examples_block,\n        \"tools\": tools_block,\n        \"context\": context_block,\n        \"errors\": errors_block,\n        \"footer\": footer_block\n    }\n}\n</code></pre> <p>Don't override auto-populated blocks unnecessarily</p> <p>The <code>datetime</code>, <code>tools</code>, and <code>errors</code> blocks are auto-populated. Only override if you need custom behavior.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#troubleshooting","level":2,"title":"Troubleshooting","text":"<p>Agent ignores instructions - Be more specific. Use examples instead of rules.</p> <p><code>{{ super() }}</code> causes errors - Only use <code>{{ super() }}</code> when the parent block has content. Empty blocks in <code>Actor/main.jinja2</code>: <code>global</code>, <code>instructions</code>, <code>examples</code>, <code>context</code>, <code>footer</code>.</p> <p>Works with one LLM, not another - Different LLMs need different prompt styles. Test with your production model.</p>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/prompts/#best-practices","level":2,"title":"Best practices","text":"<ul> <li>Start with <code>{{ super() }}</code> to keep defaults</li> <li>Be specific: \"Keep responses under 3 sentences\" not \"Be concise\"</li> <li>Use examples over rules</li> <li>Test with <code>log_level='DEBUG'</code></li> <li>Only customize when defaults consistently fail</li> </ul>","path":["Configuration","Prompts"],"tags":[]},{"location":"configuration/reports/","level":1,"title":"Reports","text":"<p>One-click reproducible analytics that combine SQL precision with AI insights.</p> <p>Reports execute a sequence of tasks, pass data between them, and render as interactive documents. Each report can be executed, exported to notebooks, and deployed as a web application.</p>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#quick-start","level":2,"title":"Quick Start","text":"<p>Build your first report in minutes. This example loads a small dataset, composes a <code>Section</code> with a custom <code>Action</code> (for visualization) and a <code>SQLQuery</code> (for aggregation), passes results through shared context, and renders an interactive Vega-Lite chart. Run it locally, export to a notebook, or serve it as a web app.</p> <pre><code>import pandas as pd\nimport panel as pn\n\nfrom lumen.ai.llm import OpenAI\nfrom lumen.ai.report import Action, Report, Section\nfrom lumen.ai.actions import SQLQuery\nfrom lumen.pipeline import Pipeline\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.views import VegaLiteView\n\npn.extension(\"vega\")\n\n\nclass MonthlyRevenue(Action):\n    async def _execute(self, context, **kwargs):\n        df = pd.DataFrame({\"month\": [\"Jan\", \"Feb\", \"Mar\"], \"revenue\": [100000, 125000, 150000]})\n        source = DuckDBSource.from_df(tables={\"q1\": df})\n        pipeline = Pipeline(source=source, table=\"q1\")\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": \"bar\",\n                \"encoding\": {\"x\": {\"field\": \"month\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"revenue\", \"type\": \"quantitative\"}},\n                \"width\": \"container\",\n            },\n            sizing_mode=\"stretch_width\",\n            height=400,\n        )\n        return [chart], {\"source\": source}\n\n\nreport = Report(\n    Section(\n        MonthlyRevenue(title=\"Monthly Revenue\"),\n        SQLQuery(\n            sql_expr=\"\"\"\n            SELECT\n            SUM(CASE WHEN month = 'Jan' THEN revenue ELSE 0 END) AS jan,\n            SUM(CASE WHEN month = 'Feb' THEN revenue ELSE 0 END) AS feb,\n            SUM(CASE WHEN month = 'Mar' THEN revenue ELSE 0 END) AS mar,\n            SUM(revenue) AS total\n            FROM q1\n        \"\"\",\n            table=\"q1_total\",\n            llm=OpenAI(),\n        ),\n        title=\"Q1 Revenue Report\",\n    ),\n    title=\"Sales Report\",\n)\n\nawait report.execute()\nreport.show()\n</code></pre>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#structure","level":2,"title":"Structure","text":"<p>Reports follow a three-level hierarchy:</p> <pre><code>Report (level 1)\n‚îî‚îÄ‚îÄ Section (level 2)\n    ‚îî‚îÄ‚îÄ Task (level 3): Action, ActorTask, or SQLQuery\n</code></pre>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#why-reports","level":2,"title":"Why Reports?","text":"Pain Point How Reports Solve It \"Our weekly metrics are generated manually\" Automate with one-click execution \"Analysis isn't reproducible\" Same inputs ‚Üí same outputs, every time \"Can't share analysis with non-coders\" Export to Jupyter notebooks instantly \"AI analysis is inconsistent\" Combine deterministic SQL with AI insights \"Reports are siloed in notebooks\" Serve as interactive web apps <p>Report is the top-level container with controls to execute, clear, collapse/expand, export, and configure. Section groups related tasks as collapsible accordions. Task is a unit of work.</p>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#task-types","level":2,"title":"Task Types","text":"","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#sqlquery","level":3,"title":"SQLQuery","text":"<p>No custom code needed‚Äîjust SQL:</p> <pre><code>from lumen.ai.actions import SQLQuery\nfrom lumen.ai.llm import OpenAI\nfrom lumen.sources.duckdb import DuckDBSource\n\nsource = DuckDBSource(uri=\"sales.db\")\n\nSQLQuery(\n    source=source,\n    table=\"sales_summary\",\n    sql_expr=\"SELECT region, SUM(amount) as total FROM sales GROUP BY region\",\n    title=\"Sales by Region\",\n    llm=OpenAI()  # Required for AI-generated captions\n)\n</code></pre> <p>Outputs <code>source</code>, <code>pipeline</code>, <code>data</code>, <code>metaset</code>, and <code>table</code> to context for downstream tasks.</p>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#action","level":3,"title":"Action","text":"<p>Subclass <code>Action</code> for custom Python logic:</p> <pre><code>from lumen.ai.report import Action\nfrom panel.pane import Markdown\n\nclass MyAction(Action):\n    async def _execute(self, context, **kwargs):\n        result = do_something()\n        return [Markdown(f\"Result: {result}\")], {\"my_result\": result}\n</code></pre> <p>Return <code>(outputs, context_updates)</code>. Use <code>[]</code> for no outputs, <code>{}</code> for no context updates.</p> <p>Example:</p> <pre><code>import panel as pn\nfrom lumen.ai.report import Action, Report, Section\nfrom lumen.ai.editors import LumenEditor\nfrom lumen.pipeline import Pipeline\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.views.base import VegaLiteView\n\npn.extension(\"tabulator\", \"vega\")\n\nclass LoadDataAction(Action):\n    async def _execute(self, context, **kwargs):\n        source = DuckDBSource(tables={\"penguins\": \"https://datasets.holoviz.org/penguins/v1/penguins.csv\"})\n        pipeline = Pipeline(source=source, table=\"penguins\")\n        return [pipeline.__panel__()], {\"source\": source}\n\nclass AnalyzeAction(Action):\n    async def _execute(self, context, **kwargs):\n        source = context[\"source\"]\n        avg_source = source.create_sql_expr_source(\n            tables={\"avg_data\": \"SELECT species, AVG(CAST(NULLIF(body_mass_g, 'NA') AS DOUBLE)) AS avg_mass FROM penguins GROUP BY species\"}\n        )\n        pipeline = Pipeline(source=avg_source, table=\"avg_data\")\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": \"bar\",\n                \"encoding\": {\n                    \"x\": {\"field\": \"species\", \"type\": \"nominal\"},\n                    \"y\": {\"field\": \"avg_mass\", \"type\": \"quantitative\"},\n                },\n            },\n            sizing_mode=\"stretch_width\",\n        )\n        return [LumenEditor(component=chart, title=\"Avg Body Mass by Species\")], {}\n\nreport = Report(\n    Section(LoadDataAction(title=\"Load\"), AnalyzeAction(title=\"Analyze\"), title=\"Penguins\")\n)\nreport.show()\n</code></pre>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#actortask","level":3,"title":"ActorTask","text":"<p>Wrap any Agent for LLM-powered analysis:</p> <pre><code>from lumen.ai.report import ActorTask\nfrom lumen.ai.agents import SQLAgent, ChatAgent\n\nSection(\n    ActorTask(SQLAgent(), title=\"Query\", instruction=\"Get sales by region\"),\n    ActorTask(ChatAgent(), title=\"Summarize\", instruction=\"Explain the trends\"),\n)\n</code></pre> <pre><code>from lumen.ai.report import ActorTask, Report, Section\nfrom lumen.ai.agents import SQLAgent, VegaLiteAgent\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.ai.schemas import get_metaset\nfrom lumen.ai.llm import OpenAI\n\nllm = OpenAI()\nsource = DuckDBSource(tables={\"penguins\": \"https://datasets.holoviz.org/penguins/v1/penguins.csv\"})\nmetaset = await get_metaset([source], tables=source.get_tables())\n\nreport = Report(\n    Section(\n        ActorTask(\n            SQLAgent(llm=llm),\n            title=\"Query Data\",\n            instruction=\"Get average body mass by species\",\n            context={\"source\": source, \"sources\": [source], \"metaset\": metaset}\n        ),\n        ActorTask(\n            VegaLiteAgent(llm=llm),\n            instruction=\"Create a bar chart of the results\",\n            context={},\n        ),\n        title=\"Analysis\",\n    )\n)\nawait report.execute()\nreport.show()\n</code></pre>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#choosing-the-right-type","level":3,"title":"Choosing the Right Type","text":"Scenario Use Known SQL query <code>SQLQuery</code> ‚Äî fastest, no LLM call Natural language ‚Üí SQL <code>ActorTask</code> + <code>SQLAgent</code> Interpretation, summaries <code>ActorTask</code> + <code>ChatAgent</code> Custom Python logic <code>Action</code>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#best-practices","level":2,"title":"Best Practices","text":"<p>Action granularity: Group by analytical question, not output type. One action can return multiple outputs (table + chart + summary).</p> <p>Section organization: Each section answers one business question. Keep 2-5 related tasks per section.</p> <p>Context flow: Pass derived metrics, not just raw data. Use descriptive keys (<code>total_revenue</code> not <code>val</code>).</p> <p>AI instructions: Be specific about format and scope:</p> <pre><code># ‚ùå Vague\nActorTask(ChatAgent(), instruction=\"Analyze the data\")\n\n# ‚úÖ Specific\nActorTask(ChatAgent(), instruction=\"\"\"\nBased on the metrics above:\n1. Top 3 trends (bullet points)\n2. Top 3 risks (High/Medium/Low)\nKeep under 200 words.\n\"\"\")\n</code></pre> <p>Error handling: Use <code>abort_on_error=True</code> (default) for dependent tasks, <code>abort_on_error=False</code> for independent analyses that shouldn't block each other.</p> <p>Performance: Prefer <code>SQLQuery</code> over <code>ActorTask</code> for known queries. Use <code>prepare()</code> for expensive one-time setup.</p>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#context","level":2,"title":"Context","text":"<p>Tasks communicate through a shared context dictionary.</p> <p>Declaring dependencies with schemas:</p> <pre><code>from lumen.ai.context import ContextModel\nfrom typing import NotRequired\n\nclass MyInputs(ContextModel):\n    pipeline: object        # Required\n    sql: NotRequired[str]   # Optional\n\nclass MyAction(Action):\n    input_schema = MyInputs\n\n    async def _execute(self, context, **kwargs):\n        pipeline = context[\"pipeline\"]\n        return [], {}\n</code></pre> <p>Invalidation: When a task's output changes, downstream tasks automatically re-run. Manually invalidate with <code>report.invalidate([\"key\"])</code>.</p>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#running-and-exporting","level":2,"title":"Running and Exporting","text":"<p>UI controls: Execute (‚ñ∂), Clear (‚úï), Collapse/Expand, Export (‚Üì), Settings (‚öô)</p> <p>Run locally:</p> <pre><code>report.show(port=5006)\n</code></pre> <p>Deploy:</p> <pre><code>report.servable()\n</code></pre> <p>Export to notebook:</p> <pre><code>await report.execute()\nwith open(\"report.ipynb\", \"w\") as f:\n    f.write(report.to_notebook())\n</code></pre> <p>Validate before running:</p> <pre><code>from lumen.ai.context import ContextError\n\ntry:\n    report.validate(context={\"source\": my_source})\nexcept ContextError as e:\n    print(f\"Missing dependencies: {e}\")\n</code></pre>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#modifying-reports","level":2,"title":"Modifying Reports","text":"<pre><code>section.append(NewAction())\nsection.insert(0, FirstAction())\nsection.remove(old_action)\nreport1.merge(report2)\n</code></pre>","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#lifecycle-methods","level":2,"title":"Lifecycle Methods","text":"Method Purpose <code>prepare(context)</code> Async setup before first execution <code>_execute(context)</code> Your implementation <code>reset()</code> Clear outputs <code>cleanup()</code> Final cleanup on removal","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/reports/#troubleshooting","level":2,"title":"Troubleshooting","text":"Problem Solution \"Task has unmet requirements\" Add a task that provides the required context key, or mark field as <code>NotRequired</code> Context not updating Return a tuple: <code>return [output], {\"key\": value}</code> Notebook export fails Call <code>execute()</code> before <code>to_notebook()</code> SQLQuery shows no caption Pass an <code>llm</code> parameter","path":["Configuration","Reports"],"tags":[]},{"location":"configuration/sources/","level":1,"title":"Data Sources","text":"<p>Connect Lumen to files, databases, or data warehouses.</p> <p>See also: Navigating the UI ‚Äî Learn how to manage data sources from the interface.</p>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#quick-start","level":2,"title":"Quick start","text":"Load a file<pre><code>lumen-ai serve penguins.csv\n</code></pre> <p>Works with CSV, Parquet, JSON, and URLs.</p> Multiple files<pre><code>lumen-ai serve penguins.csv earthquakes.parquet\n</code></pre> In Python<pre><code>import lumen.ai as lmai\n\nui = lmai.ExplorerUI(data=['penguins.csv', 'earthquakes.parquet'])\nui.servable()\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#supported-sources","level":2,"title":"Supported sources","text":"Source Use for Files CSV, Parquet, JSON (local or URL) DuckDB Local SQL queries on files Snowflake Cloud data warehouse BigQuery Google's data warehouse PostgreSQL PostgreSQL via SQLAlchemy MySQL MySQL via SQLAlchemy SQLite SQLite via SQLAlchemy Oracle Oracle via SQLAlchemy MSSQL Microsoft SQL Server via SQLAlchemy Intake Data catalogs","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#database-connections","level":2,"title":"Database connections","text":"","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#snowflake","level":3,"title":"Snowflake","text":"Snowflake with SSO<pre><code>from lumen.sources.snowflake import SnowflakeSource\nimport lumen.ai as lmai\n\nsource = SnowflakeSource(\n    account='your-account',\n    database='your-database',\n    authenticator='externalbrowser',  # SSO\n)\n\nui = lmai.ExplorerUI(data=source)\nui.servable()\n</code></pre> <p>Authentication options:</p> <ul> <li><code>authenticator='externalbrowser'</code> - SSO (recommended)</li> <li><code>authenticator='snowflake'</code> - Username/password (needs <code>password=</code>)</li> <li><code>authenticator='oauth'</code> - OAuth token (needs <code>token=</code>)</li> </ul> <p>Select specific tables:</p> <pre><code>source = SnowflakeSource(\n    account='your-account',\n    database='your-database',\n    tables=['CUSTOMERS', 'ORDERS']\n)\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#bigquery","level":3,"title":"BigQuery","text":"BigQuery connection<pre><code>from lumen.sources.bigquery import BigQuerySource\n\nsource = BigQuerySource(\n    project_id='your-project-id',\n    tables=['dataset.table1', 'dataset.table2']\n)\n\nui = lmai.ExplorerUI(data=source)\nui.servable()\n</code></pre> <p>Authentication:</p> <pre><code>gcloud auth application-default login\n</code></pre> <p>Or set service account:</p> <pre><code>export GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/service-account.json\"\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#postgresql","level":3,"title":"PostgreSQL","text":"PostgreSQL via SQLAlchemy<pre><code>from lumen.sources.sqlalchemy import SQLAlchemySource\n\nsource = SQLAlchemySource(\n    url='postgresql://user:password@localhost:5432/database'\n)\n\nui = lmai.ExplorerUI(data=source)\nui.servable()\n</code></pre> <p>Or use individual parameters:</p> <pre><code>source = SQLAlchemySource(\n    drivername='postgresql+psycopg2',\n    username='user',\n    password='password',\n    host='localhost',\n    port=5432,\n    database='mydb'\n)\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#mysql","level":3,"title":"MySQL","text":"MySQL connection<pre><code>from lumen.sources.sqlalchemy import SQLAlchemySource\n\nsource = SQLAlchemySource(\n    url='mysql+pymysql://user:password@localhost:3306/database'\n)\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#sqlite","level":3,"title":"SQLite","text":"SQLite file<pre><code>from lumen.sources.sqlalchemy import SQLAlchemySource\n\nsource = SQLAlchemySource(url='sqlite:///data.db')\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#advanced-file-handling","level":2,"title":"Advanced file handling","text":"","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#duckdb-for-sql-on-files","level":3,"title":"DuckDB for SQL on files","text":"<p>Run SQL directly on CSV/Parquet files:</p> SQL on files<pre><code>from lumen.sources.duckdb import DuckDBSource\n\nsource = DuckDBSource(\n    tables={\n        'penguins': 'penguins.csv',\n        'quakes': \"read_csv('https://earthquake.usgs.gov/data.csv')\",\n    }\n)\n</code></pre> <p>Load remote files:</p> Remote files with DuckDB<pre><code>source = DuckDBSource(\n    tables=['https://datasets.holoviz.org/penguins/v1/penguins.csv'],\n    initializers=[\n        'INSTALL httpfs;',\n        'LOAD httpfs;'\n    ]  # (1)!\n)\n</code></pre> <ol> <li>Required for HTTP/S3 access</li> </ol>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#multiple-sources","level":3,"title":"Multiple sources","text":"Mix sources<pre><code>from lumen.sources.snowflake import SnowflakeSource\nfrom lumen.sources.duckdb import DuckDBSource\n\nsnowflake = SnowflakeSource(account='...', database='...')\nlocal = DuckDBSource(tables=['local.csv'])\n\nui = lmai.ExplorerUI(data=[snowflake, local])\nui.servable()\n</code></pre>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#custom-table-names","level":3,"title":"Custom table names","text":"Rename tables<pre><code>source = DuckDBSource(\n    tables={\n        'customers': 'customer_data.csv',  # (1)!\n        'orders': 'order_history.parquet',\n    }\n)\n</code></pre> <ol> <li>Use 'customers' instead of 'customer_data.csv' in queries</li> </ol>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#troubleshooting","level":2,"title":"Troubleshooting","text":"<p>\"Table not found\" - Table names are case-sensitive. Check exact names.</p> <p>\"Connection failed\" - Verify credentials and network access.</p> <p>\"File not found\" - Use absolute paths or URLs. Relative paths are relative to where you run the command.</p> <p>Slow queries - If using DuckDB on files, it's fast. Slowness usually comes from the database or network, not Lumen.</p>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/sources/#best-practices","level":2,"title":"Best practices","text":"<p>Start with files for development. Move to databases for production.</p> <p>Use URLs for shared datasets that don't change often.</p> <p>Limit tables when possible - faster planning and lower LLM costs.</p> <p>Name tables clearly - Use meaningful names instead of generic file names.</p>","path":["Configuration","Data Sources"],"tags":[]},{"location":"configuration/tools/","level":1,"title":"Tools","text":"<p>Tools let agents access external data and perform specialized tasks.</p> <p>Most users don't need custom tools. Built-in tools handle common needs.</p> <p>See also: Agents ‚Äî Agents invoke tools when needed. For more complex logic, you may want to create a custom agent instead.</p>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#built-in-tools","level":2,"title":"Built-in tools","text":"<p>Lumen includes tools automatically:</p> <ul> <li>TableLookup - Finds relevant tables in your data (see Vector Stores)</li> <li>DocumentLookup - Searches uploaded documents (see Vector Stores)</li> <li>DbtslLookup - Queries dbt Semantic Layer metrics</li> </ul> <p>You don't need to configure these. Agents use them when needed.</p>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#create-a-simple-tool","level":2,"title":"Create a simple tool","text":"<p>If you require a custom tool, e.g. either to provide additional context, render some output or perform some action simply provide a function with type annotations and a docstring:</p> Simple function tool<pre><code>import lumen.ai as lmai\n\ndef calculate_average(numbers: list[float]) -&gt; float:\n    \"\"\"\n    Calculate the average of a list of numbers.\n\n    Parameters\n    ----------\n    numbers : list[float]\n        Numbers to average\n\n    Returns\n    -------\n    float\n        The average\n    \"\"\"\n    return sum(numbers) / len(numbers)\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[calculate_average]  # (1)!\n)\nui.servable()\n</code></pre> <ol> <li>Function automatically becomes a tool - the LLM uses your docstring and type hints</li> </ol> <p>Lumen can now call this function by filling in the arguments. The return value is surfaced to the model, and only added to context if <code>provides</code> is set.</p>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#define-a-tool-with-metadata","level":2,"title":"Define a tool with metadata","text":"<p>Some tools require access to the current context, e.g. to access the current data. To declare that a particular argument should be looked up in the context you can use the <code>define_tool</code> decorator to annotate the function, ensuring the <code>FunctionTool</code> can populate <code>requires</code>, <code>provides</code>, and <code>purpose</code>.</p> <p>As an example we can define a function that accept the <code>pipeline</code> and counts the number of rows in the table:</p> Tool annotations<pre><code>import lumen.ai as lmai\nfrom lumen.ai.tools import define_tool\n\n@define_tool(\n    requires=[\"pipeline\"],\n    purpose=\"Count rows in the active table\"\n)\ndef count_rows(pipeline) -&gt; int:\n    \"\"\"Count total rows in the current table.\"\"\"\n    return len(pipeline.data)\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[count_rows]\n)\nui.servable()\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#render-tool-output","level":2,"title":"Render tool output","text":"<p>If your tool returns a value you want to render directly, set <code>render_output=True</code>:</p> Render tool output<pre><code>import lumen.ai as lmai\nfrom panel_material_ui import Card\nfrom lumen.ai.tools import define_tool\n\n@define_tool(render_output=True, purpose=\"Show a greeting card\")\ndef greeting() -&gt; Card:\n    return Card(\n        \"Hello from Lumen tools!\",\n        title=\"Greeting\",\n        collapsed=True\n    )\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[greeting]\n)\nui.servable()\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#explicit-functiontool-definition","level":2,"title":"Explicit <code>FunctionTool</code> definition","text":"<p>You may also explicitly define a <code>FunctionTool</code> instance:</p> Tool with context access<pre><code>from lumen.ai.tools import FunctionTool\n\ndef filter_penguins(table) -&gt; dict:\n    \"\"\"\n    Filter penguins by bill length.\n\n    Parameters\n    ----------\n    table : pd.DataFrame\n        The penguin data\n\n    Returns\n    -------\n    dict\n        Filtered data and summary\n    \"\"\"\n    filtered = table[table['bill_length_mm'] &gt; 40]\n    return {\n        \"filtered_table\": filtered,\n        \"summary\": f\"Found {len(filtered)} penguins with bill length &gt; 40mm\"\n    }\n\ntool = FunctionTool(\n    function=filter_penguins,\n    requires=[\"table\"],              # (1)!\n    provides=[\"filtered_table\", \"summary\"],  # (2)!\n    purpose=\"Filter penguins by bill length\"\n)\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[tool]\n)\nui.servable()\n</code></pre> <ol> <li>Tool reads <code>table</code> from context</li> <li>Tool adds <code>filtered_table</code> and <code>summary</code> to context (function must return a dict with those keys)</li> </ol>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#tool-that-calls-an-api","level":2,"title":"Tool that calls an API","text":"<p>Wrap external services:</p> API tool<pre><code>def fetch_weather(location: str) -&gt; str:\n    \"\"\"\n    Get current weather for a location.\n\n    Parameters\n    ----------\n    location : str\n        City name\n\n    Returns\n    -------\n    str\n        Weather description\n    \"\"\"\n    import requests\n    response = requests.get(f\"https://api.weather.gov/...\")\n    return f\"Weather: {response.json()['temp']}¬∞F\"\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[fetch_weather]\n)\nui.servable()\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#complete-example-data-validation","level":2,"title":"Complete example: Data validation","text":"Data quality tool<pre><code>import pandas as pd\nfrom lumen.ai.tools import FunctionTool\n\ndef validate_quality(table: pd.DataFrame) -&gt; dict:\n    \"\"\"\n    Check data quality and report issues.\n\n    Parameters\n    ----------\n    table : pd.DataFrame\n        Data to validate\n\n    Returns\n    -------\n    dict\n        Validation report\n    \"\"\"\n    missing = table.isnull().sum().sum()\n    duplicates = table.duplicated().sum()\n\n    issues = []\n    if missing &gt; 0:\n        issues.append(f\"{missing} missing values\")\n    if duplicates &gt; 0:\n        issues.append(f\"{duplicates} duplicate rows\")\n\n    return {\n        \"total_rows\": len(table),\n        \"issues\": issues,\n        \"status\": \"‚úì Clean\" if not issues else \"‚ö†Ô∏è Issues found\"\n    }\n\ntool = FunctionTool(\n    function=validate_quality,\n    requires=[\"table\"],\n    provides=[\"data_quality_report\"],\n    purpose=\"Validate data quality and report issues\"\n)\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[tool]\n)\nui.servable()\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#tool-components","level":2,"title":"Tool components","text":"<p><code>requires</code> - Context keys the tool needs:</p> <pre><code>requires=[\"table\", \"sql\"]  # Tool receives these from context\n</code></pre> <p><code>provides</code> - Context keys the tool creates (for a single key, a non-dict return value is wrapped):</p> <pre><code>provides=[\"summary\", \"report\"]  # Tool adds these to context\n</code></pre> <p><code>purpose</code> - Description for the LLM:</p> <pre><code>purpose=\"Validates data quality and finds issues\"\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#multiple-tools","level":2,"title":"Multiple tools","text":"<p>Combine tools for complex workflows:</p> With built-in toolsOnly custom tools Mix custom and built-in tools<pre><code>from lumen.ai.tools import DocumentLookup\n\ndef get_stats(table) -&gt; dict:\n    \"\"\"Calculate summary statistics.\"\"\"\n    return {\n        \"min\": table['bill_length_mm'].min(),\n        \"max\": table['bill_length_mm'].max(),\n        \"mean\": table['bill_length_mm'].mean(),\n    }\n\ndef filter_species(table, species: str) -&gt; dict:\n    \"\"\"Filter by species name.\"\"\"\n    filtered = table[table['species'] == species]\n    return {\n        \"filtered\": filtered,\n        \"count\": len(filtered)\n    }\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[get_stats, filter_species, DocumentLookup()]\n)\nui.servable()\n</code></pre> Multiple custom tools<pre><code>def tool_a(data: list) -&gt; dict:\n    \"\"\"Process data.\"\"\"\n    return {\"result_a\": processed}\n\ndef tool_b(data: list) -&gt; dict:\n    \"\"\"Analyze data.\"\"\"\n    return {\"result_b\": analyzed}\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[tool_a, tool_b]\n)\nui.servable()\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#best-practices","level":2,"title":"Best practices","text":"","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#write-clear-docstrings","level":3,"title":"Write clear docstrings","text":"Good docstring format<pre><code>def my_tool(data: list) -&gt; str:\n    \"\"\"\n    One-line summary of what it does.\n\n    Detailed explanation if needed.\n\n    Parameters\n    ----------\n    data : list\n        What the data represents\n\n    Returns\n    -------\n    str\n        What gets returned\n    \"\"\"\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#use-type-hints","level":3,"title":"Use type hints","text":"Type hints help the LLM<pre><code>def process(numbers: list[float], threshold: int) -&gt; dict:\n    \"\"\"Type hints help the LLM call correctly.\"\"\"\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#name-parameters-clearly","level":3,"title":"Name parameters clearly","text":"<pre><code># Good\ndef calculate_average(numbers: list[float]) -&gt; float:\n\n# Bad\ndef calculate(x: list[float]) -&gt; float:\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#keep-tools-focused","level":3,"title":"Keep tools focused","text":"<pre><code># Good - one task\ndef validate_email(email: str) -&gt; bool:\n\n# Bad - too many tasks\ndef validate_and_process_user_data(data: dict):\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#return-structured-data-when-using-provides","level":3,"title":"Return structured data when using provides","text":"<p>Match provides with return keys</p> <p>When using <code>provides</code>, your function must return a dict with those keys:</p> <pre><code>tool = FunctionTool(\n    function=my_function,\n    provides=[\"result\", \"metadata\"]  # These keys must be in return dict\n)\n\ndef my_function(data):\n    return {\n        \"result\": processed_data,\n        \"metadata\": {\"count\": 10}\n    }  # ‚úÖ Has both \"result\" and \"metadata\"\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#handle-errors-gracefully","level":3,"title":"Handle errors gracefully","text":"Return error dictReturn error string Structured error handling<pre><code>def process(data: list) -&gt; dict:\n    if not data:\n        return {\"error\": \"No data provided\"}\n\n    try:\n        result = sum(data) / len(data)\n        return {\"average\": result}\n    except Exception as e:\n        return {\"error\": str(e)}\n</code></pre> Simple error handling<pre><code>def process(data: list) -&gt; str:\n    if not data:\n        return \"Error: No data provided\"\n\n    try:\n        result = sum(data) / len(data)\n        return f\"Average: {result:.2f}\"\n    except Exception as e:\n        return f\"Error: {e}\"\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#when-to-use-tools-vs-agents","level":2,"title":"When to use tools vs agents","text":"Use tools when Use agents when Simple function call Complex prompting needed No async/await needed Multiple LLM calls required Wrapping external API Multi-step reasoning needed Straightforward logic Sophisticated error handling","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#troubleshooting","level":2,"title":"Troubleshooting","text":"","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#tool-never-gets-called","level":3,"title":"Tool never gets called","text":"<p>The coordinator doesn't think the tool is relevant. Make the <code>purpose</code> clear and specific:</p> <pre><code># Bad\npurpose = \"Does stuff with data\"\n\n# Good\npurpose = \"Validates email addresses and returns True if valid\"\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#missing-required-argument","level":3,"title":"Missing required argument","text":"<p>Tool expects a context key that doesn't exist. Ensure <code>requires</code> lists correct keys:</p> <pre><code>tool = FunctionTool(\n    function=my_function,\n    requires=[\"table\"],  # Must exist in context\n)\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#tool-fails-silently","level":3,"title":"Tool fails silently","text":"<p>Add error handling and return error messages instead of raising exceptions:</p> <pre><code>def my_tool(data):\n    try:\n        # Your logic\n        return result\n    except Exception as e:\n        return {\"error\": str(e)}\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#keyerror-when-using-provides","level":3,"title":"KeyError when using provides","text":"<p>Common mistake with provides</p> <p>Your function must return a dict with all keys listed in <code>provides</code>:</p> <pre><code># Wrong - returns a string but provides expects dict keys\nprovides=[\"summary\", \"count\"]\n\ndef bad_tool(data):\n    return \"Summary text\"  # ‚ùå\n\n# Correct - returns dict with expected keys\nprovides=[\"summary\", \"count\"]\n\ndef good_tool(data):\n    return {\n        \"summary\": \"Summary text\",\n        \"count\": len(data)\n    }  # ‚úÖ\n</code></pre>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/tools/#see-also","level":2,"title":"See also","text":"<ul> <li>Vector Stores - Configure document search and table discovery tools</li> <li>Embeddings - Configure semantic search for tools</li> <li>Agents - When to use agents instead of tools</li> </ul>","path":["Configuration","Tools"],"tags":[]},{"location":"configuration/ui/","level":1,"title":"User Interface","text":"<p>Configure the Lumen AI chat interface.</p>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#chatui-vs-explorerui","level":2,"title":"ChatUI vs ExplorerUI","text":"<p>Lumen provides two interfaces:</p> <ul> <li>ExplorerUI - Split view with table explorer, multiple explorations, and a navigation tree. Best for most use cases.</li> <li>ChatUI - Simple chat-only interface. Best for embedded applications.</li> </ul> <p>Use <code>ExplorerUI</code> unless you specifically need the simpler ChatUI.</p>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#basic-configuration","level":2,"title":"Basic configuration","text":"Minimal setup<pre><code>import lumen.ai as lmai\n\nui = lmai.ExplorerUI(data='penguins.csv')\nui.servable()\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#common-parameters","level":2,"title":"Common parameters","text":"","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#load-data","level":3,"title":"Load data","text":"Multiple sources<pre><code>ui = lmai.ExplorerUI(data=['customers.csv', 'orders.csv'])\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#configure-llm","level":3,"title":"Configure LLM","text":"Change provider<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    llm=lmai.llm.Anthropic()\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#add-agents","level":3,"title":"Add agents","text":"Custom agents<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    agents=[MyCustomAgent()]  # Adds to 8 default agents\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#add-tools","level":3,"title":"Add tools","text":"Custom tools<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    tools=[my_function]  # Functions become tools automatically\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#change-title","level":3,"title":"Change title","text":"Custom title<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    title='Sales Analytics'\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#custom-suggestions","level":3,"title":"Custom suggestions","text":"Quick action buttons<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    suggestions=[\n        (\"search\", \"What data is available?\"),\n        (\"bar_chart\", \"Show trends\"),\n    ]  # (1)!\n)\n</code></pre> <ol> <li>Tuples of (Material icon name, button text)</li> </ol>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#advanced-parameters","level":2,"title":"Advanced parameters","text":"","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#enable-chat-logging","level":3,"title":"Enable chat logging","text":"Log conversations<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    logs_db_path='logs.db'  # SQLite database for all messages\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#configure-coordinator","level":3,"title":"Configure coordinator","text":"Coordinator options<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    coordinator_params={\n        'verbose': True,\n        'validation_enabled': False\n    }\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#custom-file-handlers","level":3,"title":"Custom file handlers","text":"Handle custom file types<pre><code>def handle_hdf5(file_bytes, alias, filename):\n    # Process file and add to source\n    return True\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    table_upload_callbacks={'hdf5': handle_hdf5}\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#provide-initial-context","level":3,"title":"Provide initial context","text":"Pre-populate context<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    context={'company': 'Acme', 'year': 2024}  # (1)!\n)\n</code></pre> <ol> <li>Available to all agents</li> </ol>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#custom-notebook-export","level":3,"title":"Custom notebook export","text":"Add preamble to exports<pre><code>ui = lmai.ExplorerUI(\n    data='penguins.csv',\n    notebook_preamble='# Analysis by Data Team\\n# Generated: 2024'\n)\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#custom-source-controls","level":3,"title":"Custom source controls","text":"<p>Source controls provide UI interfaces for loading data from external services.</p> <p>Controls let users interactively fetch data from APIs, databases, or specialized sources directly in the Lumen UI sidebar. They're essential for integrating external data that isn't available as static files or database connections.</p> <p>Why use source controls?</p> <p>Source controls solve common data integration challenges:</p> <ul> <li>External APIs - Fetch data from REST APIs that require parameters or authentication</li> <li>User selection - Let users pick data subsets (years, regions, variables) before loading</li> <li>Dynamic data - Access real-time or frequently updated data sources</li> <li>Complex workflows - Handle multi-step data fetching and transformation</li> <li>Authentication - Manage API keys or credentials securely</li> </ul> <p>Built-in controls</p> Control Use for <code>UploadControls</code> Uploading local files (CSV, Excel, etc.) <code>DownloadControls</code> Fetching data from URLs or building custom controls <p>Key components</p> <p>Inherited from <code>BaseSourceControls</code></p> Component Purpose <code>_error_placeholder</code> Show error messages <code>_message_placeholder</code> Show success messages <code>_progress_bar</code> Loading indicator (or use <code>loading=True</code> on layout) <code>_progress_description</code> Progress text <code>_count</code> Counter for unique source names <code>outputs</code> Dict to store created sources <p>Required implementation steps</p> <ol> <li>Define parameters - Use <code>param</code> types for user inputs</li> <li>Build UI - Create widgets with Panel or Material-UI components</li> <li>Fetch data - Use <code>asyncio.to_thread()</code> for blocking API calls</li> <li>Register source - Create DuckDB source with <code>from_df()</code> </li> <li>Update outputs - Set <code>outputs</code> dict and trigger events</li> </ol> <p>Complete minimal example</p> <pre><code>import asyncio\nimport pandas as pd\nimport panel as pn\nimport param\nimport lumen.ai as lmai\nfrom datetime import date, timedelta\nfrom lumen.ai.controls import DownloadControls\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.util import normalize_table_name\nfrom panel_material_ui import Button, DatePicker, Column\n\npn.extension()\n\n\nclass WeatherControl(DownloadControls):\n    \"\"\"Fetch weather data from Iowa Environmental Mesonet.\"\"\"\n\n    start_date = param.Date(default=date.today() - timedelta(days=7))\n    end_date = param.Date(default=date.today())\n\n    label = '&lt;span class=\"material-icons\"&gt;wb_sunny&lt;/span&gt; Weather Data'\n\n    def __init__(self, **params):\n        super().__init__(**params)\n\n        self._start_picker = DatePicker.from_param(\n            self.param.start_date, \n            label=\"Start Date\"\n        )\n        self._end_picker = DatePicker.from_param(\n            self.param.end_date,\n            label=\"End Date\"\n        )\n        self._fetch_button = Button(\n            label=\"Fetch Weather Data\",\n            on_click=self._on_fetch\n        )\n        self._layout = Column(\n            self._start_picker,\n            self._end_picker,\n            self._fetch_button\n        )\n\n    async def _on_fetch(self, event):\n        \"\"\"Fetch weather data from API.\"\"\"\n        with self._layout.param.update(loading=True):\n            await asyncio.sleep(0.01)\n\n            # Build API URL\n            url = (\n                f\"https://mesonet.agron.iastate.edu/cgi-bin/request/daily.py?\"\n                f\"stations=OAK&amp;\"\n                f\"sts={self.start_date.strftime('%Y-%m-%d')}&amp;\"\n                f\"ets={self.end_date.strftime('%Y-%m-%d')}&amp;\"\n                f\"network=CA_ASOS&amp;format=csv\"\n            )\n\n            # Fetch data\n            df = await asyncio.to_thread(pd.read_csv, url)\n\n            if df is not None and not df.empty:\n                await self._add_table(df)\n                self.param.trigger(\"upload_successful\")\n\n    async def _add_table(self, df):\n        \"\"\"Register DataFrame as DuckDB source.\"\"\"\n        table_name = normalize_table_name(\n            f\"weather_{self.start_date}_{self.end_date}\"\n        )\n        source = DuckDBSource.from_df(tables={table_name: df})\n        source.tables[table_name] = f\"SELECT * FROM {table_name}\"\n\n        self.outputs[\"source\"] = source\n        self.outputs[\"sources\"] = self.outputs.get(\"sources\", []) + [source]\n        self.outputs[\"table\"] = table_name\n        self.param.trigger(\"outputs\")\n\n    def __panel__(self):\n        return self._layout\n\n\nui = lmai.ExplorerUI(\n    source_controls=[WeatherControl],\n    title=\"Weather Data Explorer\",\n)\nui.servable()\n</code></pre> <p>This example fetches real weather data from the Iowa Environmental Mesonet for Oakland, CA. Users can select date ranges and immediately query the data with natural language.</p> <p>Best practices</p> <ul> <li>Use <code>asyncio.to_thread()</code> instead of <code>run_in_executor()</code> for blocking calls</li> <li>Show loading state with <code>loading=True</code> on the layout or use progress bars</li> <li>Handle errors gracefully and display messages to users</li> <li>Add metadata to sources to help LLM agents understand the data</li> <li>Validate inputs before making expensive API calls</li> <li>Cache API responses when possible to avoid redundant calls</li> <li>Normalize table names with <code>normalize_table_name()</code> to ensure DuckDB compatibility</li> <li>Use dynamic table names that include parameters for clarity</li> <li>Bind widgets with <code>from_param()</code> for cleaner code</li> </ul>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#complete-example","level":2,"title":"Complete example","text":"Full configuration<pre><code>import lumen.ai as lmai\nfrom lumen.sources.snowflake import SnowflakeSource\n\nsource = SnowflakeSource(\n    account='acme',\n    database='sales',\n    authenticator='externalbrowser'\n)\n\nllm = lmai.llm.OpenAI(\n    model_kwargs={\n        'default': {'model': 'gpt-4o-mini'},\n        'sql': {'model': 'gpt-4o'},\n    }\n)\n\nanalysis_agent = lmai.agents.AnalysisAgent(analyses=[MyAnalysis])\n\nui = lmai.ExplorerUI(\n    data=source,\n    llm=llm,\n    agents=[analysis_agent],\n    tools=[my_tool],\n    title='Sales Analytics',\n    suggestions=[\n        (\"trending_up\", \"Revenue trends\"),\n        (\"people\", \"Top customers\"),\n    ],\n    log_level='INFO',\n    logs_db_path='logs.db'\n)\n\nui.servable()\n</code></pre>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#all-parameters","level":2,"title":"All parameters","text":"<p>Quick reference:</p> Parameter Type Purpose <code>data</code> str/Path/Source/list Data sources to load <code>llm</code> Llm LLM provider (default: OpenAI) <code>agents</code> list Additional agents <code>analyses</code> list Custom analyses <code>context</code> dict Initial context <code>coordinator</code> type Planner or DependencyResolver <code>coordinator_params</code> dict Coordinator configuration <code>default_agents</code> list Replace default agents <code>demo_inputs</code> list Demo prompts for the coordinator <code>document_vector_store</code> VectorStore Vector store for document tools <code>export_functions</code> dict Map exporter names to export functions <code>interface</code> type Chat interface class <code>llm_choices</code> list LLM model choices shown in Settings <code>log_level</code> str DEBUG/INFO/WARNING/ERROR <code>logfire_tags</code> list Log LLM calls to Logfire with tags <code>logs_db_path</code> str Chat logging database path <code>notebook_preamble</code> str Export header <code>provider_choices</code> dict LLM providers shown in Settings <code>source_controls</code> list Source control components for data <code>suggestions</code> list Quick action buttons <code>title</code> str App title <code>tools</code> list Custom tools <code>upload_handlers</code> dict File extension upload handlers <code>vector_store</code> VectorStore Vector store for non-doc tools <p>See parameter docstrings in code for complete details.</p>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/ui/#see-also","level":3,"title":"See also","text":"<ul> <li>Data Sources ‚Äî File and database connections</li> <li>Tools ‚Äî Custom functions for agents</li> <li>Building a Census Data Explorer ‚Äî Complete walkthrough with minimal and full examples</li> </ul>","path":["Configuration","User Interface"],"tags":[]},{"location":"configuration/vector_stores/","level":1,"title":"Vector Stores","text":"<p>Store and search text using semantic similarity.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#quick-start","level":2,"title":"Quick start","text":"<p>In-memory vector store:</p> Simple vector store<pre><code>from lumen.ai.vector_store import NumpyVectorStore\n\nvector_store = NumpyVectorStore()\nawait vector_store.add_file('documentation.pdf')\n\nresults = await vector_store.query('authentication setup', top_k=3)\n</code></pre> <p>Persistent storage with DuckDB:</p> Persistent vector store<pre><code>from lumen.ai.vector_store import DuckDBVectorStore\n\nvector_store = DuckDBVectorStore(uri='embeddings.db')\nawait vector_store.add_file('documentation.pdf')\n</code></pre> <p>See Embeddings for configuring how text is converted to vectors.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#store-types","level":2,"title":"Store types","text":"","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#numpyvectorstore","level":3,"title":"NumpyVectorStore","text":"<p>In-memory storage using Numpy arrays.</p> <pre><code>from lumen.ai.vector_store import NumpyVectorStore\n\nvector_store = NumpyVectorStore()\n</code></pre> <ul> <li>‚úÖ Fast, simple</li> <li>‚ö†Ô∏è Data lost on restart</li> <li>Best for: Development, testing, small datasets</li> </ul>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#duckdbvectorstore","level":3,"title":"DuckDBVectorStore","text":"<p>Persistent storage with HNSW indexing.</p> <pre><code>from lumen.ai.vector_store import DuckDBVectorStore\n\nvector_store = DuckDBVectorStore(uri='embeddings.db')\n</code></pre> <ul> <li>‚úÖ Persists on disk</li> <li>‚úÖ Scales to millions of documents</li> <li>‚úÖ Fast similarity search</li> <li>Best for: Production, large datasets</li> </ul>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#adding-documents","level":2,"title":"Adding documents","text":"","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#add-files","level":3,"title":"Add files","text":"Add any file<pre><code>await vector_store.add_file('documentation.pdf')\nawait vector_store.add_file('guide.md')\nawait vector_store.add_file('https://example.com/page')  # URLs work too\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#add-directories","level":3,"title":"Add directories","text":"Add all files<pre><code>await vector_store.add_directory(\n    'docs/',\n    pattern='*.md',                  # Only markdown\n    exclude_patterns=['**/draft/*'], # Skip drafts\n    max_concurrent=10                # Process 10 at once\n)\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#add-text","level":3,"title":"Add text","text":"Add text directly<pre><code>await vector_store.add([\n    {\n        'text': 'Lumen is a data exploration framework.',\n        'metadata': {'source': 'intro', 'category': 'overview'}\n    }\n])\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#searching","level":2,"title":"Searching","text":"","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#semantic-search","level":3,"title":"Semantic search","text":"Find similar text<pre><code>results = await vector_store.query(\n    'How do I authenticate users?',\n    top_k=5,        # Top 5 results\n    threshold=0.3   # Min similarity\n)\n\nfor result in results:\n    print(f\"{result['similarity']:.2f}: {result['text']}\")\n</code></pre> <p>Similarity is powered by embeddings - see Embeddings - Providers for quality options.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#filter-by-metadata","level":3,"title":"Filter by metadata","text":"Filter search<pre><code>results = await vector_store.query(\n    'authentication',\n    filters={'category': 'security', 'version': '2.0'}\n)\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#exact-metadata-lookup","level":3,"title":"Exact metadata lookup","text":"Metadata-only search<pre><code>results = vector_store.filter_by(\n    filters={'author': 'admin'},\n    limit=10\n)\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#upsert-prevent-duplicates","level":2,"title":"Upsert (prevent duplicates)","text":"Upsert instead of add<pre><code># First call - adds new item\nawait vector_store.upsert([\n    {'text': 'Hello world', 'metadata': {'source': 'greeting'}}\n])\n\n# Second call - skips (already exists)\nawait vector_store.upsert([\n    {'text': 'Hello world', 'metadata': {'source': 'greeting'}}\n])\n</code></pre> <p>Use <code>upsert()</code> when reprocessing documents that may not have changed.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#management","level":2,"title":"Management","text":"Delete, clear, count<pre><code># Delete by ID\nvector_store.delete([1, 2, 3])\n\n# Clear everything\nvector_store.clear()\n\n# Count documents\nnum_docs = len(vector_store)\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#contextual-augmentation-situate","level":2,"title":"Contextual augmentation (situate)","text":"<p>Add context descriptions to chunks:</p> Enable situate<pre><code>vector_store = DuckDBVectorStore(\n    situate=True,  # Generate context for each chunk\n)\n\nawait vector_store.add_file('long_document.pdf')\n</code></pre> <p>Each chunk gets context like:</p> <p>\"This section discusses OAuth2 authentication. It follows the introduction and references token refresh mechanisms.\"</p> <p>When to use:</p> <ul> <li>‚úÖ Long technical documents, books, research papers</li> <li>‚úÖ Documents with forward/backward references</li> <li>‚ùå Short documents, FAQs, independent chunks</li> </ul> <p>Requires an LLM to generate context - see LLM Providers for configuration.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#integration-with-lumen-ai","level":2,"title":"Integration with Lumen AI","text":"","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#document-search","level":3,"title":"Document search","text":"Enable document search<pre><code>import lumen.ai as lmai\n\nvector_store = DuckDBVectorStore(uri='docs.db')\nawait vector_store.add_directory('documentation/')\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    vector_store=vector_store\n)\nui.servable()\n</code></pre> <p>Users can now ask questions about uploaded documents. See Tools - DocumentLookup for how this works.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#configuration","level":2,"title":"Configuration","text":"","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#custom-embeddings","level":3,"title":"Custom embeddings","text":"Use different embeddings<pre><code>from lumen.ai.embeddings import HuggingFaceEmbeddings\n\nvector_store = DuckDBVectorStore(\n    embeddings=HuggingFaceEmbeddings(model=\"BAAI/bge-small-en-v1.5\")\n)\n</code></pre> <p>See Embeddings - Providers for all embedding options.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#read-only-mode","level":3,"title":"Read-only mode","text":"Read-only access<pre><code>vector_store = DuckDBVectorStore(\n    uri='embeddings.db',\n    read_only=True\n)\n</code></pre>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#chunk-size","level":3,"title":"Chunk size","text":"Control chunking<pre><code>vector_store = DuckDBVectorStore(\n    chunk_size=512  # Smaller chunks\n)\n</code></pre> <p>See Embeddings - Chunk size for chunking strategies.</p>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#best-practices","level":2,"title":"Best practices","text":"<p>Choose the right store:</p> <ul> <li>Development ‚Üí <code>NumpyVectorStore</code></li> <li>Production ‚Üí <code>DuckDBVectorStore</code></li> </ul> <p>Optimize threshold:</p> <ul> <li>Exploratory ‚Üí <code>threshold=0.3</code></li> <li>Precise ‚Üí <code>threshold=0.5</code></li> <li>Very strict ‚Üí <code>threshold=0.7</code></li> </ul> <p>Use upsert for idempotency:</p> <ul> <li>Reprocessing ‚Üí <code>upsert()</code></li> <li>New content ‚Üí <code>add()</code></li> </ul>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/vector_stores/#see-also","level":2,"title":"See also","text":"<ul> <li>Embeddings - Configure how text is converted to vectors</li> <li>Tools - Built-in tools that use vector stores</li> <li>Agents - Agents that leverage document search</li> <li>LLM Providers - Required for situate feature</li> </ul>","path":["Configuration","Vector Stores"],"tags":[]},{"location":"configuration/spec/","level":1,"title":"Lumen YAML Specifications","text":"<p>Build powerful data dashboards using YAML configuration files‚Äîno Python coding required.</p> <p>About Lumen specs and Lumen AI</p> <p>Lumen AI runs on Lumen specs under the hood. When you use Lumen AI to create dashboards, it generates these YAML specifications automatically. Reports created with Lumen AI are fully reproducible using the generated specs.</p> <p>Historically, users wrote these specs manually before LLMs became capable. Now, Lumen AI can generate them for you through natural language conversation. However, understanding specs is still valuable for:</p> <ul> <li>Customizing AI-generated dashboards beyond what the AI created</li> <li>Building dashboards programmatically without the AI interface</li> <li>Version control and reproducibility of your dashboard configurations</li> <li>Advanced features not yet supported by the AI</li> </ul> <p>Choose your approach:</p> <ul> <li>Want AI to build it for you? ‚Üí Use Lumen AI</li> <li>Want to learn the underlying system? ‚Üí Continue reading this guide</li> <li>Want to customize an AI-generated dashboard? ‚Üí Learn specs, then edit the YAML</li> </ul>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#what-are-lumen-specs","level":2,"title":"What are Lumen specs?","text":"<p>Lumen specifications let you build interactive data dashboards by writing YAML configuration instead of code. Define your data sources, transformations, and visualizations declaratively, then deploy with a single command.</p>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#why-use-specs","level":2,"title":"Why use specs?","text":"Benefit Description No coding required Build dashboards using simple YAML syntax Fast iteration Edit YAML, refresh browser‚Äîsee changes instantly Version control friendly Track dashboard changes like any text file Reproducible Share exact dashboard configuration with others Extensible Add Python when you need custom behavior AI-transparent Understand and modify what Lumen AI generates","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#quick-navigation","level":2,"title":"Quick navigation","text":"<p>Choose your path based on experience level:</p>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#new-to-lumen-specs","level":3,"title":"üéØ New to Lumen specs?","text":"<p>Start with the tutorial to build your first dashboard in 15 minutes:</p> <p>Build Dashboard with Spec - Complete hands-on tutorial</p> <p>Then understand the concepts:</p> <ol> <li>Core Concepts - Understand how Lumen specs work</li> <li>Loading Data - Connect to your data sources</li> </ol>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#building-dashboards","level":3,"title":"üí™ Building dashboards?","text":"<p>Guides for common dashboard tasks:</p> Task Guide Load data from files Loading Data Filter and transform data Transforming Data Create plots and tables Visualizing Data Use variables and references Variables &amp; References Enable data downloads Data Downloads","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#advanced-features","level":3,"title":"üöÄ Advanced features?","text":"<p>Extend Lumen with custom functionality:</p> <ul> <li>Custom Components - Build custom sources, transforms, filters, and views</li> <li>Python API - Build dashboards programmatically</li> <li>Authentication - Secure your dashboards</li> </ul>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#ready-to-deploy","level":3,"title":"üõ†Ô∏è Ready to deploy?","text":"<p>Launch your dashboard:</p> <ul> <li>Deployment - Serve dashboards and validate configurations</li> </ul>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#how-lumen-works","level":2,"title":"How Lumen works","text":"<p>Lumen follows a simple three-stage workflow:</p> <pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Sources  ‚îÇ ‚îÄ‚îÄ&gt; ‚îÇ Pipelines ‚îÇ ‚îÄ‚îÄ&gt; ‚îÇ Views  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ‚îÇ                 ‚îÇ                  ‚îÇ\n    ‚îÇ                 ‚îÇ                  ‚îÇ\nLoad data      Filter/transform     Visualize\n</code></pre> <ol> <li>Sources load data from files, databases, or APIs</li> <li>Pipelines filter and transform the data</li> <li>Views display the results as plots, tables, or other visualizations</li> </ol>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#example-dashboard","level":2,"title":"Example dashboard","text":"<p>Here's a complete dashboard specification:</p> <pre><code>config:\n  title: Sales Dashboard\n  theme: dark\n\nsources:\n  sales_data:\n    type: file\n    tables:\n      sales: data/sales.csv\n\npipelines:\n  filtered_sales:\n    source: sales_data\n    table: sales\n    filters:\n      - type: widget\n        field: region\n      - type: widget\n        field: product\n\nlayouts:\n  - title: Sales Overview\n    pipeline: filtered_sales\n    views:\n      - type: hvplot\n        kind: line\n        x: date\n        y: revenue\n      - type: table\n        page_size: 20\n</code></pre> <p>Deploy with one command:</p> <pre><code>lumen serve dashboard.yaml --show\n</code></pre>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#yaml-vs-python","level":2,"title":"YAML vs Python","text":"<p>Lumen offers two approaches to building dashboards:</p> Aspect YAML Python Syntax Simple configuration Python code Learning curve Beginner-friendly Requires Python knowledge Flexibility Good for common patterns Full programmatic control Best for Standard dashboards Complex custom applications Documentation This guide Python API Guide <p>Most users start with YAML and add Python only when needed.</p>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#getting-help","level":2,"title":"Getting help","text":"<ul> <li>Stuck? Check the Deployment guide for validation</li> <li>Need examples? Each guide includes working code samples</li> <li>Want to extend? See the Customization guide</li> </ul>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/#next-steps","level":2,"title":"Next steps","text":"<p>New to specs? Start with the Build Dashboard with Spec tutorial to create your first dashboard in 15 minutes.</p> <p>Returning users? Jump to the guide that matches your current task using the navigation above.</p>","path":["Configuration","Specs","Lumen YAML Specifications"],"tags":[]},{"location":"configuration/spec/authentication/","level":1,"title":"Securing dashboards with authentication","text":"<p>Restrict dashboard access to authorized users.</p> <p>Documentation in progress</p> <p>Detailed authentication documentation is coming soon. For now, see the Panel authentication guide.</p>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#quick-start","level":2,"title":"Quick start","text":"<p>Add basic authentication to your dashboard:</p> <pre><code>config:\n  auth:\n    type: basic\n    users:\n      - alice\n      - bob\n</code></pre>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#authentication-types","level":2,"title":"Authentication types","text":"Type Description Use case <code>basic</code> Username list Simple user restrictions <code>oauth</code> OAuth providers GitHub, Google, Azure AD <code>password</code> Username/password Custom authentication","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#github-oauth-example","level":2,"title":"GitHub OAuth example","text":"<p>Restrict to specific GitHub users:</p> <pre><code>config:\n  auth:\n    type: oauth\n    oauth_provider: github\n    oauth_key: {{ env(\"GITHUB_CLIENT_ID\") }}\n    oauth_secret: {{ env(\"GITHUB_CLIENT_SECRET\") }}\n    authorized_users:\n      - github_username1\n      - github_username2\n</code></pre>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#resources","level":2,"title":"Resources","text":"<p>For complete authentication documentation, see:</p> <ul> <li>Panel Authentication Guide</li> <li>OAuth Setup Guide</li> </ul>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#common-patterns","level":2,"title":"Common patterns","text":"","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#development-vs-production","level":3,"title":"Development vs production","text":"<pre><code>config:\n  auth:\n    type: {{ env(\"AUTH_TYPE\", \"basic\") }}\n    users: {{ env(\"AUTH_USERS\", \"['dev_user']\") }}\n</code></pre> <p>Set different auth for each environment:</p> <pre><code># Development\nexport AUTH_TYPE=basic\nexport AUTH_USERS=\"['alice', 'bob']\"\n\n# Production\nexport AUTH_TYPE=oauth\nexport OAUTH_PROVIDER=github\n</code></pre>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#per-layout-restrictions","level":3,"title":"Per-layout restrictions","text":"<pre><code>layouts:\n  - title: Public Dashboard\n    # No auth required\n    views:\n      - type: table\n\n  - title: Admin Dashboard\n    auth:\n      users: [admin]\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/authentication/#next-steps","level":2,"title":"Next steps","text":"<ul> <li>Panel Authentication Guide - Complete authentication documentation</li> <li>Deployment guide - Deploy secured dashboards</li> <li>Variables guide - Use environment variables for secrets</li> </ul>","path":["Configuration","Specs","Securing dashboards with authentication"],"tags":[]},{"location":"configuration/spec/concepts/","level":1,"title":"Core concepts","text":"<p>Understand how Lumen works to build your own dashboards effectively.</p> <p>Prerequisites</p> <p>Complete the Build Dashboard with Spec tutorial before reading this guide. This page generalizes those concepts so you can apply them to your own data.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#how-lumen-works","level":2,"title":"How Lumen works","text":"<p>Lumen transforms data through three stages:</p> <pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ Sources  ‚îÇ ‚îÄ‚îÄ&gt; ‚îÇ Pipelines ‚îÇ ‚îÄ‚îÄ&gt; ‚îÇ Views  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n     ‚îÇ                 ‚îÇ                  ‚îÇ\n     ‚îÇ                 ‚îÇ                  ‚îÇ\nLoad data      Filter/transform     Visualize\n</code></pre> <ol> <li>Sources load data from files, databases, or APIs</li> <li>Pipelines filter and transform the data (optional)</li> <li>Views display results as plots, tables, or indicators</li> </ol> <p>Configuration settings control the overall dashboard appearance and behavior.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#yaml-vs-python","level":2,"title":"YAML vs Python","text":"<p>Lumen supports two approaches:</p> Aspect YAML Specifications Python API Syntax Simple configuration Python code Learning curve Beginner-friendly Requires Python knowledge Iteration speed Very fast (edit and refresh) Fast (requires restart) Flexibility Good for standard patterns Full programmatic control Best for Most dashboards Complex custom applications Guide This section Python API Guide <p>Most users start with YAML and only switch to Python when they need custom behavior.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#yaml-specification-structure","level":2,"title":"YAML specification structure","text":"<p>A Lumen specification uses YAML syntax. YAML represents data with key: value pairs and lists with leading dashes -. Learn more in the YAML guide.</p> <p>Lumen specifications contain these sections:</p> <pre><code>config:              # Dashboard settings (optional)\n  title: ...\n  theme: ...\n\nsources:             # Data sources (required)\n  source_name:\n    type: ...\n\npipelines:           # Data processing (optional)\n  pipeline_name:\n    source: ...\n    filters: ...\n    transforms: ...\n\nlayouts:             # Visual output (required)\n  - title: ...\n    views:\n      - type: ...\n</code></pre> <p>Required sections: You need at least one source and one layout to create a dashboard.</p> <p>Optional sections: Config and pipelines add functionality but aren't mandatory.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#section-details","level":2,"title":"Section details","text":"","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#config-dashboard-wide-settings","level":3,"title":"Config: Dashboard-wide settings","text":"<p>The <code>config</code> section sets global options that apply to the entire dashboard:</p> <pre><code>config:\n  title: My Dashboard           # Browser title and header\n  layout: tabs                  # Layout mode: tabs, grid, or column\n  logo: assets/my_logo.png      # Custom logo image\n  theme: dark                   # Color scheme: dark, default, etc.\n</code></pre> <p>Common config parameters:</p> Parameter Purpose Example values <code>title</code> Dashboard name \"Sales Dashboard\" <code>theme</code> Color scheme <code>dark</code>, <code>default</code> <code>layout</code> Top-level layout <code>tabs</code>, <code>grid</code>, <code>column</code> <code>logo</code> Custom logo path <code>assets/logo.png</code> <p>Skip the config section to use defaults (light theme, generic title).</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#sources-loading-data","level":3,"title":"Sources: Loading data","text":"<p>The <code>sources</code> section defines where data comes from. Each source has a name and type:</p> <pre><code>sources:\n  my_source:                    # Source name (you choose this)\n    type: file                  # Source type\n    tables:\n      my_table: data.csv        # Table name and location\n</code></pre> <p>Common source types:</p> Type Purpose Example <code>file</code> CSV, Excel, Parquet, JSON files Local or remote files <code>intake</code> Intake catalogs Data catalogs <code>duckdb</code> DuckDB databases SQL queries <code>rest</code> REST APIs API endpoints <p>Example loading a remote CSV:</p> <pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguins: https://datasets.holoviz.org/penguins/v1/penguins.csv\n</code></pre> <p>See the Sources guide for all source types and configuration options.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#pipelines-filtering-and-transforming","level":3,"title":"Pipelines: Filtering and transforming","text":"<p>Pipelines manipulate data before visualization. Use them to filter rows or transform columns:</p> <pre><code>pipelines:\n  processed_data:               # Pipeline name (you choose this)\n    source: my_source           # Which source to use\n    table: my_table             # Which table from that source\n    filters:                    # Filter rows (optional)\n      - type: widget\n        field: category\n    transforms:                 # Transform data (optional)\n      - type: columns\n        columns: [col1, col2]\n</code></pre> <p>Skip pipelines if you want to display raw data without modification.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#filters","level":4,"title":"Filters","text":"<p>Filters let users drill down into data subsets:</p> <pre><code>filters:\n  - type: widget              # Interactive widget filter\n    field: species            # Column to filter on\n  - type: widget\n    field: island\n</code></pre> <p>Common filter types:</p> Type Purpose User control <code>widget</code> Interactive dropdown/slider Yes <code>constant</code> Fixed filter value No <code>facet</code> Split data into groups Yes","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#transforms","level":4,"title":"Transforms","text":"<p>Transforms modify data structure or values:</p> <pre><code>transforms:\n  - type: columns             # Select specific columns\n    columns: [id, name, value]\n  - type: aggregate           # Group and aggregate\n    method: mean\n    by: [category]\n</code></pre> <p>Common transform types:</p> Type Purpose <code>columns</code> Select specific columns <code>aggregate</code> Group and compute statistics <code>sort</code> Order rows <code>query</code> SQL-like filtering <p>See the Pipelines guide for complete filter and transform reference.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#layouts-visualizing-data","level":3,"title":"Layouts: Visualizing data","text":"<p>The <code>layouts</code> section creates the visual dashboard. Each layout contains views:</p> <pre><code>layouts:\n  - title: My Dashboard         # Layout title\n    pipeline: processed_data    # Or use source directly\n    views:                      # List of visualizations\n      - type: hvplot\n        kind: scatter\n        x: bill_length\n        y: bill_depth\n      - type: table\n        page_size: 20\n</code></pre> <p>Link views to data using either:</p> <ul> <li><code>pipeline: pipeline_name</code> - Use processed data</li> <li><code>source: source_name</code> - Use raw data directly</li> </ul>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#view-types","level":4,"title":"View types","text":"<p>Common view types:</p> Type Purpose Use case <code>hvplot</code> Interactive plots Scatter, line, bar, hist, box, etc. <code>table</code> Data tables Displaying tabular data <code>indicator</code> Single metrics KPIs, status indicators <code>download</code> Download buttons Data export <p>Example with multiple views:</p> <pre><code>layouts:\n  - title: Analysis\n    pipeline: my_pipeline\n    layout: [[0], [1, 2]]       # Custom arrangement\n    views:\n      - type: hvplot            # View 0: Scatter plot\n        kind: scatter\n        x: x_col\n        y: y_col\n      - type: hvplot            # View 1: Histogram\n        kind: hist\n        y: x_col\n      - type: table             # View 2: Data table\n        page_size: 20\n</code></pre> <p>The <code>layout</code> parameter controls view arrangement:</p> <ul> <li><code>[[0], [1, 2]]</code> - View 0 on top, views 1 and 2 side-by-side below</li> <li><code>[[0, 1], [2, 3]]</code> - 2x2 grid</li> </ul> <p>See the Views guide for all view types and layout options.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#advanced-sections","level":2,"title":"Advanced sections","text":"","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#defaults-parameter-overrides","level":3,"title":"Defaults: Parameter overrides","text":"<p>Set default values for components throughout your specification:</p> <pre><code>defaults:\n  filters:\n    - type: widget\n      multi: false            # Single-select by default\n  views:\n    - type: hvplot\n      responsive: true        # All plots responsive\n</code></pre> <p>This prevents repetition when many components share settings.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#variables-dynamic-configuration","level":3,"title":"Variables: Dynamic configuration","text":"<p>Create reusable variables that can be referenced anywhere:</p> <pre><code>variables:\n  ticker:\n    type: widget\n    kind: TextInput\n    value: AAPL\n\nsources:\n  stock_data:\n    type: file\n    tables:\n      data: $variables.ticker  # References the variable\n</code></pre> <p>Variables make dashboards dynamic. See the Variables guide.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#authentication","level":3,"title":"Authentication","text":"<p>Restrict dashboard access to authorized users:</p> <pre><code>auth:\n  type: basic\n  users:\n    - alice\n    - bob\n</code></pre> <p>See the Authentication guide for setup details.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#execution-flow","level":2,"title":"Execution flow","text":"<p>Understanding how Lumen executes helps debug issues:</p> <ol> <li>Initialization: Lumen reads your YAML file</li> <li>Source loading: Data loads from configured sources</li> <li>Pipeline execution: </li> <li>Filters apply (based on widget values)</li> <li>Transforms execute in order</li> <li>View rendering: Views display the processed data</li> <li>User interaction: Widget changes trigger re-execution from step 3</li> </ol> <p>Pipeline execution is lazy‚Äîdata only loads when needed for display.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#yaml-syntax-tips","level":2,"title":"YAML syntax tips","text":"","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#indentation-matters","level":3,"title":"Indentation matters","text":"<p>YAML uses whitespace for structure. Use consistent indentation (2 spaces recommended):</p> <pre><code># Correct\nsources:\n  my_source:\n    type: file\n\n# Wrong - inconsistent indentation\nsources:\nmy_source:\n      type: file\n</code></pre>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#lists-use-dashes","level":3,"title":"Lists use dashes","text":"<p>Create lists with leading dashes:</p> <pre><code>filters:\n  - type: widget\n    field: category\n  - type: widget\n    field: region\n</code></pre>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#quotes-for-special-characters","level":3,"title":"Quotes for special characters","text":"<p>Use quotes when values contain special characters:</p> <pre><code>title: \"Sales: Q4 Results\"   # Colon requires quotes\ntable: my-table               # Hyphens are fine without quotes\n</code></pre>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#common-patterns","level":2,"title":"Common patterns","text":"","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#basic-dashboard-source-view","level":3,"title":"Basic dashboard (source + view)","text":"<p>Minimal dashboard showing raw data:</p> <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: data.csv\n\nlayouts:\n  - title: Data\n    source: data\n    views:\n      - type: table\n        table: table\n</code></pre>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#dashboard-with-filtering","level":3,"title":"Dashboard with filtering","text":"<p>Add interactive filters:</p> <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: data.csv\n\npipelines:\n  filtered:\n    source: data\n    table: table\n    filters:\n      - type: widget\n        field: category\n\nlayouts:\n  - title: Filtered Data\n    pipeline: filtered\n    views:\n      - type: hvplot\n        kind: bar\n        x: name\n        y: value\n</code></pre>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#multi-view-dashboard","level":3,"title":"Multi-view dashboard","text":"<p>Show data in multiple ways:</p> <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: data.csv\n\npipelines:\n  processed:\n    source: data\n    table: table\n    filters:\n      - type: widget\n        field: region\n\nlayouts:\n  - title: Dashboard\n    pipeline: processed\n    layout: [[0, 1], [2]]\n    views:\n      - type: hvplot\n        kind: line\n        x: date\n        y: sales\n      - type: hvplot\n        kind: bar\n        x: product\n        y: sales\n      - type: table\n        page_size: 10\n</code></pre>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/concepts/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you understand Lumen's structure:</p> <ol> <li>Sources guide - Learn to load data from different sources</li> <li>Pipelines guide - Master filters and transforms</li> <li>Views guide - Create compelling visualizations</li> <li>Variables guide - Build dynamic dashboards</li> </ol> <p>Building a specific dashboard? Use these concepts as reference while following individual guides for your specific needs.</p>","path":["Configuration","Specs","Core concepts"],"tags":[]},{"location":"configuration/spec/customization/","level":1,"title":"Extending Lumen with custom components","text":"<p>Build custom components and callbacks to extend Lumen's functionality.</p>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#customization-overview","level":2,"title":"Customization overview","text":"<p>Lumen provides two main extension points:</p> Extension Type Purpose Examples Custom components New sources, transforms, filters, or views Custom data source, special transform Callbacks Actions triggered by events Logging, notifications, custom workflows","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#custom-components","level":2,"title":"Custom components","text":"<p>Create custom sources, transforms, filters, or views when built-in components don't meet your needs.</p>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#component-types","level":3,"title":"Component types","text":"<p>You can customize these component types:</p> File Component Type Base Class <code>sources.py</code> Data sources <code>lumen.sources.Source</code> <code>transforms.py</code> Data transforms <code>lumen.transforms.Transform</code> <code>filters.py</code> Data filters <code>lumen.filters.Filter</code> <code>views.py</code> Visualizations <code>lumen.views.View</code>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#two-approaches","level":3,"title":"Two approaches","text":"<p>Approach 1: Automatic imports ‚Äî Save to specific filenames next to your YAML file. Reference by simple name.</p> <p>Approach 2: Module paths ‚Äî Save to custom folders. Reference using dot notation.</p>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#approach-1-automatic-imports","level":2,"title":"Approach 1: Automatic imports","text":"<p>Lumen automatically imports these files if they exist alongside your YAML:</p> <ul> <li><code>sources.py</code></li> <li><code>transforms.py</code></li> <li><code>filters.py</code></li> <li><code>views.py</code></li> </ul>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#example-custom-transform","level":3,"title":"Example: Custom transform","text":"<p>Create <code>transforms.py</code>:</p> <pre><code>import param\nfrom lumen.transforms import Transform\n\nclass StableSort(Transform):\n    \"\"\"Sort using stable algorithm.\"\"\"\n\n    by = param.ListSelector(\n        default=[],\n        doc=\"Columns to sort by\"\n    )\n\n    ascending = param.ClassSelector(\n        default=True,\n        class_=(bool, list),\n        doc=\"Sort ascending vs descending\"\n    )\n\n    transform_type = 'stablesort'  # Name for YAML\n    _field_params = ['by']         # Parameters that accept field names\n\n    def apply(self, table):\n        \"\"\"Apply the transform to data.\"\"\"\n        return table.sort_values(\n            self.by,\n            ascending=self.ascending,\n            kind='stable'\n        )\n</code></pre> <p>Reference in YAML:</p> <pre><code>pipelines:\n  sorted_data:\n    source: my_source\n    table: my_table\n    transforms:\n      - type: stablesort          # Uses your custom transform\n        by: [date, category]\n        ascending: [true, false]\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#example-custom-view","level":3,"title":"Example: Custom view","text":"<p>Create <code>views.py</code>:</p> <pre><code>from lumen.views import View\nimport panel as pn\n\nclass TextEditor(View):\n    \"\"\"Rich text editor view.\"\"\"\n\n    view_type = 'texteditor'       # Name for YAML\n    _extension = 'texteditor'      # Panel extension to load\n\n    def get_panel(self):\n        \"\"\"Return the Panel component.\"\"\"\n        return pn.widgets.TextEditor(**self._get_params())\n\n    def _get_params(self):\n        \"\"\"Get parameters for the widget.\"\"\"\n        return dict(\n            **self.kwargs,\n            sizing_mode='stretch_width',\n            placeholder='Enter some text'\n        )\n</code></pre> <p>Reference in YAML:</p> <pre><code>layouts:\n  - title: Dashboard\n    views:\n      - type: texteditor          # Uses your custom view\n        height: 250\n        placeholder: \"Enter notes here\"\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#example-custom-filter","level":3,"title":"Example: Custom filter","text":"<p>Create <code>filters.py</code>:</p> <pre><code>import param\nfrom lumen.filters import Filter\n\nclass RangeFilter(Filter):\n    \"\"\"Filter for numeric ranges.\"\"\"\n\n    min_value = param.Number(default=0)\n    max_value = param.Number(default=100)\n\n    filter_type = 'range'\n\n    def apply(self, table):\n        \"\"\"Apply the filter.\"\"\"\n        return table[\n            (table[self.field] &gt;= self.min_value) &amp;\n            (table[self.field] &lt;= self.max_value)\n        ]\n</code></pre> <p>Reference in YAML:</p> <pre><code>pipelines:\n  filtered:\n    source: my_source\n    table: my_table\n    filters:\n      - type: range\n        field: price\n        min_value: 10\n        max_value: 1000\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#example-custom-source","level":3,"title":"Example: Custom source","text":"<p>Create <code>sources.py</code>:</p> <pre><code>import param\nimport pandas as pd\nfrom lumen.sources import Source\n\nclass APISource(Source):\n    \"\"\"Load data from a REST API.\"\"\"\n\n    api_url = param.String(doc=\"API endpoint URL\")\n    api_key = param.String(doc=\"API authentication key\")\n\n    source_type = 'api'\n\n    def get(self, table, **query):\n        \"\"\"Fetch data from API.\"\"\"\n        import requests\n\n        response = requests.get(\n            f\"{self.api_url}/{table}\",\n            headers={'Authorization': f'Bearer {self.api_key}'},\n            params=query\n        )\n        response.raise_for_status()\n        return pd.DataFrame(response.json())\n</code></pre> <p>Reference in YAML:</p> <pre><code>sources:\n  my_api:\n    type: api\n    api_url: https://api.example.com/v1\n    api_key: {{ env(\"API_KEY\") }}\n    tables:\n      users: users\n      orders: orders\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#complete-example","level":3,"title":"Complete example","text":"<p>File structure:</p> <pre><code>project/\n‚îú‚îÄ‚îÄ dashboard.yaml\n‚îú‚îÄ‚îÄ transforms.py\n‚îî‚îÄ‚îÄ views.py\n</code></pre> <p>transforms.py:</p> <pre><code>import param\nfrom lumen.transforms import Transform\n\nclass StableSort(Transform):\n    by = param.ListSelector(default=[], doc=\"Columns to sort by\")\n    ascending = param.ClassSelector(\n        default=True,\n        class_=(bool, list),\n        doc=\"Sort ascending vs descending\"\n    )\n    transform_type = 'stablesort'\n    _field_params = ['by']\n\n    def apply(self, table):\n        return table.sort_values(\n            self.by,\n            ascending=self.ascending,\n            kind='stable'\n        )\n</code></pre> <p>views.py:</p> <pre><code>from lumen.views import View\nimport panel as pn\n\nclass TextEditor(View):\n    view_type = 'texteditor'\n    _extension = 'texteditor'\n\n    def get_panel(self):\n        return pn.widgets.TextEditor(**self._get_params())\n\n    def _get_params(self):\n        return dict(\n            **self.kwargs,\n            sizing_mode='stretch_width',\n            placeholder='Enter some text'\n        )\n</code></pre> <p>dashboard.yaml:</p> <pre><code>config:\n  title: Custom Components Demo\n\nsources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  processed:\n    source: penguins\n    table: data\n    filters:\n      - type: widget\n        field: species\n    transforms:\n      - type: columns\n        columns: [species, island, bill_length_mm, bill_depth_mm]\n      - type: stablesort          # Custom transform\n        by: [species, island]\n\nlayouts:\n  - title: Analysis\n    pipeline: processed\n    layout: [[0, 1], [2]]\n    sizing_mode: stretch_width\n    views:\n      - type: hvplot\n        kind: scatter\n        x: bill_length_mm\n        y: bill_depth_mm\n        color: species\n        height: 400\n      - type: table\n        show_index: false\n        height: 400\n      - type: texteditor          # Custom view\n        height: 200\n</code></pre> <p>Launch with:</p> <pre><code>lumen serve dashboard.yaml --show\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#approach-2-module-paths","level":2,"title":"Approach 2: Module paths","text":"<p>Organize custom components in a module structure and reference using dot notation.</p>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#module-structure","level":3,"title":"Module structure","text":"<p>Create a package next to your YAML file:</p> <pre><code>project/\n‚îú‚îÄ‚îÄ dashboard.yaml\n‚îî‚îÄ‚îÄ my_library/\n    ‚îú‚îÄ‚îÄ __init__.py\n    ‚îî‚îÄ‚îÄ custom.py\n</code></pre> <p>my_library/custom.py:</p> <pre><code>import param\nfrom lumen.transforms import Transform\nfrom lumen.views import View\nimport panel as pn\n\nclass StableSort(Transform):\n    by = param.ListSelector(default=[])\n    ascending = param.ClassSelector(default=True, class_=(bool, list))\n    transform_type = 'stablesort'\n    _field_params = ['by']\n\n    def apply(self, table):\n        return table.sort_values(self.by, ascending=self.ascending, kind='stable')\n\n\nclass TextEditor(View):\n    view_type = 'texteditor'\n    _extension = 'texteditor'\n\n    def get_panel(self):\n        return pn.widgets.TextEditor(**self._get_params())\n\n    def _get_params(self):\n        return dict(**self.kwargs, sizing_mode='stretch_width')\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#reference-with-module-path","level":3,"title":"Reference with module path","text":"<p>Use full module path in YAML:</p> <pre><code>pipelines:\n  processed:\n    source: my_source\n    table: my_table\n    transforms:\n      - type: my_library.custom.StableSort  # Full module path\n        by: [date]\n\nlayouts:\n  - title: Dashboard\n    views:\n      - type: my_library.custom.TextEditor  # Full module path\n        height: 250\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#when-to-use-module-paths","level":3,"title":"When to use module paths","text":"<p>Use module paths when:</p> <ul> <li>You have many custom components</li> <li>You want to organize components by functionality</li> <li>You're building a reusable library</li> <li>You need namespace separation</li> </ul> <p>Use automatic imports when:</p> <ul> <li>You have few custom components</li> <li>You want simple, quick customization</li> <li>Components are specific to one dashboard</li> </ul>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#callbacks","level":2,"title":"Callbacks","text":"<p>Callbacks perform actions when specific events occur.</p>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#available-callback-hooks","level":3,"title":"Available callback hooks","text":"<p>The <code>Config</code> object provides these hooks:</p> Hook Trigger Use case <code>on_session_created</code> User session starts Logging, initialization <code>on_session_destroyed</code> User session ends Cleanup, analytics <code>on_loaded</code> Frontend fully loaded Ready notifications <code>on_error</code> Dashboard callback errors Error handling <code>on_update</code> Pipeline updates Change tracking, logging","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#defining-callbacks","level":3,"title":"Defining callbacks","text":"<p>Callbacks must be importable functions. Create <code>callbacks.py</code> next to your YAML:</p> <pre><code>import panel as pn\n\ndef session_created():\n    \"\"\"Called when a user session starts.\"\"\"\n    print(f'Session created for user {pn.state.user}')\n    print(f'Session ID: {pn.state.session_id}')\n\ndef session_destroyed():\n    \"\"\"Called when a user session ends.\"\"\"\n    print(f'Session ended for user {pn.state.user}')\n\ndef frontend_loaded():\n    \"\"\"Called when the frontend finishes loading.\"\"\"\n    print('Dashboard loaded successfully')\n\ndef pipeline_updated(pipeline):\n    \"\"\"Called when a pipeline updates.\"\"\"\n    print(f'Pipeline {pipeline.name} was updated')\n    print(f'Current data shape: {pipeline.data.shape}')\n\ndef error_occurred(error):\n    \"\"\"Called when an error occurs.\"\"\"\n    print(f'Error: {error}')\n    # Send to error tracking service\n</code></pre> <p>Reference in YAML:</p> <pre><code>config:\n  on_session_created: callbacks.session_created\n  on_session_destroyed: callbacks.session_destroyed\n  on_loaded: callbacks.frontend_loaded\n  on_update: callbacks.pipeline_updated\n  on_error: callbacks.error_occurred\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#callback-examples","level":3,"title":"Callback examples","text":"","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#logging-user-activity","level":4,"title":"Logging user activity","text":"<pre><code># callbacks.py\nimport logging\nimport panel as pn\n\nlogger = logging.getLogger(__name__)\n\ndef log_session_start():\n    logger.info(f'User {pn.state.user} started session at {pn.state.curdoc.session_context.id}')\n\ndef log_pipeline_update(pipeline):\n    logger.info(f'Pipeline {pipeline.name} updated. Rows: {len(pipeline.data)}')\n</code></pre> <pre><code>config:\n  on_session_created: callbacks.log_session_start\n  on_update: callbacks.log_pipeline_update\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#send-notifications","level":4,"title":"Send notifications","text":"<pre><code># callbacks.py\nimport requests\n\ndef notify_error(error):\n    \"\"\"Send error to Slack webhook.\"\"\"\n    webhook_url = \"https://hooks.slack.com/services/YOUR/WEBHOOK/URL\"\n    message = {\n        \"text\": f\"Dashboard error: {error}\",\n        \"username\": \"Lumen Bot\"\n    }\n    requests.post(webhook_url, json=message)\n</code></pre> <pre><code>config:\n  on_error: callbacks.notify_error\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#track-analytics","level":4,"title":"Track analytics","text":"<pre><code># callbacks.py\nimport panel as pn\nfrom datetime import datetime\n\nsessions = []\n\ndef track_session_start():\n    sessions.append({\n        'user': pn.state.user,\n        'start_time': datetime.now(),\n        'session_id': pn.state.session_id\n    })\n\ndef track_session_end():\n    for session in sessions:\n        if session['session_id'] == pn.state.session_id:\n            session['end_time'] = datetime.now()\n            session['duration'] = session['end_time'] - session['start_time']\n</code></pre> <pre><code>config:\n  on_session_created: callbacks.track_session_start\n  on_session_destroyed: callbacks.track_session_end\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#initialize-resources","level":4,"title":"Initialize resources","text":"<pre><code># callbacks.py\nimport panel as pn\n\ndef initialize_session():\n    \"\"\"Set up session-specific resources.\"\"\"\n    if not hasattr(pn.state, 'cache'):\n        pn.state.cache = {}\n\n    print(f'Initialized cache for {pn.state.user}')\n\ndef cleanup_session():\n    \"\"\"Clean up session resources.\"\"\"\n    if hasattr(pn.state, 'cache'):\n        pn.state.cache.clear()\n        print(f'Cleaned up resources for {pn.state.user}')\n</code></pre> <pre><code>config:\n  on_session_created: callbacks.initialize_session\n  on_session_destroyed: callbacks.cleanup_session\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#callback-limitations","level":3,"title":"Callback limitations","text":"<p>Serialization</p> <p>Callbacks defined inline in Python cannot be serialized to YAML:</p> <pre><code># ‚ùå Won't work - cannot serialize to YAML\ndef created():\n    print('Session created')\n\nconfig = lm.Config(on_session_created=created)\nconfig.to_spec()  # Fails!\n</code></pre> <p>Define callbacks in external modules instead:</p> <pre><code># ‚úÖ Works - importable from module\nimport lumen as lm\nimport callbacks  # External module\n\nconfig = lm.Config(on_session_created=callbacks.created)\nconfig.to_spec()  # Succeeds\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#best-practices","level":2,"title":"Best practices","text":"","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#component-design","level":3,"title":"Component design","text":"<p>Keep components focused: Each component should do one thing well.</p> <pre><code># ‚úÖ Good - focused responsibility\nclass UpperCaseTransform(Transform):\n    def apply(self, table):\n        return table.apply(lambda x: x.str.upper() if x.dtype == 'object' else x)\n\n# ‚ùå Bad - too many responsibilities\nclass MegaTransform(Transform):\n    def apply(self, table):\n        # Uppercase, sort, filter, aggregate...\n        pass\n</code></pre> <p>Document parameters: Use clear docstrings.</p> <pre><code>class MyTransform(Transform):\n    field = param.String(doc=\"Column name to transform\")\n    method = param.Selector(\n        default='mean',\n        objects=['mean', 'median', 'mode'],\n        doc=\"Aggregation method to apply\"\n    )\n</code></pre> <p>Handle errors gracefully: Validate inputs and provide helpful error messages.</p> <pre><code>def apply(self, table):\n    if self.field not in table.columns:\n        raise ValueError(\n            f\"Column '{self.field}' not found. \"\n            f\"Available columns: {list(table.columns)}\"\n        )\n    return table[self.field].mean()\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#callback-design","level":3,"title":"Callback design","text":"<p>Keep callbacks fast: Don't block the main thread.</p> <pre><code># ‚úÖ Good - quick operation\ndef log_update(pipeline):\n    print(f'Updated: {pipeline.name}')\n\n# ‚ùå Bad - slow operation\ndef slow_update(pipeline):\n    time.sleep(10)  # Blocks dashboard!\n</code></pre> <p>Use async for slow operations:</p> <pre><code>import asyncio\n\nasync def notify_update(pipeline):\n    await asyncio.sleep(1)  # Doesn't block\n    print(f'Updated: {pipeline.name}')\n</code></pre> <p>Handle exceptions: Don't let callbacks crash the dashboard.</p> <pre><code>def safe_callback(pipeline):\n    try:\n        # Your logic\n        risky_operation()\n    except Exception as e:\n        print(f'Callback error: {e}')\n        # Dashboard continues running\n</code></pre>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/customization/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you can extend Lumen:</p> <ul> <li>Python API guide - Build complete custom applications</li> <li>Deployment guide - Deploy dashboards with custom components</li> <li>Panel documentation - Learn more about Panel widgets</li> <li>Param documentation - Understand parameter declarations</li> </ul>","path":["Configuration","Specs","Extending Lumen with custom components"],"tags":[]},{"location":"configuration/spec/deployment/","level":1,"title":"Deploying and validating dashboards","text":"<p>Deploy dashboards as standalone applications and validate configurations.</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#serving-dashboards","level":2,"title":"Serving dashboards","text":"<p>Deploy your dashboard to make it accessible as a web application.</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#serve-from-yaml","level":3,"title":"Serve from YAML","text":"<p>Launch a YAML specification:</p> <pre><code>lumen serve dashboard.yaml --show\n</code></pre> <p>The <code>--show</code> flag automatically opens your browser.</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#serve-from-python","level":3,"title":"Serve from Python","text":"<p>Launch a Python script:</p> <pre><code>lumen serve app.py --show\n</code></pre> <p>Your Python file must call <code>.servable()</code>:</p> <pre><code>import lumen as lm\n\ndashboard = lm.Dashboard(...)\ndashboard.servable()\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#development-mode","level":3,"title":"Development mode","text":"<p>Use <code>--autoreload</code> while developing to see changes instantly:</p> <pre><code>lumen serve dashboard.yaml --show --autoreload\n</code></pre> <p>The dashboard reloads automatically when you save changes to your YAML file.</p> <p>Development workflow</p> <p>Keep <code>--autoreload</code> running in a terminal while editing your YAML. Save changes and refresh your browser to see updates.</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#server-options","level":3,"title":"Server options","text":"<p>Common command-line options:</p> Option Purpose Example <code>--show</code> Open browser automatically <code>--show</code> <code>--autoreload</code> Reload on file changes <code>--autoreload</code> <code>--port</code> Custom port number <code>--port 5006</code> <code>--address</code> Bind to specific address <code>--address 0.0.0.0</code> <code>--allow-websocket-origin</code> Allow external access <code>--allow-websocket-origin=example.com</code> <code>--template-vars</code> Pass template variables <code>--template-vars=\"{'USER': 'alice'}\"</code>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#custom-port","level":3,"title":"Custom port","text":"<pre><code>lumen serve dashboard.yaml --port 8080 --show\n</code></pre> <p>Access at: <code>http://localhost:8080</code></p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#external-access","level":3,"title":"External access","text":"<p>Allow access from other machines:</p> <pre><code>lumen serve dashboard.yaml --address 0.0.0.0 --port 5006\n</code></pre> <p>Then access from other machines using your IP: <code>http://192.168.1.100:5006</code></p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#production-deployment","level":3,"title":"Production deployment","text":"<p>For production, use a process manager and reverse proxy:</p> <pre><code># Using panel serve (same underlying command)\npanel serve dashboard.yaml \\\n  --port 5006 \\\n  --address 0.0.0.0 \\\n  --allow-websocket-origin=yourdomain.com \\\n  --num-procs 4\n</code></pre> <p>Options for production:</p> <ul> <li><code>--num-procs</code>: Number of worker processes</li> <li><code>--use-xheaders</code>: Trust proxy headers (for HTTPS)</li> <li><code>--allow-websocket-origin</code>: Whitelist domains</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#validating-specifications","level":2,"title":"Validating specifications","text":"<p>Validate YAML files before deployment to catch errors early.</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#run-validation","level":3,"title":"Run validation","text":"<pre><code>lumen validate dashboard.yaml\n</code></pre> <p>Validation checks for:</p> <ul> <li>YAML syntax errors</li> <li>Invalid component types</li> <li>Missing required parameters</li> <li>Unknown parameter names</li> <li>Missing dependencies</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#success-output","level":3,"title":"Success output","text":"<pre><code>‚úì Validation successful\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#error-output","level":3,"title":"Error output","text":"<p>Validation provides detailed error messages:</p> <pre><code>ERROR: View component specification declared unknown type 'hvplotqedq'. \nDid you mean 'hvplot' or 'hvplot_ui'?\n\n    table: penguins\n    type: hvplotqedq\n    kind: scatter\n    x: bill_length_mm\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#common-validation-errors","level":2,"title":"Common validation errors","text":"","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#indentation-errors","level":3,"title":"Indentation errors","text":"<p>YAML is whitespace-sensitive:</p> <pre><code>ERROR: expected &lt;block end&gt;, but found '?'\n  in \"&lt;unicode string&gt;\", line 28, column 3:\n      facet:\n      ^\n</code></pre> <p>Fix: Check indentation is consistent (use 2 spaces, not tabs).</p> <pre><code># ‚ùå Wrong\nsources:\nmy_source:\n    type: file\n\n# ‚úÖ Correct\nsources:\n  my_source:\n    type: file\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#invalid-key-names","level":3,"title":"Invalid key names","text":"<pre><code>ERROR: mapping values are not allowed here\n  in \"&lt;unicode string&gt;\", line 6, column 11:\n        shared: true\n              ^\n</code></pre> <p>Fix: Check for typos in parameter names and ensure proper nesting.</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#unknown-component-types","level":3,"title":"Unknown component types","text":"<pre><code>ERROR: View component specification declared unknown type 'tabel'. \nDid you mean 'table'?\n</code></pre> <p>Fix: Correct the type name (check for typos).</p> <pre><code># ‚ùå Wrong\nviews:\n  - type: tabel\n\n# ‚úÖ Correct\nviews:\n  - type: table\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#missing-packages","level":3,"title":"Missing packages","text":"<pre><code>ERROR: In order to use the source component 'intake', \nthe 'intake' package must be installed.\n</code></pre> <p>Fix: Install the required package:</p> <pre><code>conda install intake\n# or\npip install intake\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#invalid-parameter-values","level":3,"title":"Invalid parameter values","text":"<pre><code>ERROR: Parameter 'kind' must be one of: scatter, line, bar, hist, box, area\nReceived: 'scater'\n</code></pre> <p>Fix: Use valid parameter values (check documentation).</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#pre-deployment-checklist","level":2,"title":"Pre-deployment checklist","text":"<p>Before deploying to production:</p>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#1-validate-specification","level":3,"title":"1. Validate specification","text":"<pre><code>lumen validate dashboard.yaml\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#2-test-locally","level":3,"title":"2. Test locally","text":"<pre><code>lumen serve dashboard.yaml --show\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#3-check-data-sources","level":3,"title":"3. Check data sources","text":"<ul> <li>Verify files/URLs are accessible</li> <li>Test with production data</li> <li>Check credentials work</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#4-review-security","level":3,"title":"4. Review security","text":"<ul> <li>Don't hardcode secrets in YAML</li> <li>Use environment variables for sensitive data</li> <li>Enable authentication if needed</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#5-test-performance","level":3,"title":"5. Test performance","text":"<ul> <li>Check loading times</li> <li>Test with expected data volumes</li> <li>Enable caching for large datasets</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#6-verify-dependencies","level":3,"title":"6. Verify dependencies","text":"<p>List all required packages in <code>requirements.txt</code>:</p> <pre><code>lumen\npanel\nhvplot\n# Add other dependencies\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#deployment-patterns","level":2,"title":"Deployment patterns","text":"","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#local-development","level":3,"title":"Local development","text":"<pre><code>lumen serve dashboard.yaml --show --autoreload\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#testingstaging","level":3,"title":"Testing/staging","text":"<pre><code>lumen serve dashboard.yaml \\\n  --port 5006 \\\n  --address 0.0.0.0 \\\n  --allow-websocket-origin=staging.example.com\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#production-with-docker","level":3,"title":"Production with Docker","text":"<p>Dockerfile:</p> <pre><code>FROM python:3.10-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY dashboard.yaml .\nCOPY data/ data/\n\nEXPOSE 5006\n\nCMD [\"lumen\", \"serve\", \"dashboard.yaml\", \\\n     \"--port\", \"5006\", \\\n     \"--address\", \"0.0.0.0\", \\\n     \"--allow-websocket-origin\", \"*\"]\n</code></pre> <p>Build and run:</p> <pre><code>docker build -t my-dashboard .\ndocker run -p 5006:5006 my-dashboard\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#production-with-systemd","level":3,"title":"Production with systemd","text":"<p>Create <code>/etc/systemd/system/lumen-dashboard.service</code>:</p> <pre><code>[Unit]\nDescription=Lumen Dashboard\nAfter=network.target\n\n[Service]\nType=simple\nUser=www-data\nWorkingDirectory=/var/www/dashboard\nEnvironment=\"PATH=/usr/local/bin:/usr/bin\"\nExecStart=/usr/local/bin/lumen serve dashboard.yaml \\\n  --port 5006 \\\n  --address 0.0.0.0 \\\n  --num-procs 4\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Enable and start:</p> <pre><code>sudo systemctl enable lumen-dashboard\nsudo systemctl start lumen-dashboard\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#with-nginx-reverse-proxy","level":3,"title":"With nginx reverse proxy","text":"<p>nginx configuration:</p> <pre><code>server {\n    listen 80;\n    server_name dashboard.example.com;\n\n    location / {\n        proxy_pass http://localhost:5006;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # WebSocket support\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#environment-configuration","level":2,"title":"Environment configuration","text":"","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#environment-variables","level":3,"title":"Environment variables","text":"<p>Use environment variables for deployment-specific settings:</p> <p>dashboard.yaml:</p> <pre><code>config:\n  title: {{ env(\"APP_TITLE\", \"My Dashboard\") }}\n\nsources:\n  database:\n    type: duckdb\n    uri: {{ env(\"DATABASE_URL\") }}\n    cache_dir: {{ env(\"CACHE_DIR\", \".cache\") }}\n</code></pre> <p>Set variables:</p> <pre><code>export APP_TITLE=\"Production Dashboard\"\nexport DATABASE_URL=\"postgresql://localhost/mydb\"\nexport CACHE_DIR=\"/var/cache/lumen\"\n\nlumen serve dashboard.yaml\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#configuration-files","level":3,"title":"Configuration files","text":"<p>Manage settings per environment:</p> <p>.env.development:</p> <pre><code>APP_TITLE=\"Development Dashboard\"\nDATABASE_URL=\"sqlite:///dev.db\"\nDEBUG=true\n</code></pre> <p>.env.production:</p> <pre><code>APP_TITLE=\"Production Dashboard\"\nDATABASE_URL=\"postgresql://prod-server/db\"\nDEBUG=false\n</code></pre> <p>Load with a startup script:</p> <pre><code>#!/bin/bash\nset -a\nsource .env.production\nset +a\n\nlumen serve dashboard.yaml --port 5006\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#monitoring-and-logging","level":2,"title":"Monitoring and logging","text":"","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#enable-logging","level":3,"title":"Enable logging","text":"<pre><code># app.py\nimport logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('dashboard.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# Your dashboard code...\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#health-checks","level":3,"title":"Health checks","text":"<p>Add a health check endpoint:</p> <pre><code>import panel as pn\n\ndef health_check():\n    return pn.pane.Markdown(\"OK\")\n\npn.serve(\n    {'/': dashboard.servable(), '/health': health_check},\n    port=5006\n)\n</code></pre> <p>Check with:</p> <pre><code>curl http://localhost:5006/health\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#best-practices","level":2,"title":"Best practices","text":"","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#version-control","level":3,"title":"Version control","text":"<p>Include in git:</p> <pre><code># Track these\ngit add dashboard.yaml\ngit add requirements.txt\ngit add README.md\n\n# Ignore these\necho \".cache/\" &gt;&gt; .gitignore\necho \"*.log\" &gt;&gt; .gitignore\necho \".env*\" &gt;&gt; .gitignore\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#documentation","level":3,"title":"Documentation","text":"<p>Create a README with:</p> <ul> <li>Setup instructions</li> <li>Required environment variables</li> <li>Deployment steps</li> <li>Troubleshooting tips</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#automated-testing","level":3,"title":"Automated testing","text":"<p>Test dashboards in CI/CD:</p> <pre><code># .github/workflows/test.yml\n- name: Validate dashboard\n  run: lumen validate dashboard.yaml\n\n- name: Test serving\n  run: |\n    lumen serve dashboard.yaml --port 5006 &amp;\n    sleep 5\n    curl http://localhost:5006/\n</code></pre>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/deployment/#next-steps","level":2,"title":"Next steps","text":"<ul> <li>Authentication guide - Secure your deployments</li> <li>Panel deployment docs - Advanced deployment options</li> <li>Variables guide - Manage environment-specific configuration</li> </ul>","path":["Configuration","Specs","Deploying and validating dashboards"],"tags":[]},{"location":"configuration/spec/downloads/","level":1,"title":"Enabling data downloads","text":"<p>Let users export dashboard data in various formats.</p>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#download-locations","level":2,"title":"Download locations","text":"<p>Add download capability in three ways:</p> Location Configuration Description Sidebar <code>download:</code> in layout Button in sidebar View <code>download</code> view type Dedicated download component Table <code>download:</code> in table view Integrated with table","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#sidebar-download","level":2,"title":"Sidebar download","text":"<p>Add a download button to the layout sidebar:</p> <pre><code>sources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguin Data\n    source: penguins\n    download: csv              # Adds download button to sidebar\n    views:\n      - type: table\n        table: data\n</code></pre> <p>Users click the download button in the sidebar to export current (filtered) data.</p>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#download-view","level":2,"title":"Download view","text":"<p>Create a dedicated download component:</p> <pre><code>sources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguin Data\n    source: penguins\n    views:\n      - type: download         # Download view\n        format: csv\n      - type: table\n        table: data\n</code></pre> <p>The download view appears as a button within the main content area.</p>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#table-download","level":2,"title":"Table download","text":"<p>Integrate download directly into table views:</p> <pre><code>sources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguin Data\n    source: penguins\n    views:\n      - type: table\n        table: data\n        download: csv          # Adds download to table controls\n</code></pre> <p>Download button appears in the table's control bar.</p>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#download-formats","level":2,"title":"Download formats","text":"<p>Supported export formats:</p> Format Extension Best for <code>csv</code> .csv Spreadsheets, most tools <code>xlsx</code> .xlsx Excel workbooks <code>json</code> .json Web APIs, JavaScript","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#csv-downloads","level":3,"title":"CSV downloads","text":"<pre><code>layouts:\n  - title: Data\n    source: my_source\n    download: csv\n    views:\n      - type: download\n        format: csv\n</code></pre>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#excel-downloads","level":3,"title":"Excel downloads","text":"<pre><code>layouts:\n  - title: Data\n    source: my_source\n    download: xlsx\n    views:\n      - type: download\n        format: xlsx\n</code></pre>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#json-downloads","level":3,"title":"JSON downloads","text":"<pre><code>layouts:\n  - title: Data\n    source: my_source\n    download: json\n    views:\n      - type: download\n        format: json\n</code></pre>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#customizing-download-buttons","level":2,"title":"Customizing download buttons","text":"<p>Configure button appearance and behavior:</p> <pre><code>views:\n  - type: download\n    format: csv\n    button_type: primary       # primary, success, warning, danger\n    button_text: \"Export Data\"\n    filename: \"my_data.csv\"    # Custom filename\n</code></pre> <p>Button types:</p> Type Appearance <code>default</code> Standard button <code>primary</code> Blue/highlighted <code>success</code> Green <code>warning</code> Orange <code>danger</code> Red","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#combined-approach","level":2,"title":"Combined approach","text":"<p>Use multiple download methods together:</p> <pre><code>sources:\n  sales:\n    type: file\n    tables:\n      data: sales.csv\n\npipelines:\n  filtered:\n    source: sales\n    table: data\n    filters:\n      - type: widget\n        field: region\n      - type: widget\n        field: year\n\nlayouts:\n  - title: Sales Dashboard\n    pipeline: filtered\n    download: csv              # Sidebar download\n    views:\n      - type: download         # Dedicated download view\n        format: xlsx\n        button_type: success\n        button_text: \"Export to Excel\"\n      - type: table\n        show_index: false\n        download: csv          # Table download\n      - type: hvplot\n        kind: bar\n        x: product\n        y: revenue\n</code></pre> <p>This provides three download options: 1. CSV from sidebar 2. Excel from dedicated button 3. CSV from table</p>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#download-behavior","level":2,"title":"Download behavior","text":"","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#what-gets-downloaded","level":3,"title":"What gets downloaded","text":"<p>Downloads export the current filtered data:</p> <ul> <li>If users applied filters, only filtered data exports</li> <li>If pipeline has transforms, transformed data exports</li> <li>Raw source data is never directly accessible</li> </ul>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#file-naming","level":3,"title":"File naming","text":"<p>Default filename format: <code>{table_name}_{timestamp}.{format}</code></p> <p>Custom filenames:</p> <pre><code>views:\n  - type: download\n    format: csv\n    filename: \"sales_report_2024.csv\"\n</code></pre>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#python-api","level":2,"title":"Python API","text":"<p>Enable downloads programmatically:</p> <pre><code>from lumen.views import Download\nimport lumen as lm\n\npipeline = lm.Pipeline.from_spec({...})\n\ndownload_view = Download(\n    pipeline=pipeline,\n    format='csv',\n    button_type='primary',\n    button_text='Export Data'\n)\n\n# Include in layout\nimport panel as pn\n\npn.Column(\n    pipeline.control_panel,\n    download_view,\n    lm.views.Table(pipeline=pipeline)\n)\n</code></pre>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/downloads/#next-steps","level":2,"title":"Next steps","text":"<ul> <li>Views guide - Learn about table views and other visualizations</li> <li>Pipelines guide - Filter data before download</li> <li>Deployment guide - Deploy dashboards with downloads</li> </ul>","path":["Configuration","Specs","Enabling data downloads"],"tags":[]},{"location":"configuration/spec/pipelines/","level":1,"title":"Transforming data with pipelines","text":"<p>Pipelines filter and transform data before visualization.</p> <p>Pipelines consume data from Sources and prepare it for Views.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#pipeline-fundamentals","level":2,"title":"Pipeline fundamentals","text":"<p>Pipelines sit between sources and views, manipulating data as it flows through:</p> <pre><code>Source ‚Üí Pipeline ‚Üí View\n         (filter + transform)\n</code></pre> <p>Skip pipelines if you want to display raw data without modification. Connect views directly to sources instead.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#when-to-use-pipelines","level":3,"title":"When to use pipelines","text":"<p>Use pipelines to:</p> <ul> <li>Filter data: Show only rows matching criteria (e.g., \"sales from 2023\")</li> <li>Transform data: Modify structure or values (e.g., \"compute averages by region\")</li> <li>Clean data: Select columns, sort rows, handle missing values</li> <li>Aggregate data: Group and summarize (e.g., \"total sales by product\")</li> </ul>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#basic-pipeline-syntax","level":3,"title":"Basic pipeline syntax","text":"YAMLPython <pre><code>pipelines:\n  pipeline_name:         # Choose any name\n    source: source_name  # Which source to use\n    table: table_name    # Which table from that source\n    filters: [...]       # Optional\n    transforms: [...]    # Optional\n</code></pre> <pre><code>from lumen.pipeline import Pipeline\n\npipeline = Pipeline.from_spec({\n    \"source\": {\"type\": \"file\", \"tables\": {\"data\": \"data.csv\"}},\n    \"filters\": [...],\n    \"transforms\": [...]\n})\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#understanding-pipeline-execution","level":2,"title":"Understanding pipeline execution","text":"<p>Pipeline execution order matters. Operations occur in this sequence:</p> <pre><code>‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ 1. Source.get() with Filter/SQL state      ‚îÇ\n‚îÇ    (Optimized at database level if SQL)     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n               ‚îÇ\n               ‚ñº\n     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n     ‚îÇ 2. DataFrame returned‚îÇ\n     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                ‚îÇ\n                ‚ñº\n     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n     ‚îÇ 3. Transforms applied        ‚îÇ\n     ‚îÇ    (in order specified)      ‚îÇ\n     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</code></pre> <p>Key insight: Filters and SQL transforms can execute at the database level (fast). Regular transforms execute on the returned DataFrame (after data is in memory).</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#working-with-filters","level":2,"title":"Working with filters","text":"<p>Filters let users drill down into data subsets interactively.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#widget-filters","level":3,"title":"Widget filters","text":"<p>Widget filters create interactive controls in the sidebar:</p> YAMLPythonResult <pre><code>pipelines:\n  filtered_data:\n    source: my_source\n    table: my_table\n    filters:\n      - type: widget\n        field: category      # Column to filter\n      - type: widget\n        field: region\n      - type: widget\n        field: year\n</code></pre> <pre><code>pipeline = Pipeline(source=source, table='my_table')\npipeline.add_filter('widget', field='category')\npipeline.add_filter('widget', field='region')\npipeline.add_filter('widget', field='year')\n</code></pre> <p>Creates dropdown widgets for each field. Users select values to filter data.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#automatic-filters","level":3,"title":"Automatic filters","text":"<p>Generate filters for all columns automatically:</p> YAMLPython <pre><code>pipelines:\n  auto_filtered:\n    source: my_source\n    table: my_table\n    filters: auto      # Creates widgets for all columns\n</code></pre> <pre><code>pipeline = Pipeline(\n    source=source,\n    table='my_table',\n    filters='auto'\n)\n</code></pre> <p>When to use auto filters</p> <p>Automatic filters work well for exploring new datasets. For production dashboards, explicitly specify filters for better control.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#filter-types","level":3,"title":"Filter types","text":"Type Purpose User interaction <code>widget</code> Interactive dropdown/slider Users choose values <code>constant</code> Fixed filter value No interaction (always applied) <code>facet</code> Split data into groups Users navigate groups","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#constant-filters","level":3,"title":"Constant filters","text":"<p>Apply fixed filters that users can't change:</p> <pre><code>filters:\n  - type: constant\n    field: status\n    value: active      # Always filter to active records\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#widget-filter-customization","level":3,"title":"Widget filter customization","text":"<p>Customize widget appearance and behavior:</p> <pre><code>filters:\n  - type: widget\n    field: category\n    multi: false         # Single-select instead of multi-select\n    default: \"Electronics\"  # Pre-selected value\n  - type: widget\n    field: price\n    kind: RangeSlider    # Use slider for numeric ranges\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#working-with-transforms","level":2,"title":"Working with transforms","text":"<p>Transforms modify data structure or values.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#column-selection","level":3,"title":"Column selection","text":"<p>Select specific columns to display:</p> YAMLPython <pre><code>transforms:\n  - type: columns\n    columns: [id, name, category, price, date]\n</code></pre> <pre><code>pipeline.add_transform('columns', columns=['id', 'name', 'category', 'price', 'date'])\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#aggregation","level":3,"title":"Aggregation","text":"<p>Group data and compute statistics:</p> YAMLPythonEffect <pre><code>transforms:\n  - type: aggregate\n    method: mean           # sum, mean, min, max, count, etc.\n    by: [category, region] # Group by these columns\n</code></pre> <pre><code>from lumen.transforms import Aggregate\n\npipeline.add_transform(Aggregate(\n    method='mean',\n    by=['category', 'region']\n))\n</code></pre> <p>Computes the mean of all numeric columns, grouped by category and region.</p> <p>Common aggregation methods:</p> Method Computation <code>sum</code> Total of values <code>mean</code> Average <code>median</code> Middle value <code>min</code> Minimum value <code>max</code> Maximum value <code>count</code> Number of records <code>std</code> Standard deviation","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#sorting","level":3,"title":"Sorting","text":"<p>Order rows by column values:</p> <pre><code>transforms:\n  - type: sort\n    by: [date, revenue]\n    ascending: [false, false]   # Sort descending\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#query-sql-like-filtering","level":3,"title":"Query (SQL-like filtering)","text":"<p>Filter using SQL-like expressions:</p> <pre><code>transforms:\n  - type: query\n    query: \"price &gt; 100 and category == 'Electronics'\"\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#transform-types-reference","level":3,"title":"Transform types reference","text":"Type Purpose Example <code>columns</code> Select specific columns Keep only needed fields <code>aggregate</code> Group and compute stats Average sales by region <code>sort</code> Order rows Sort by date <code>query</code> SQL-like filtering <code>price &gt; 100</code> <code>astype</code> Change column data types Convert to datetime <code>project</code> Create derived columns <code>total = price * quantity</code>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#building-pipelines-declaratively","level":2,"title":"Building pipelines declaratively","text":"<p>The declarative approach uses nested dictionaries, similar to YAML.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#complete-example","level":3,"title":"Complete example","text":"YAMLPython <pre><code>sources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  analysis:\n    source: penguins\n    table: data\n    filters:\n      - type: widget\n        field: species\n      - type: widget\n        field: island\n      - type: widget\n        field: sex\n    transforms:\n      - type: aggregate\n        method: mean\n        by: [species, sex, year]\n\nlayouts:\n  - title: Penguin Analysis\n    pipeline: analysis\n    views:\n      - type: table\n</code></pre> <pre><code>from lumen.pipeline import Pipeline\n\npipeline = Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'tables': {\n            'data': 'https://datasets.holoviz.org/penguins/v1/penguins.csv'\n        }\n    },\n    'filters': [\n        {'type': 'widget', 'field': 'species'},\n        {'type': 'widget', 'field': 'island'},\n        {'type': 'widget', 'field': 'sex'},\n    ],\n    'transforms': [\n        {'type': 'aggregate', 'method': 'mean', 'by': ['species', 'sex', 'year']}\n    ]\n})\n\npipeline.data  # Preview the result\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#preview-data","level":3,"title":"Preview data","text":"<p>Access processed data at any point:</p> <pre><code>pipeline.data           # Current filtered/transformed data\npipeline.data.head()    # First few rows\npipeline.data.shape     # Dimensions\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#building-pipelines-programmatically","level":2,"title":"Building pipelines programmatically","text":"<p>The programmatic approach builds pipelines step-by-step.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#create-a-pipeline","level":3,"title":"Create a pipeline","text":"<p>Start with a source:</p> <pre><code>from lumen.sources import FileSource\nfrom lumen.pipeline import Pipeline\n\nsource = FileSource(tables={\n    'penguins': 'https://datasets.holoviz.org/penguins/v1/penguins.csv'\n})\n\npipeline = Pipeline(source=source, table='penguins')\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#add-filters-step-by-step","level":3,"title":"Add filters step-by-step","text":"<pre><code>pipeline.add_filter('widget', field='species')\npipeline.add_filter('widget', field='island')\npipeline.add_filter('widget', field='sex')\npipeline.add_filter('widget', field='year')\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#add-transforms-step-by-step","level":3,"title":"Add transforms step-by-step","text":"<pre><code># Select columns\ncolumns = ['species', 'island', 'sex', 'year', 'bill_length_mm', 'bill_depth_mm']\npipeline.add_transform('columns', columns=columns)\n\n# Sort by species\npipeline.add_transform('sort', by=['species'])\n\n# Preview result\npipeline.data.head()\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#display-in-notebooks","level":3,"title":"Display in notebooks","text":"<p>Render pipelines interactively in Jupyter notebooks:</p> <pre><code>import panel as pn\n\npn.extension('tabulator')\n\npipeline  # Renders with widgets and data preview\n</code></pre> <p>Show only the control panel:</p> <pre><code>pipeline.control_panel  # Just the filter widgets\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#control-auto-update-behavior","level":3,"title":"Control auto-update behavior","text":"<p>By default, pipelines update after every interaction. Disable for manual control:</p> <pre><code>pipeline = Pipeline(\n    source=source,\n    table='penguins',\n    auto_update=False  # Require explicit update\n)\n\n# Add update button\nimport panel as pn\n\npn.Column(\n    pipeline.control_panel,\n    pn.widgets.Button(name='Update', on_click=lambda e: pipeline.update()),\n    pipeline.data\n)\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#chaining-pipelines","level":2,"title":"Chaining pipelines","text":"<p>Create processing stages by chaining pipelines together. This lets one pipeline build on another's output.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#why-chain-pipelines","level":3,"title":"Why chain pipelines?","text":"<ul> <li>Separate concerns: Filter in one stage, aggregate in another</li> <li>Reuse filtering: Multiple aggregations of the same filtered data</li> <li>Optimize performance: Share computation between related views</li> </ul>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#chain-in-python","level":3,"title":"Chain in Python","text":"<p>Use the <code>.chain()</code> method:</p> <pre><code>from lumen.sources import FileSource\nfrom lumen.pipeline import Pipeline\nfrom lumen.transforms import Aggregate\n\n# Create base pipeline with filtering\nsource = FileSource(tables={\n    'penguins': 'https://datasets.holoviz.org/penguins/v1/penguins.csv'\n})\n\nbase_pipeline = Pipeline(source=source, table='penguins')\nbase_pipeline.add_filter('widget', field='species')\nbase_pipeline.add_filter('widget', field='island')\n\n# Chain to create aggregated view\nagg_pipeline = base_pipeline.chain(\n    transforms=[Aggregate(method='mean', by=['species', 'year'])]\n)\n\n# Both pipelines share the same filters\n# base_pipeline shows filtered raw data\n# agg_pipeline shows filtered + aggregated data\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#chain-in-yaml","level":3,"title":"Chain in YAML","text":"<p>Reference one pipeline from another using <code>pipeline:</code> instead of <code>source:</code>:</p> YAMLResult <pre><code>sources:\n  penguins:\n    type: file\n    tables:\n      data: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  # Base pipeline with filtering\n  filtered:\n    source: penguins\n    table: data\n    filters:\n      - type: widget\n        field: island\n\n  # Chained pipeline adds transforms\n  aggregated:\n    pipeline: filtered        # Reference the other pipeline\n    transforms:\n      - type: aggregate\n        method: mean\n        by: [species, year]\n\nlayouts:\n  - title: Analysis\n    views:\n      - type: table\n        pipeline: filtered    # Shows filtered raw data\n      - type: table\n        pipeline: aggregated  # Shows filtered + aggregated data\n</code></pre> <ul> <li>Both tables use the same island filter</li> <li>First table shows raw filtered data</li> <li>Second table shows aggregated filtered data</li> <li>Changing the filter updates both tables</li> </ul>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#multiple-chains","level":3,"title":"Multiple chains","text":"<p>Create multiple processing branches:</p> <pre><code># Base filtering\nbase = Pipeline(source=source, table='data')\nbase.add_filter('widget', field='category')\n\n# Branch 1: Aggregated view\nagg_branch = base.chain(transforms=[\n    Aggregate(method='sum', by=['region'])\n])\n\n# Branch 2: Top 10 view\ntop_branch = base.chain(transforms=[\n    Sort(by=['revenue'], ascending=False),\n    {'type': 'query', 'query': 'index &lt; 10'}\n])\n\n# All three share the category filter:\n# - base: filtered raw data\n# - agg_branch: filtered + aggregated\n# - top_branch: filtered + top 10\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#branching-pipelines-advanced","level":2,"title":"Branching pipelines (advanced)","text":"<p>Branching creates multiple views of the same source data at different processing stages.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#simple-branch-example","level":3,"title":"Simple branch example","text":"YAMLFlow diagram <pre><code>sources:\n  sales:\n    type: file\n    tables:\n      data: sales.csv\n\npipelines:\n  # Base pipeline\n  base:\n    source: sales\n    table: data\n    filters:\n      - type: widget\n        field: region\n\n  # Branch: adds column selection\n  selected:\n    pipeline: base\n    transforms:\n      - type: columns\n        columns: [date, product, revenue]\n\n  # Branch: adds aggregation\n  summary:\n    pipeline: base\n    transforms:\n      - type: aggregate\n        method: sum\n        by: [product]\n\nlayouts:\n  - title: Sales Dashboard\n    views:\n      - type: table\n        pipeline: base       # Filtered full data\n      - type: table\n        pipeline: selected   # Filtered + selected columns\n      - type: hvplot\n        pipeline: summary    # Filtered + aggregated\n        kind: bar\n        x: product\n        y: revenue\n</code></pre> <pre><code>Source (sales.csv)\n     ‚îÇ\n     ‚ñº\nPipeline: base (filter by region)\n     ‚îÇ\n     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n     ‚îÇ         ‚îÇ         ‚îÇ\n     ‚ñº         ‚ñº         ‚ñº\n  View 1   Pipeline:  Pipeline:\n           selected   summary\n              ‚îÇ         ‚îÇ\n              ‚ñº         ‚ñº\n           View 2    View 3\n</code></pre> <p>All three views share the region filter from the base pipeline.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#complex-branching","level":3,"title":"Complex branching","text":"<p>Create deep processing hierarchies:</p> <pre><code>pipelines:\n  # Level 1: Base filtering\n  base:\n    source: data_source\n    filters:\n      - type: widget\n        field: year\n      - type: widget\n        field: category\n\n  # Level 2: Column selection\n  cleaned:\n    pipeline: base\n    transforms:\n      - type: columns\n        columns: [date, product, price, quantity]\n\n  # Level 3: Derived columns\n  calculated:\n    pipeline: cleaned\n    transforms:\n      - type: project\n        columns:\n          revenue: price * quantity\n\n  # Level 3 alternate: Aggregation\n  summary:\n    pipeline: cleaned\n    transforms:\n      - type: aggregate\n        method: sum\n        by: [product]\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#using-pipelines-outside-dashboards","level":2,"title":"Using pipelines outside dashboards","text":"<p>Pipelines work independently of full dashboard specifications. Use them in notebooks or custom applications.</p>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#in-jupyter-notebooks","level":3,"title":"In Jupyter notebooks","text":"<pre><code>from lumen.pipeline import Pipeline\nfrom lumen.views import Table, hvPlotView\nimport panel as pn\n\npn.extension('tabulator')\n\n# Create pipeline\npipeline = Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'tables': {'data': 'data.csv'}\n    },\n    'filters': [\n        {'type': 'widget', 'field': 'category'},\n        {'type': 'widget', 'field': 'region'}\n    ]\n})\n\n# Display with Panel\npn.Row(\n    pipeline.control_panel,\n    pn.Column(\n        hvPlotView(pipeline=pipeline, kind='bar', x='product', y='sales'),\n        Table(pipeline=pipeline)\n    )\n)\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#in-custom-panel-apps","level":3,"title":"In custom Panel apps","text":"<p>Build custom applications using Panel's layout system:</p> <pre><code>from lumen.pipeline import Pipeline\nfrom lumen.views import hvPlotView, Table\nimport panel as pn\n\npn.extension('tabulator')\n\n# Create pipeline\npipeline = Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'tables': {'penguins': 'penguins.csv'}\n    },\n    'filters': [\n        {'type': 'widget', 'field': 'species'},\n        {'type': 'widget', 'field': 'island'}\n    ]\n})\n\n# Create views\nscatter = hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    by='species'\n)\n\ntable = Table(pipeline=pipeline, page_size=10)\n\n# Custom layout\napp = pn.template.MaterialTemplate(\n    title='Penguin Analysis',\n    sidebar=[pipeline.control_panel],\n    main=[\n        pn.Row(scatter, table)\n    ]\n)\n\napp.servable()\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#binding-to-custom-widgets","level":3,"title":"Binding to custom widgets","text":"<p>Bind pipeline data to any Panel component:</p> <pre><code>import panel as pn\n\n# Bind data to DataFrame pane\ndata_pane = pn.pane.DataFrame(\n    pipeline.param.data,\n    width=800,\n    height=400\n)\n\n# Bind to custom function\n@pn.depends(pipeline.param.data)\ndef custom_view(data):\n    return pn.pane.Markdown(f\"**Rows**: {len(data)}\")\n\npn.Column(\n    pipeline.control_panel,\n    data_pane,\n    custom_view\n)\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#common-patterns","level":2,"title":"Common patterns","text":"","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#filter-then-visualize","level":3,"title":"Filter then visualize","text":"<pre><code>pipelines:\n  filtered_data:\n    source: my_source\n    table: my_table\n    filters:\n      - type: widget\n        field: year\n      - type: widget\n        field: category\n\nlayouts:\n  - title: Dashboard\n    pipeline: filtered_data\n    views:\n      - type: hvplot\n        kind: line\n        x: date\n        y: sales\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#filter-transform-then-visualize","level":3,"title":"Filter, transform, then visualize","text":"<pre><code>pipelines:\n  processed_data:\n    source: my_source\n    table: my_table\n    filters:\n      - type: widget\n        field: region\n    transforms:\n      - type: columns\n        columns: [date, product, revenue]\n      - type: sort\n        by: [date]\n\nlayouts:\n  - title: Dashboard\n    pipeline: processed_data\n    views:\n      - type: hvplot\n        kind: bar\n        x: product\n        y: revenue\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#multiple-aggregations-of-same-data","level":3,"title":"Multiple aggregations of same data","text":"<pre><code>pipelines:\n  base:\n    source: sales\n    table: data\n    filters:\n      - type: widget\n        field: year\n\n  by_region:\n    pipeline: base\n    transforms:\n      - type: aggregate\n        method: sum\n        by: [region]\n\n  by_product:\n    pipeline: base\n    transforms:\n      - type: aggregate\n        method: sum\n        by: [product]\n\nlayouts:\n  - title: Sales Analysis\n    views:\n      - type: hvplot\n        pipeline: by_region\n        kind: bar\n      - type: hvplot\n        pipeline: by_product\n        kind: bar\n</code></pre>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/pipelines/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you understand pipelines:</p> <ul> <li>Views guide - Visualize your processed data</li> <li>Variables guide - Make pipelines dynamic</li> <li>Python API guide - Build complex applications</li> </ul>","path":["Configuration","Specs","Transforming data with pipelines"],"tags":[]},{"location":"configuration/spec/python-api/","level":1,"title":"Building dashboards with Python","text":"<p>Build Lumen dashboards programmatically using Python instead of YAML.</p>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#why-use-python","level":2,"title":"Why use Python?","text":"Aspect YAML Python Syntax Simple configuration Python code Learning curve Beginner-friendly Requires Python knowledge Iteration Very fast (edit + refresh) Fast (requires restart) Flexibility Good for standard patterns Full programmatic control Debugging Limited Full Python debugging Dynamic behavior Variables + templates Complete programmatic control Best for Most dashboards Complex applications, custom logic <p>Use Python when you need:</p> <ul> <li>Complex conditional logic</li> <li>Dynamic component generation</li> <li>Custom data processing not supported by transforms</li> <li>Integration with existing Python applications</li> <li>Full programmatic control</li> </ul>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#python-api-basics","level":2,"title":"Python API basics","text":"<p>The Python API mirrors the YAML structure using Python objects:</p> YAML Section Python Class <code>config</code> <code>lumen.Config</code> <code>sources</code> <code>lumen.sources.*</code> classes <code>pipelines</code> <code>lumen.Pipeline</code> <code>layouts</code> <code>lumen.Layout</code> <code>views</code> <code>lumen.views.*</code> classes","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#building-pipelines-in-python","level":2,"title":"Building pipelines in Python","text":"<p>Start by creating a Pipeline object. You can build declaratively (like YAML) or programmatically (step-by-step).</p>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#declarative-approach","level":3,"title":"Declarative approach","text":"<p>Use nested dictionaries mirroring YAML structure:</p> <pre><code>import lumen as lm\n\npipeline = lm.Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'tables': {\n            'penguins': 'https://datasets.holoviz.org/penguins/v1/penguins.csv'\n        }\n    },\n    'filters': [\n        {'type': 'widget', 'field': 'species'},\n        {'type': 'widget', 'field': 'island'},\n        {'type': 'widget', 'field': 'sex'},\n    ],\n    'transforms': [\n        {'type': 'aggregate', 'method': 'mean', 'by': ['species', 'sex', 'year']}\n    ]\n})\n\n# Preview the data\npipeline.data\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#programmatic-approach","level":3,"title":"Programmatic approach","text":"<p>Build step-by-step using Python methods:</p> <pre><code>import lumen as lm\nfrom lumen.sources import FileSource\n\n# Create source\nsource = FileSource(tables={\n    'penguins': 'https://datasets.holoviz.org/penguins/v1/penguins.csv'\n})\n\n# Create pipeline\npipeline = lm.Pipeline(source=source, table='penguins')\n\n# Add filters\npipeline.add_filter('widget', field='species')\npipeline.add_filter('widget', field='island')\npipeline.add_filter('widget', field='sex')\npipeline.add_filter('widget', field='year')\n\n# Add transforms\ncolumns = ['species', 'island', 'sex', 'year', 'bill_length_mm', 'bill_depth_mm']\npipeline.add_transform('columns', columns=columns)\n\n# Preview\npipeline.data.head()\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#preview-data-anytime","level":3,"title":"Preview data anytime","text":"<pre><code>pipeline.data          # Current filtered/transformed data\npipeline.data.head()   # First 5 rows\npipeline.data.shape    # Dimensions (rows, columns)\npipeline.data.columns  # Column names\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#automatic-filters","level":3,"title":"Automatic filters","text":"<p>Generate filters for all columns:</p> <pre><code>pipeline = lm.Pipeline(\n    source=source,\n    table='penguins',\n    filters='auto'  # Creates widget for every column\n)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#control-updates","level":3,"title":"Control updates","text":"<p>By default, pipelines update after every interaction. Disable for manual control:</p> <pre><code>pipeline = lm.Pipeline(\n    source=source,\n    table='penguins',\n    auto_update=False  # Manual updates only\n)\n\n# Later, trigger update manually\npipeline.update()\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#display-in-notebooks","level":3,"title":"Display in notebooks","text":"<p>Render pipelines interactively in Jupyter:</p> <pre><code>import panel as pn\n\npn.extension('tabulator')\n\npipeline  # Shows widgets + data preview\n</code></pre> <p>Show only controls:</p> <pre><code>pipeline.control_panel  # Just the filter widgets\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#creating-views","level":2,"title":"Creating views","text":"<p>Views visualize pipeline data. Attach views to pipelines, and they update automatically.</p>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#plot-views","level":3,"title":"Plot views","text":"<pre><code>from lumen.views import hvPlotView\n\nscatter = hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    by='species',\n    height=400,\n    responsive=True\n)\n\nscatter  # Display in notebook\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#table-views","level":3,"title":"Table views","text":"<pre><code>from lumen.views import Table\n\ntable = Table(\n    pipeline=pipeline,\n    page_size=10,\n    show_index=False,\n    sizing_mode='stretch_width'\n)\n\ntable\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#multiple-views-from-one-pipeline","level":3,"title":"Multiple views from one pipeline","text":"<pre><code># Create views\nscatter = hvPlotView(pipeline=pipeline, kind='scatter', x='bill_length_mm', y='bill_depth_mm')\nhist = hvPlotView(pipeline=pipeline, kind='hist', y='bill_length_mm')\ntable = Table(pipeline=pipeline, page_size=10)\n\n# Display together\nimport panel as pn\n\npn.Column(scatter, pn.Row(hist, table))\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#building-layouts","level":2,"title":"Building layouts","text":"<p>Use the <code>Layout</code> component to organize views:</p> <pre><code>import lumen as lm\n\n# Create pipeline\npipeline = lm.Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'tables': {'penguins': 'penguins.csv'}\n    },\n    'filters': [\n        {'type': 'widget', 'field': 'island'},\n        {'type': 'widget', 'field': 'sex'},\n    ]\n})\n\n# Create views\nscatter = lm.views.hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    by='species'\n)\n\ntable = lm.views.Table(pipeline=pipeline, page_size=10)\n\n# Create layout\nlayout = lm.Layout(\n    views={'scatter': scatter, 'table': table},\n    title='Palmer Penguins',\n    layout=[[0], [1]]  # Scatter on top, table below\n)\n\nlayout\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#building-complete-dashboards","level":2,"title":"Building complete dashboards","text":"<p>Combine everything into a <code>Dashboard</code> object:</p> <pre><code>import lumen as lm\nimport panel as pn\n\npn.extension('tabulator', design='material')\n\n# Create pipeline\npipeline = lm.Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'tables': {\n            'penguins': 'https://datasets.holoviz.org/penguins/v1/penguins.csv'\n        }\n    },\n    'filters': [\n        {'type': 'widget', 'field': 'island'},\n        {'type': 'widget', 'field': 'sex'},\n        {'type': 'widget', 'field': 'year'}\n    ],\n})\n\n# Create views\nscatter = lm.views.hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    by='species',\n    responsive=True,\n    height=400\n)\n\ntable = lm.views.Table(\n    pipeline=pipeline,\n    page_size=10,\n    sizing_mode='stretch_width'\n)\n\n# Create layout\nlayout = lm.Layout(\n    views={'scatter': scatter, 'table': table},\n    title='Palmer Penguins'\n)\n\n# Create dashboard\ndashboard = lm.Dashboard(\n    config={'title': 'Palmer Penguins', 'theme': 'dark'},\n    layouts=[layout]\n)\n\ndashboard\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#serve-the-dashboard","level":3,"title":"Serve the dashboard","text":"<p>Save as <code>app.py</code> and serve:</p> <pre><code>import lumen as lm\nimport panel as pn\n\npn.extension('tabulator')\n\n# ... (pipeline, views, layout code) ...\n\ndashboard = lm.Dashboard(\n    config={'title': 'My Dashboard'},\n    layouts=[layout]\n)\n\ndashboard.servable()  # Makes it servable\n</code></pre> <p>Then run:</p> <pre><code>panel serve app.py --show\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#integration-with-panel","level":2,"title":"Integration with Panel","text":"<p>Lumen components work seamlessly with Panel for maximum flexibility.</p>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#custom-layouts-with-panel","level":3,"title":"Custom layouts with Panel","text":"<pre><code>import panel as pn\nimport lumen as lm\n\npn.extension('tabulator')\n\n# Create pipeline\npipeline = lm.Pipeline.from_spec({...})\n\n# Create views\nscatter = lm.views.hvPlotView(pipeline=pipeline, kind='scatter', x='x', y='y')\ntable = lm.views.Table(pipeline=pipeline)\n\n# Custom Panel layout\napp = pn.template.MaterialTemplate(\n    title='Custom Dashboard',\n    sidebar=[\n        pipeline.control_panel,\n        pn.pane.Markdown('## About\\nThis dashboard shows...')\n    ],\n    main=[\n        pn.Row(scatter, table)\n    ]\n)\n\napp.servable()\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#combine-with-panel-widgets","level":3,"title":"Combine with Panel widgets","text":"<pre><code>import panel as pn\nimport lumen as lm\n\n# Lumen pipeline\npipeline = lm.Pipeline.from_spec({...})\n\n# Panel widget\ncustom_widget = pn.widgets.TextInput(name='Search', placeholder='Enter term...')\n\n# Combine\npn.Column(\n    '# My Dashboard',\n    custom_widget,\n    pipeline.control_panel,\n    lm.views.Table(pipeline=pipeline)\n)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#bind-to-custom-functions","level":3,"title":"Bind to custom functions","text":"<pre><code>import panel as pn\n\n@pn.depends(pipeline.param.data)\ndef custom_view(data):\n    return pn.pane.Markdown(f\"\"\"\n    ## Summary\n    - Total rows: {len(data)}\n    - Columns: {len(data.columns)}\n    - Memory: {data.memory_usage().sum() / 1024:.2f} KB\n    \"\"\")\n\npn.Column(\n    pipeline.control_panel,\n    custom_view,\n    lm.views.Table(pipeline=pipeline)\n)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#react-to-changes","level":3,"title":"React to changes","text":"<pre><code>import panel as pn\n\ndef on_data_change(event):\n    print(f'Data updated! New shape: {event.new.shape}')\n\npipeline.param.watch(on_data_change, 'data')\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#advanced-patterns","level":2,"title":"Advanced patterns","text":"","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#dynamic-pipeline-creation","level":3,"title":"Dynamic pipeline creation","text":"<pre><code>def create_pipeline(source_file, filter_fields):\n    \"\"\"Create pipeline based on parameters.\"\"\"\n    pipeline = lm.Pipeline.from_spec({\n        'source': {\n            'type': 'file',\n            'tables': {'data': source_file}\n        },\n        'filters': [\n            {'type': 'widget', 'field': field}\n            for field in filter_fields\n        ]\n    })\n    return pipeline\n\n# Use it\npipeline = create_pipeline('sales.csv', ['region', 'category', 'year'])\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#conditional-views","level":3,"title":"Conditional views","text":"<pre><code>def create_views(pipeline, plot_type='scatter'):\n    \"\"\"Create different views based on type.\"\"\"\n    if plot_type == 'scatter':\n        return lm.views.hvPlotView(\n            pipeline=pipeline,\n            kind='scatter',\n            x='x', y='y'\n        )\n    elif plot_type == 'line':\n        return lm.views.hvPlotView(\n            pipeline=pipeline,\n            kind='line',\n            x='date', y='value'\n        )\n    else:\n        return lm.views.Table(pipeline=pipeline)\n\nview = create_views(pipeline, plot_type='scatter')\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#multiple-pipelines","level":3,"title":"Multiple pipelines","text":"<pre><code># Create base pipeline\nbase_pipeline = lm.Pipeline.from_spec({\n    'source': {'type': 'file', 'tables': {'data': 'data.csv'}},\n    'filters': [{'type': 'widget', 'field': 'category'}]\n})\n\n# Create branches\nagg_pipeline = base_pipeline.chain(\n    transforms=[{'type': 'aggregate', 'method': 'sum', 'by': ['region']}]\n)\n\ntop_pipeline = base_pipeline.chain(\n    transforms=[\n        {'type': 'sort', 'by': ['revenue'], 'ascending': False},\n        {'type': 'query', 'query': 'index &lt; 10'}\n    ]\n)\n\n# Different views of same data\npn.Tabs(\n    ('Raw', lm.views.Table(pipeline=base_pipeline)),\n    ('Aggregated', lm.views.hvPlotView(pipeline=agg_pipeline, kind='bar')),\n    ('Top 10', lm.views.Table(pipeline=top_pipeline))\n)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#class-based-dashboards","level":3,"title":"Class-based dashboards","text":"<pre><code>import lumen as lm\nimport panel as pn\n\nclass SalesDashboard:\n    \"\"\"Reusable dashboard class.\"\"\"\n\n    def __init__(self, data_file):\n        self.pipeline = lm.Pipeline.from_spec({\n            'source': {'type': 'file', 'tables': {'data': data_file}},\n            'filters': [\n                {'type': 'widget', 'field': 'region'},\n                {'type': 'widget', 'field': 'year'}\n            ]\n        })\n\n        self.views = {\n            'scatter': lm.views.hvPlotView(\n                pipeline=self.pipeline,\n                kind='scatter',\n                x='date', y='revenue'\n            ),\n            'table': lm.views.Table(pipeline=self.pipeline)\n        }\n\n    def show(self):\n        \"\"\"Display the dashboard.\"\"\"\n        return pn.Column(\n            '# Sales Dashboard',\n            self.pipeline.control_panel,\n            pn.Row(self.views['scatter'], self.views['table'])\n        )\n\n# Use it\ndashboard = SalesDashboard('sales.csv')\ndashboard.show()\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#converting-between-yaml-and-python","level":2,"title":"Converting between YAML and Python","text":"","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#yaml-to-python","level":3,"title":"YAML to Python","text":"<p>Load YAML specs in Python:</p> <pre><code>import lumen as lm\n\n# From file\ndashboard = lm.Dashboard.from_yaml('dashboard.yaml')\n\n# From string\nyaml_spec = \"\"\"\nconfig:\n  title: My Dashboard\nsources:\n  data:\n    type: file\n    tables:\n      main: data.csv\n\"\"\"\ndashboard = lm.Dashboard.from_yaml_string(yaml_spec)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#python-to-yaml","level":3,"title":"Python to YAML","text":"<p>Export Python objects to YAML:</p> <pre><code>import lumen as lm\n\n# Create in Python\npipeline = lm.Pipeline.from_spec({...})\n\n# Export to YAML\nyaml_str = pipeline.to_yaml()\nprint(yaml_str)\n\n# Save to file\nwith open('pipeline.yaml', 'w') as f:\n    f.write(yaml_str)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#debugging","level":2,"title":"Debugging","text":"","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#print-current-data","level":3,"title":"Print current data","text":"<pre><code>pipeline.data         # View current data\nprint(pipeline.data.head())\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#check-filter-values","level":3,"title":"Check filter values","text":"<pre><code>for filter in pipeline.filters:\n    print(f'{filter.field}: {filter.value}')\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#inspect-transforms","level":3,"title":"Inspect transforms","text":"<pre><code>for transform in pipeline.transforms:\n    print(f'{transform.transform_type}: {transform.to_spec()}')\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#enable-logging","level":3,"title":"Enable logging","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger('lumen')\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#interactive-debugging","level":3,"title":"Interactive debugging","text":"<pre><code>import pdb\n\n# Add breakpoint\npdb.set_trace()\n\n# Or use ipdb in notebooks\nimport ipdb; ipdb.set_trace()\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#best-practices","level":2,"title":"Best practices","text":"","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#use-type-hints","level":3,"title":"Use type hints","text":"<pre><code>from typing import List\nimport lumen as lm\n\ndef create_filters(fields: List[str]) -&gt; List[dict]:\n    \"\"\"Create widget filters for fields.\"\"\"\n    return [\n        {'type': 'widget', 'field': field}\n        for field in fields\n    ]\n\npipeline = lm.Pipeline.from_spec({\n    'source': {...},\n    'filters': create_filters(['region', 'year'])\n})\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#error-handling","level":3,"title":"Error handling","text":"<pre><code>try:\n    pipeline = lm.Pipeline.from_spec({\n        'source': {'type': 'file', 'tables': {'data': 'missing.csv'}}\n    })\nexcept FileNotFoundError as e:\n    print(f'Data file not found: {e}')\n    # Fall back to alternative source\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#configuration-management","level":3,"title":"Configuration management","text":"<pre><code>import os\nfrom pathlib import Path\n\n# Use environment variables\nDATA_DIR = os.getenv('DATA_DIR', 'data')\nCACHE_DIR = os.getenv('CACHE_DIR', '.cache')\n\npipeline = lm.Pipeline.from_spec({\n    'source': {\n        'type': 'file',\n        'cache_dir': CACHE_DIR,\n        'tables': {\n            'data': Path(DATA_DIR) / 'sales.csv'\n        }\n    }\n})\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#reusable-components","level":3,"title":"Reusable components","text":"<pre><code># config.py\nDEFAULT_FILTERS = [\n    {'type': 'widget', 'field': 'region'},\n    {'type': 'widget', 'field': 'year'}\n]\n\nDEFAULT_PLOT_PARAMS = {\n    'responsive': True,\n    'height': 400\n}\n\n# app.py\nfrom config import DEFAULT_FILTERS, DEFAULT_PLOT_PARAMS\n\npipeline = lm.Pipeline.from_spec({\n    'source': {...},\n    'filters': DEFAULT_FILTERS\n})\n\nscatter = lm.views.hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    **DEFAULT_PLOT_PARAMS\n)\n</code></pre>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/python-api/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you can build dashboards in Python:</p> <ul> <li>Panel documentation - Learn more about Panel layouts and widgets</li> <li>Customization guide - Build custom components</li> <li>Deployment guide - Deploy Python dashboards</li> </ul>","path":["Configuration","Specs","Building dashboards with Python"],"tags":[]},{"location":"configuration/spec/sources/","level":1,"title":"Loading data with sources","text":"<p>Sources load data into your dashboard from files, databases, or APIs.</p> <p>Sources provide raw data that can be transformed with Pipelines.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#source-fundamentals","level":2,"title":"Source fundamentals","text":"<p>Every Lumen dashboard needs at least one source. Sources define where data comes from and how to access it.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#basic-source-syntax","level":3,"title":"Basic source syntax","text":"<pre><code>sources:\n  source_name:           # Choose any name\n    type: source_type    # file, duckdb, intake, rest, etc.\n    # Additional parameters depend on type\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#available-source-types","level":3,"title":"Available source types","text":"Type Purpose Best for <code>file</code> CSV, Excel, Parquet, JSON files Local or remote file data <code>duckdb</code> DuckDB SQL queries SQL-based data access <code>intake</code> Intake catalog entries Data catalogs <code>rest</code> REST API endpoints API data <code>live</code> Live website status checks Website monitoring <p>This guide focuses on <code>file</code> sources (most common). See Lumen's source reference for other types.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#file-sources","level":2,"title":"File sources","text":"<p>FileSource loads data from files in various formats:</p> <ul> <li>CSV - Comma-separated values</li> <li>Excel - XLSX and XLS files  </li> <li>Parquet - Columnar storage format</li> <li>JSON - JavaScript Object Notation</li> </ul>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#local-files","level":3,"title":"Local files","text":"<p>Load files from your local filesystem:</p> YAMLPython <pre><code>sources:\n  local_source:\n    type: file\n    tables:\n      my_data: data/sales.csv\n\nlayouts:\n  - title: Sales Data\n    source: local_source\n    views:\n      - type: table\n        table: my_data\n</code></pre> <pre><code>from lumen.pipeline import Pipeline\n\npipeline = Pipeline.from_spec({\n    \"source\": {\n        \"type\": \"file\",\n        \"tables\": {\"my_data\": \"data/sales.csv\"}\n    },\n})\n\npipeline.data  # Preview in notebook\n</code></pre> <p>File paths can be relative (to your YAML file) or absolute.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#remote-files","level":3,"title":"Remote files","text":"<p>Load files from URLs:</p> YAMLPython <pre><code>sources:\n  remote_source:\n    type: file\n    tables:\n      penguins: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguin Data\n    source: remote_source\n    views:\n      - type: table\n        table: penguins\n</code></pre> <pre><code>from lumen.pipeline import Pipeline\n\ndata_url = \"https://datasets.holoviz.org/penguins/v1/penguins.csv\"\npipeline = Pipeline.from_spec({\n    \"source\": {\n        \"type\": \"file\",\n        \"tables\": {\"penguins\": data_url}\n    },\n})\n\npipeline.data\n</code></pre> <p>Remote files load over HTTP/HTTPS. Lumen downloads them when needed.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#multiple-tables","level":3,"title":"Multiple tables","text":"<p>Sources can provide multiple tables:</p> <pre><code>sources:\n  sales_data:\n    type: file\n    tables:\n      customers: data/customers.csv\n      orders: data/orders.csv\n      products: data/products.csv\n</code></pre> <p>Reference each table independently in pipelines or layouts:</p> <pre><code>pipelines:\n  customer_pipeline:\n    source: sales_data\n    table: customers      # Uses the customers table\n\n  order_pipeline:\n    source: sales_data\n    table: orders         # Uses the orders table\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#file-format-options","level":3,"title":"File format options","text":"<p>Pass format-specific options using the <code>kwargs</code> parameter:</p> CSV with custom delimiterExcel with specific sheetParquet with engine <pre><code>sources:\n  tsv_source:\n    type: file\n    tables:\n      data: data.tsv\n    kwargs:\n      sep: \"\\t\"        # Tab-separated\n      header: 0\n</code></pre> <pre><code>sources:\n  excel_source:\n    type: file\n    tables:\n      q1_data: sales.xlsx\n    kwargs:\n      sheet_name: \"Q1 Sales\"\n</code></pre> <pre><code>sources:\n  parquet_source:\n    type: file\n    tables:\n      large_data: data.parq\n    kwargs:\n      engine: fastparquet\n</code></pre> <p>These <code>kwargs</code> pass directly to pandas read functions (<code>read_csv</code>, <code>read_excel</code>, etc.).</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#caching-data","level":2,"title":"Caching data","text":"<p>Caching saves remote data locally to speed up dashboard loading. This is especially useful for large files.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#basic-caching","level":3,"title":"Basic caching","text":"<p>Enable caching with the <code>cache_dir</code> parameter:</p> YAMLPython <pre><code>sources:\n  large_source:\n    type: file\n    cache_dir: cache           # Directory for cached data\n    tables:\n      nyc_taxi: https://s3.amazonaws.com/datashader-data/nyc_taxi_wide.parq\n    kwargs:\n      engine: fastparquet\n\nlayouts:\n  - title: NYC Taxi Data\n    source: large_source\n    views:\n      - type: table\n        table: nyc_taxi\n</code></pre> <pre><code>from lumen.pipeline import Pipeline\n\ndata_url = \"https://s3.amazonaws.com/datashader-data/nyc_taxi_wide.parq\"\npipeline = Pipeline.from_spec({\n    \"source\": {\n        \"type\": \"file\",\n        \"cache_dir\": \"cache\",\n        \"tables\": {\"nyc_taxi\": data_url},\n        \"kwargs\": {\"engine\": \"fastparquet\"},\n    },\n})\n\npipeline.data\n</code></pre> <p>First load timing</p> <p>Initial load may take several minutes for large files. Subsequent loads are much faster using the cached version.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#how-caching-works","level":3,"title":"How caching works","text":"<ol> <li>First load: Lumen downloads the file and saves it to <code>cache_dir</code> as Parquet</li> <li>Subsequent loads: Lumen reads from the local cache instead of downloading again</li> <li>Cache structure: Lumen creates the cache directory if it doesn't exist</li> </ol> <p>Cache files are stored as:</p> <ul> <li><code>{cache_dir}/{table_name}.parq</code> - Parquet data file</li> <li><code>{cache_dir}/{table_name}.json</code> - Schema metadata</li> </ul>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#cache-strategies","level":3,"title":"Cache strategies","text":"<p>Sources support different caching strategies via <code>cache_per_query</code>:</p> Strategy Behavior Best for <code>cache_per_query: false</code> Cache entire table Small to medium datasets <code>cache_per_query: true</code> Cache each filtered query separately Large datasets with many filters <p>Example with per-query caching:</p> <pre><code>sources:\n  large_db:\n    type: duckdb\n    uri: large_database.db\n    cache_dir: cache\n    cache_per_query: true    # Cache filtered results separately\n</code></pre> <p>This is useful when users filter data in many different ways‚Äîeach unique filter combination caches separately.</p>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#pre-caching","level":3,"title":"Pre-caching","text":"<p>Pre-populate caches with expected queries to eliminate initial loading delays.</p> <p>Define pre-cache configurations in two forms:</p> <p>Form 1: Cross-product of values</p> <pre><code>sources:\n  weather_data:\n    type: file\n    cache_dir: cache\n    cache_per_query: true\n    tables:\n      weather: weather.csv\n    pre_cache:\n      filters:\n        region: [north, south, east, west]\n        year: [2020, 2021, 2022, 2023]\n</code></pre> <p>This creates 16 cache entries (4 regions √ó 4 years).</p> <p>Form 2: Explicit combinations</p> <pre><code>sources:\n  weather_data:\n    type: file\n    cache_dir: cache\n    cache_per_query: true\n    tables:\n      weather: weather.csv\n    pre_cache:\n      - filters:\n          region: north\n          year: 2023\n      - filters:\n          region: south\n          year: 2023\n</code></pre> <p>This creates only 2 specific cache entries.</p> <p>To populate caches, initialize a pipeline and trigger loading:</p> <pre><code>from lumen.pipeline import Pipeline\n\npipeline = Pipeline.from_spec({\n    \"source\": {\n        \"type\": \"file\",\n        \"cache_dir\": \"cache\",\n        \"cache_per_query\": True,\n        \"tables\": {\"weather\": \"weather.csv\"},\n        \"pre_cache\": {\n            \"filters\": {\n                \"region\": [\"north\", \"south\"],\n                \"year\": [2022, 2023]\n            }\n        }\n    }\n})\n\n# Trigger cache population\npipeline.populate_cache()\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#source-parameters-reference","level":2,"title":"Source parameters reference","text":"","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#common-parameters","level":3,"title":"Common parameters","text":"<p>These parameters work with all source types:</p> Parameter Type Purpose <code>type</code> string Source type (required) <code>tables</code> dict Mapping of table names to file paths/URLs <code>cache_dir</code> string Directory for caching data <code>cache_per_query</code> boolean Cache strategy (table vs query) <code>kwargs</code> dict Format-specific options","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#filesource-specific-parameters","level":3,"title":"FileSource-specific parameters","text":"Parameter Type Purpose Default <code>tables</code> dict Table name ‚Üí file path mapping Required <code>root</code> string Root directory for relative paths Current directory <code>kwargs</code> dict Pandas read function parameters <code>{}</code>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#common-patterns","level":2,"title":"Common patterns","text":"","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#simple-local-file","level":3,"title":"Simple local file","text":"<pre><code>sources:\n  data:\n    type: file\n    tables:\n      main: data.csv\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#multiple-remote-files-with-caching","level":3,"title":"Multiple remote files with caching","text":"<pre><code>sources:\n  datasets:\n    type: file\n    cache_dir: .cache\n    tables:\n      penguins: https://datasets.holoviz.org/penguins/v1/penguins.csv\n      iris: https://datasets.holoviz.org/iris/v1/iris.csv\n      stocks: https://datasets.holoviz.org/stocks/v1/stocks.csv\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#csv-with-custom-parsing","level":3,"title":"CSV with custom parsing","text":"<pre><code>sources:\n  custom_csv:\n    type: file\n    tables:\n      data: data.csv\n    kwargs:\n      sep: \"|\"              # Pipe-separated\n      parse_dates: [date]   # Parse date column\n      dtype:\n        id: str             # Force ID as string\n        value: float\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#large-file-with-aggressive-caching","level":3,"title":"Large file with aggressive caching","text":"<pre><code>sources:\n  big_data:\n    type: file\n    cache_dir: cache\n    cache_per_query: true\n    tables:\n      large: https://example.com/huge_dataset.parq\n    kwargs:\n      engine: fastparquet\n    pre_cache:\n      filters:\n        category: [A, B, C]\n        year: [2020, 2021, 2022]\n</code></pre>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/sources/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you can load data:</p> <ul> <li>Pipelines guide - Filter and transform your data</li> <li>Views guide - Visualize your data</li> <li>Variables guide - Make sources dynamic with variables</li> </ul>","path":["Configuration","Specs","Loading data with sources"],"tags":[]},{"location":"configuration/spec/variables/","level":1,"title":"Dynamic configuration with variables","text":"<p>Variables make dashboards dynamic by parameterizing configuration values.</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#variable-types","level":2,"title":"Variable types","text":"<p>Lumen supports three types of variables:</p> Type Syntax Scope Evaluated Internal variables <code>$variables.name</code> Within spec Dynamically at runtime Source references <code>$source.table.field</code> Within spec Dynamically at runtime External variables <code>{{env(\"VAR\")}}</code> From environment Once at initialization <p>Use <code>$</code> for internal dynamic references. Use <code>{{}}</code> for external values resolved at startup.</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#internal-variables","level":2,"title":"Internal variables","text":"<p>Internal variables create reusable parameters within your specification.</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#variables-section","level":3,"title":"Variables section","text":"<p>Define variables in the <code>variables</code> section:</p> <pre><code>variables:\n  my_variable:\n    type: widget              # Makes it interactive\n    kind: Select              # Widget type\n    value: default_value      # Initial value\n    options: [opt1, opt2]     # Available choices\n</code></pre> <p>Reference them anywhere using <code>$variables.name</code>:</p> <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: $variables.my_variable  # Uses the variable value\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#widget-driven-variables","level":3,"title":"Widget-driven variables","text":"<p>Create interactive variables with widgets:</p> YAMLEffect <pre><code>variables:\n  columns:\n    type: widget\n    kind: MultiSelect\n    value: [Open, High, Low, Close]\n    options: [Open, High, Low, Close, Volume, Adj Close]\n    size: 7\n\nsources:\n  stock_data:\n    type: file\n    tables:\n      ticker: https://raw.githubusercontent.com/matplotlib/sample_data/master/aapl.csv\n    kwargs:\n      index_col: Date\n      parse_dates: [Date]\n\npipelines:\n  ticker_pipe:\n    source: stock_data\n    table: ticker\n    transforms:\n      - type: columns\n        columns: $variables.columns    # Uses selected columns\n\nlayouts:\n  - title: Stock Data\n    pipeline: ticker_pipe\n    views:\n      - type: hvplot\n        kind: line\n</code></pre> <ul> <li>Widget appears in sidebar for selecting columns</li> <li>Changing selection updates the plot</li> <li>Only selected columns pass through pipeline</li> </ul>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#variable-widget-types","level":3,"title":"Variable widget types","text":"<p>Common widget types for variables:</p> Widget Purpose Example <code>TextInput</code> Free text entry File names, search terms <code>Select</code> Single selection Category, region <code>MultiSelect</code> Multiple selections Columns, tags <code>IntSlider</code> Integer range Years, counts <code>FloatSlider</code> Float range Thresholds, ratios <code>DatePicker</code> Date selection Start/end dates <code>Checkbox</code> Boolean toggle Enable/disable features","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#text-input-variable","level":3,"title":"Text input variable","text":"<pre><code>variables:\n  ticker:\n    type: widget\n    kind: TextInput\n    value: AAPL.csv\n    placeholder: Enter ticker symbol\n\nsources:\n  stock_data:\n    type: file\n    tables:\n      data: $variables.ticker  # Uses entered filename\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#slider-variable","level":3,"title":"Slider variable","text":"<pre><code>variables:\n  year:\n    type: widget\n    kind: IntSlider\n    value: 2023\n    start: 2020\n    end: 2025\n    step: 1\n\npipelines:\n  filtered:\n    source: data_source\n    table: data\n    filters:\n      - type: constant\n        field: year\n        value: $variables.year  # Filters by slider value\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#date-picker-variable","level":3,"title":"Date picker variable","text":"<pre><code>variables:\n  start_date:\n    type: widget\n    kind: DatePicker\n    value: '2023-01-01'\n  end_date:\n    type: widget\n    kind: DatePicker\n    value: '2023-12-31'\n\npipelines:\n  date_filtered:\n    source: data_source\n    table: data\n    filters:\n      - type: constant\n        field: date\n        value: {start: $variables.start_date, end: $variables.end_date}\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#source-references","level":2,"title":"Source references","text":"<p>Reference data from sources to create dynamic relationships.</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#reference-syntax","level":3,"title":"Reference syntax","text":"<p>Source references use <code>$</code> notation:</p> Syntax References <code>$source_name</code> The entire source object <code>$source_name.table_name</code> A specific table from the source <code>$source_name.table_name.column</code> Unique values from a column","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#column-value-references","level":3,"title":"Column value references","text":"<p>Reference unique values from a column:</p> YAMLwebsites.csvEffect <pre><code>sources:\n  websites_csv:\n    type: file\n    tables:\n      websites: websites.csv\n\n  live_checker:\n    type: live\n    urls: $websites_csv.websites.url  # Gets unique URLs from CSV\n\nlayouts:\n  - title: Website Status\n    source: live_checker\n    views:\n      - type: table\n</code></pre> <pre><code>url\nhttps://google.com\nhttps://python.org\nhttps://anaconda.com\n</code></pre> <p>The <code>live</code> source checks status of all URLs found in the CSV's <code>url</code> column.</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#chaining-references","level":3,"title":"Chaining references","text":"<p>Use one source's data to configure another:</p> <pre><code>sources:\n  config:\n    type: file\n    tables:\n      settings: config.csv\n\n  data:\n    type: file\n    tables:\n      main: $config.settings.data_path  # Path from config\n    cache_dir: $config.settings.cache_dir\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#dynamic-source-selection","level":3,"title":"Dynamic source selection","text":"<p>Reference sources in pipelines:</p> <pre><code>variables:\n  data_source:\n    type: widget\n    kind: Select\n    value: source_a\n    options: [source_a, source_b, source_c]\n\npipelines:\n  dynamic:\n    source: $variables.data_source  # Uses selected source\n    table: data\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#external-variables-templating","level":2,"title":"External variables (templating)","text":"<p>External variables inject values from outside the specification using Jinja2 syntax.</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#environment-variables","level":3,"title":"Environment variables","text":"<p>Read from system environment:</p> YAMLSetting environment <pre><code>sources:\n  database:\n    type: duckdb\n    uri: {{ env(\"DATABASE_URL\") }}  # From environment\n\nlayouts:\n  - title: Data for {{ env(\"USER\") }}\n    source: database\n    views:\n      - type: table\n</code></pre> <pre><code>export DATABASE_URL=\"postgresql://localhost/mydb\"\nexport USER=\"alice\"\nlumen serve dashboard.yaml\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#command-line-arguments","level":3,"title":"Command-line arguments","text":"<p>Pass variables when serving:</p> YAMLCommand <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: {{ DATA_FILE }}  # From command line\n\nlayouts:\n  - title: Dashboard for {{ USER }}\n    source: data\n    views:\n      - type: table\n</code></pre> <pre><code>lumen serve dashboard.yaml --template-vars=\"{'DATA_FILE': 'sales.csv', 'USER': 'Bob'}\"\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#shell-commands","level":3,"title":"Shell commands","text":"<p>Execute shell commands for values:</p> YAMLResult <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: data.csv\n\nlayouts:\n  - title: {{ shell(\"echo 'Dashboard created on $(date +%Y-%m-%d)'\") }}\n    source: data\n    views:\n      - type: table\n</code></pre> <p>Title becomes: \"Dashboard created on 2024-01-15\"</p>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#http-cookies","level":3,"title":"HTTP cookies","text":"<p>Read from request cookies:</p> <pre><code>layouts:\n  - title: Dashboard for {{ cookie(\"username\") }}\n    source: data\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#http-headers","level":3,"title":"HTTP headers","text":"<p>Read from request headers:</p> <pre><code>sources:\n  data:\n    type: file\n    tables:\n      table: data_{{ header(\"X-Region\") }}.csv  # Region-specific file\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#oauth-tokens","level":3,"title":"OAuth tokens","text":"<p>Access OAuth user information:</p> <pre><code>config:\n  auth:\n    type: oauth\n\nlayouts:\n  - title: Dashboard for {{ oauth(\"user\") }}\n    source: data\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#variable-scope-and-resolution","level":2,"title":"Variable scope and resolution","text":"","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#resolution-timing","level":3,"title":"Resolution timing","text":"Variable Type When Resolved External (<code>{{}}</code>) Once at dashboard initialization Internal (<code>$</code>) Dynamically on each update <p>Example:</p> <pre><code>variables:\n  threshold:\n    type: widget\n    value: 100\n\nsources:\n  data:\n    type: file\n    tables:\n      # Resolved once at startup\n      table: {{ env(\"DATA_FILE\") }}\n\npipelines:\n  filtered:\n    source: data\n    table: table\n    transforms:\n      - type: query\n        # Resolved dynamically when threshold changes\n        query: \"value &gt; $variables.threshold\"\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#variable-precedence","level":3,"title":"Variable precedence","text":"<p>When multiple variable sources exist:</p> <ol> <li>External variables resolve first (initialization)</li> <li>Internal variables resolve during execution</li> <li>Later references can use earlier variables</li> </ol> <pre><code># This works:\nvariables:\n  base_path:\n    type: widget\n    value: {{ env(\"DATA_DIR\") }}  # External first\n\nsources:\n  data:\n    type: file\n    tables:\n      table: $variables.base_path/data.csv  # Then internal\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#common-patterns","level":2,"title":"Common patterns","text":"","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#user-selectable-data-file","level":3,"title":"User-selectable data file","text":"<pre><code>variables:\n  dataset:\n    type: widget\n    kind: Select\n    value: penguins\n    options: [penguins, iris, stocks]\n\nsources:\n  data:\n    type: file\n    tables:\n      table: https://datasets.holoviz.org/$variables.dataset/v1/$variables.dataset.csv\n\nlayouts:\n  - title: $variables.dataset Analysis\n    source: data\n    views:\n      - type: table\n        table: table\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#dynamic-filtering-threshold","level":3,"title":"Dynamic filtering threshold","text":"<pre><code>variables:\n  min_value:\n    type: widget\n    kind: IntSlider\n    value: 100\n    start: 0\n    end: 1000\n    step: 10\n\npipelines:\n  filtered:\n    source: data_source\n    table: data\n    transforms:\n      - type: query\n        query: \"sales &gt;= $variables.min_value\"\n\nlayouts:\n  - title: Sales Above $variables.min_value\n    pipeline: filtered\n    views:\n      - type: hvplot\n        kind: bar\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#configuration-from-file","level":3,"title":"Configuration from file","text":"config.csvdashboard.yaml <pre><code>setting,value\ndata_path,/data/sales.csv\ncache_enabled,true\ntheme,dark\n</code></pre> <pre><code>sources:\n  config:\n    type: file\n    tables:\n      settings: config.csv\n\n  data:\n    type: file\n    tables:\n      sales: $config.settings.data_path\n    cache_dir: cache\n\nconfig:\n  theme: $config.settings.theme\n\nlayouts:\n  - title: Sales Dashboard\n    source: data\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#multi-source-federation","level":3,"title":"Multi-source federation","text":"<pre><code>sources:\n  source_list:\n    type: file\n    tables:\n      sources: sources.csv  # Contains: name, url\n\n  federated:\n    type: file\n    tables: $source_list.sources.name  # Table per row\n    urls: $source_list.sources.url     # URLs from CSV\n\nlayouts:\n  - title: All Sources\n    source: federated\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#environment-specific-configuration","level":3,"title":"Environment-specific configuration","text":"<pre><code>config:\n  title: {{ env(\"APP_NAME\", \"My Dashboard\") }}  # With default\n\nsources:\n  data:\n    type: {{ env(\"DB_TYPE\", \"file\") }}\n    uri: {{ env(\"DATABASE_URL\") }}\n    cache_dir: {{ env(\"CACHE_DIR\", \".cache\") }}\n\nlayouts:\n  - title: {{ env(\"ENVIRONMENT\") }} Environment\n    source: data\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#best-practices","level":2,"title":"Best practices","text":"","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#when-to-use-each-type","level":3,"title":"When to use each type","text":"Use Case Variable Type Why User selections Internal (<code>$variables</code>) Dynamic updates Data relationships Source references (<code>$source</code>) Automatic synchronization Deployment config External (<code>{{env()}}</code>) Separation of concerns Secrets External (<code>{{env()}}</code>) Security Dynamic paths Both Flexibility","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#security-considerations","level":3,"title":"Security considerations","text":"<p>Never hardcode secrets</p> <p>Don't put API keys, passwords, or tokens directly in YAML:</p> <pre><code># ‚ùå Bad - secret in file\nsources:\n  api:\n    token: \"secret-api-key-12345\"\n\n# ‚úÖ Good - secret from environment\nsources:\n  api:\n    token: {{ env(\"API_KEY\") }}\n</code></pre> <p>Set secrets via environment variables:</p> <pre><code>export API_KEY=\"secret-api-key-12345\"\nlumen serve dashboard.yaml\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#variable-naming","level":3,"title":"Variable naming","text":"<p>Use clear, descriptive names:</p> <pre><code># ‚ùå Bad - unclear\nvariables:\n  v1:\n    type: widget\n    value: 100\n\n# ‚úÖ Good - descriptive\nvariables:\n  sales_threshold:\n    type: widget\n    value: 100\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#default-values","level":3,"title":"Default values","text":"<p>Always provide sensible defaults:</p> <pre><code>variables:\n  year:\n    type: widget\n    kind: IntSlider\n    value: 2023        # Default value\n    start: 2020\n    end: 2025\n</code></pre>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/variables/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you can use variables:</p> <ul> <li>Customization guide - Build custom variable types</li> <li>Deployment guide - Manage variables in production</li> <li>Python API guide - Work with variables programmatically</li> </ul>","path":["Configuration","Specs","Dynamic configuration with variables"],"tags":[]},{"location":"configuration/spec/views/","level":1,"title":"Visualizing data with views","text":"<p>Views display your data as plots, tables, indicators, and other visual components.</p> <p>Different from Analyses: For computational results (statistics, calculations, tests), see Analyses. Views are for visualizing data; analyses are for computing insights from data.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#view-fundamentals","level":2,"title":"View fundamentals","text":"<p>Views are the final output of your dashboard. They transform data into visual representations that users can see and interact with.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#basic-view-syntax","level":3,"title":"Basic view syntax","text":"YAMLPython <pre><code>layouts:\n  - title: My Dashboard\n    source: my_source      # Or pipeline: my_pipeline\n    views:\n      - type: view_type\n        # View-specific parameters\n</code></pre> <pre><code>from lumen.views import Table, hvPlotView\n\nview = hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='x_column',\n    y='y_column'\n)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#connecting-views-to-data","level":3,"title":"Connecting views to data","text":"<p>Views get data from either sources or pipelines:</p> From source (raw data)From pipeline (processed data) <pre><code>layouts:\n  - title: Dashboard\n    source: my_source\n    views:\n      - type: table\n        table: my_table\n</code></pre> <pre><code>layouts:\n  - title: Dashboard\n    pipeline: my_pipeline\n    views:\n      - type: table\n</code></pre> <p>Use pipelines when you need filtering or transforms. Use sources directly for raw data.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#available-view-types","level":2,"title":"Available view types","text":"View Type Purpose Best for <code>hvplot</code> Interactive plots Scatter, line, bar, hist, box, etc. <code>table</code> Data tables Displaying tabular data <code>indicator</code> Single metrics KPIs, status values <code>download</code> Download buttons Enabling data export <code>hvplot_ui</code> Plot with UI controls Exploratory analysis <code>altair</code> Altair visualizations Grammar of graphics plots <code>plotly</code> Plotly charts 3D plots, complex interactivity <p>This guide focuses on the most common types: <code>hvplot</code> and <code>table</code>.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#plot-views-hvplot","level":2,"title":"Plot views (hvPlot)","text":"<p>The <code>hvplot</code> view type creates interactive plots using hvPlot.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#plot-kinds","level":3,"title":"Plot kinds","text":"<p>hvPlot supports many plot types via the <code>kind</code> parameter:</p> Kind Description Use case <code>scatter</code> Scatter plot Relationships between variables <code>line</code> Line plot Time series, trends <code>bar</code> Bar chart Comparing categories <code>hist</code> Histogram Distribution of values <code>box</code> Box plot Statistical distribution <code>area</code> Area plot Cumulative values over time <code>heatmap</code> Heat map 2D data matrices <code>violin</code> Violin plot Distribution with density","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#scatter-plots","level":3,"title":"Scatter plots","text":"<p>Show relationships between two variables:</p> YAMLPython <pre><code>views:\n  - type: hvplot\n    kind: scatter\n    x: bill_length_mm\n    y: bill_depth_mm\n    color: species           # Color by category\n    size: body_mass_g        # Size by value\n    responsive: true\n    height: 400\n</code></pre> <pre><code>from lumen.views import hvPlotView\n\nscatter = hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='bill_length_mm',\n    y='bill_depth_mm',\n    color='species',\n    size='body_mass_g',\n    responsive=True,\n    height=400\n)\n</code></pre> <p>Common scatter parameters:</p> Parameter Type Purpose <code>x</code> string Column for x-axis <code>y</code> string Column for y-axis <code>color</code> string Column for color coding <code>size</code> string/int Column for point size, or fixed size <code>alpha</code> float Transparency (0-1)","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#line-plots","level":3,"title":"Line plots","text":"<p>Display trends over time or continuous variables:</p> YAMLPython <pre><code>views:\n  - type: hvplot\n    kind: line\n    x: date\n    y: revenue\n    by: region              # Create separate lines\n    responsive: true\n    legend: 'top_right'\n</code></pre> <pre><code>line = hvPlotView(\n    pipeline=pipeline,\n    kind='line',\n    x='date',\n    y='revenue',\n    by='region',\n    responsive=True,\n    legend='top_right'\n)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#bar-charts","level":3,"title":"Bar charts","text":"<p>Compare values across categories:</p> YAMLPython <pre><code>views:\n  - type: hvplot\n    kind: bar\n    x: product\n    y: sales\n    color: region\n    stacked: true           # Stack bars by color\n    rot: 45                 # Rotate x-axis labels\n</code></pre> <pre><code>bar = hvPlotView(\n    pipeline=pipeline,\n    kind='bar',\n    x='product',\n    y='sales',\n    color='region',\n    stacked=True,\n    rot=45\n)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#histograms","level":3,"title":"Histograms","text":"<p>Show distribution of values:</p> YAMLPython <pre><code>views:\n  - type: hvplot\n    kind: hist\n    y: bill_length_mm\n    bins: 30                # Number of bins\n    alpha: 0.7\n    color: '#ff6600'\n</code></pre> <pre><code>hist = hvPlotView(\n    pipeline=pipeline,\n    kind='hist',\n    y='bill_length_mm',\n    bins=30,\n    alpha=0.7,\n    color='#ff6600'\n)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#box-plots","level":3,"title":"Box plots","text":"<p>Display statistical distribution:</p> <pre><code>views:\n  - type: hvplot\n    kind: box\n    y: bill_length_mm\n    by: species              # Create box for each category\n    legend: false\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#multiple-series","level":3,"title":"Multiple series","text":"<p>Plot multiple columns on the same chart:</p> <pre><code>views:\n  - type: hvplot\n    kind: line\n    x: date\n    y: [revenue, expenses, profit]  # Multiple y-columns\n    responsive: true\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#plot-customization","level":3,"title":"Plot customization","text":"<p>Common customization parameters:</p> Parameter Type Purpose Example <code>title</code> string Plot title \"Sales Trends\" <code>xlabel</code> string X-axis label \"Date\" <code>ylabel</code> string Y-axis label \"Revenue ($)\" <code>height</code> int Plot height (pixels) 400 <code>width</code> int Plot width (pixels) 800 <code>responsive</code> bool Resize with browser true <code>legend</code> string/bool Legend position 'top_right', false <code>xlim</code> tuple X-axis range (0, 100) <code>ylim</code> tuple Y-axis range (0, 1000) <code>rot</code> int Label rotation (degrees) 45 <code>fontsize</code> dict Font sizes {title: 16, labels: 12} <code>grid</code> bool Show gridlines true <code>logx</code> bool Logarithmic x-axis true <code>logy</code> bool Logarithmic y-axis true <p>Example with many customizations:</p> <pre><code>views:\n  - type: hvplot\n    kind: scatter\n    x: gdp_per_capita\n    y: life_expectancy\n    color: continent\n    size: population\n    title: \"Health vs Wealth\"\n    xlabel: \"GDP per Capita ($)\"\n    ylabel: \"Life Expectancy (years)\"\n    logx: true\n    xlim: [100, 100000]\n    ylim: [40, 90]\n    height: 500\n    responsive: true\n    legend: 'top_left'\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#table-views","level":2,"title":"Table views","text":"<p>Display data in interactive tables with sorting, pagination, and filtering.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#basic-table","level":3,"title":"Basic table","text":"YAMLPython <pre><code>views:\n  - type: table\n    show_index: false       # Hide row index\n    page_size: 20           # Rows per page\n    height: 400\n</code></pre> <pre><code>from lumen.views import Table\n\ntable = Table(\n    pipeline=pipeline,\n    show_index=False,\n    page_size=20,\n    height=400\n)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#table-parameters","level":3,"title":"Table parameters","text":"Parameter Type Purpose Default <code>show_index</code> bool Display row numbers true <code>page_size</code> int Rows per page 20 <code>pagination</code> string Pagination type 'local' <code>height</code> int Table height (pixels) 400 <code>width</code> int Table width (pixels) None <code>theme</code> string Color theme 'default' <code>disabled</code> bool Disable interactions false <code>selectable</code> bool/int Row selection false","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#table-themes","level":3,"title":"Table themes","text":"<p>Available themes for table styling:</p> <pre><code>views:\n  - type: table\n    theme: midnight          # Options: default, modern, simple, midnight, site\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#column-formatting","level":3,"title":"Column formatting","text":"<p>Format specific columns:</p> <pre><code>views:\n  - type: table\n    formatters:\n      price: {type: money, precision: 2}\n      date: {type: datetime, format: '%Y-%m-%d'}\n      percent: {type: percentage, precision: 1}\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#selectable-rows","level":3,"title":"Selectable rows","text":"<p>Enable row selection:</p> <pre><code>views:\n  - type: table\n    selectable: 1            # Select single row (use 'checkbox' for multiple)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#remote-pagination","level":3,"title":"Remote pagination","text":"<p>For large datasets, use remote pagination:</p> <pre><code>views:\n  - type: table\n    pagination: remote       # Load pages from server\n    page_size: 50\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#indicator-views","level":2,"title":"Indicator views","text":"<p>Display single metrics or KPIs.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#number-indicator","level":3,"title":"Number indicator","text":"<p>Show a single value:</p> <pre><code>views:\n  - type: indicator\n    field: revenue           # Column to display\n    title: \"Total Revenue\"\n    format: \"${value:,.0f}\"  # Format as currency\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#gauge-indicator","level":3,"title":"Gauge indicator","text":"<p>Display value with min/max range:</p> <pre><code>views:\n  - type: indicator\n    kind: gauge\n    field: completion_rate\n    title: \"Completion Rate\"\n    min_value: 0\n    max_value: 100\n    format: \"{value:.1f}%\"\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#download-views","level":2,"title":"Download views","text":"<p>Enable data export:</p> <pre><code>views:\n  - type: download\n    format: csv              # csv, xlsx, json\n    button_type: 'primary'\n</code></pre> <p>See the Downloads guide for details.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#arranging-views","level":2,"title":"Arranging views","text":"<p>Control how views appear in your dashboard.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#default-arrangement","level":3,"title":"Default arrangement","text":"<p>Views stack vertically by default:</p> <pre><code>layouts:\n  - title: Dashboard\n    views:\n      - type: hvplot\n        kind: scatter\n      - type: hvplot\n        kind: hist\n      - type: table\n</code></pre> <p>Result: Three views stacked vertically.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#grid-layout","level":3,"title":"Grid layout","text":"<p>Use the <code>layout</code> parameter to create grids:</p> <pre><code>layouts:\n  - title: Dashboard\n    pipeline: my_pipeline\n    layout: [[0, 1], [2, 3]]  # 2x2 grid\n    views:\n      - type: hvplot          # View 0 (top-left)\n        kind: scatter\n      - type: hvplot          # View 1 (top-right)\n        kind: line\n      - type: hvplot          # View 2 (bottom-left)\n        kind: bar\n      - type: table           # View 3 (bottom-right)\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#custom-arrangements","level":3,"title":"Custom arrangements","text":"<p>Create complex layouts:</p> <pre><code>layouts:\n  - title: Dashboard\n    layout: [[0], [1, 2], [3]]  # Full-width top, two middle, full-width bottom\n    views:\n      - type: hvplot            # Full width\n        kind: line\n      - type: hvplot            # Half width\n        kind: bar\n      - type: hvplot            # Half width\n        kind: hist\n      - type: table             # Full width\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#responsive-sizing","level":3,"title":"Responsive sizing","text":"<p>Make views resize with browser window:</p> <pre><code>layouts:\n  - title: Dashboard\n    sizing_mode: stretch_width  # or stretch_both, stretch_height\n    views:\n      - type: hvplot\n        responsive: true\n        height: 400\n      - type: table\n        height: 300\n</code></pre> <p>Sizing modes:</p> Mode Behavior <code>stretch_width</code> Expand to fill width <code>stretch_height</code> Expand to fill height <code>stretch_both</code> Expand to fill both dimensions <code>scale_width</code> Maintain aspect ratio, scale to width <code>scale_height</code> Maintain aspect ratio, scale to height <code>fixed</code> Use specified width/height only","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#tabbed-layouts","level":3,"title":"Tabbed layouts","text":"<p>Create tabs at the top level:</p> <pre><code>config:\n  layout: tabs               # Use tabs instead of single page\n\nlayouts:\n  - title: Overview          # Tab 1\n    views:\n      - type: hvplot\n        kind: line\n\n  - title: Detailed Analysis # Tab 2\n    views:\n      - type: table\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#advanced-view-features","level":2,"title":"Advanced view features","text":"","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#linked-selections","level":3,"title":"Linked selections","text":"<p>Link multiple plots so selecting in one highlights in others:</p> <pre><code>views:\n  - type: hvplot\n    kind: scatter\n    x: bill_length_mm\n    y: bill_depth_mm\n    selection_mode: lasso    # Enable lasso selection\n  - type: hvplot\n    kind: hist\n    y: bill_length_mm\n    # Selection automatically links\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#dynamic-colormaps","level":3,"title":"Dynamic colormaps","text":"<p>Use dynamic colormaps for continuous values:</p> <pre><code>views:\n  - type: hvplot\n    kind: scatter\n    x: x\n    y: y\n    color: temperature\n    cmap: viridis            # or: plasma, inferno, magma, coolwarm\n    colorbar: true\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#hover-tooltips","level":3,"title":"Hover tooltips","text":"<p>Customize hover information:</p> <pre><code>views:\n  - type: hvplot\n    kind: scatter\n    x: x\n    y: y\n    hover_cols: [name, category, details]  # Show these on hover\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#aggregated-plots","level":3,"title":"Aggregated plots","text":"<p>Compute aggregations within the view:</p> <pre><code>views:\n  - type: hvplot\n    kind: bar\n    x: category\n    y: value\n    aggregator: mean         # Compute mean by category\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#common-patterns","level":2,"title":"Common patterns","text":"","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#dashboard-with-filters-and-multiple-plots","level":3,"title":"Dashboard with filters and multiple plots","text":"<pre><code>pipelines:\n  filtered:\n    source: data_source\n    table: data\n    filters:\n      - type: widget\n        field: region\n      - type: widget\n        field: year\n\nlayouts:\n  - title: Sales Dashboard\n    pipeline: filtered\n    layout: [[0, 1], [2]]\n    sizing_mode: stretch_width\n    views:\n      - type: hvplot\n        kind: line\n        x: date\n        y: revenue\n        responsive: true\n        height: 300\n      - type: hvplot\n        kind: bar\n        x: product\n        y: revenue\n        responsive: true\n        height: 300\n      - type: table\n        show_index: false\n        page_size: 15\n        height: 400\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#comparison-dashboard","level":3,"title":"Comparison dashboard","text":"<pre><code>layouts:\n  - title: Before vs After\n    layout: [[0, 1]]\n    views:\n      - type: hvplot\n        pipeline: before_pipeline\n        kind: scatter\n        x: x\n        y: y\n        title: \"Before\"\n      - type: hvplot\n        pipeline: after_pipeline\n        kind: scatter\n        x: x\n        y: y\n        title: \"After\"\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#kpi-dashboard-with-indicators","level":3,"title":"KPI dashboard with indicators","text":"<pre><code>pipelines:\n  summary:\n    source: data_source\n    table: metrics\n    transforms:\n      - type: aggregate\n        method: sum\n\nlayouts:\n  - title: KPIs\n    pipeline: summary\n    layout: [[0, 1, 2], [3]]\n    views:\n      - type: indicator\n        field: revenue\n        title: \"Revenue\"\n        format: \"${value:,.0f}\"\n      - type: indicator\n        field: orders\n        title: \"Orders\"\n        format: \"{value:,}\"\n      - type: indicator\n        field: conversion_rate\n        title: \"Conversion\"\n        format: \"{value:.1f}%\"\n      - type: hvplot\n        kind: line\n        x: date\n        y: revenue\n</code></pre>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"configuration/spec/views/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you can visualize data:</p> <ul> <li>Variables guide - Make views dynamic with variables</li> <li>Customization guide - Build custom view types</li> <li>Deployment guide - Deploy your dashboard</li> </ul> <p>For complete plot options, see the hvPlot reference.</p>","path":["Configuration","Specs","Visualizing data with views"],"tags":[]},{"location":"examples/gallery/","level":1,"title":"Gallery","text":"<p>Example dashboards built with Lumen YAML specifications.</p> <p>About YAML specs</p> <p>Lumen AI runs on Lumen specs under the hood. When you use Lumen AI to create dashboards, it generates these YAML specifications automatically. Dashboards and reports created with Lumen AI are fully reproducible using the generated specs.</p> <p>Historically, users wrote these specs manually before LLMs became capable. Now, Lumen AI can generate them for you through natural language conversation. However, understanding specs is still valuable for:</p> <ul> <li>Customizing AI outputs - Edit and enhance what the AI creates</li> <li>Programmatic dashboards - Build dashboards without the AI interface</li> <li>Version control - Track changes and reproduce dashboards</li> <li>Advanced features - Access features not yet supported by AI</li> </ul> <p>Choose your approach:</p> <ul> <li>Want AI to build it for you? ‚Üí Use Lumen AI</li> <li>Want to learn the underlying system? ‚Üí Continue reading this gallery</li> <li>Want to customize AI-generated dashboards? ‚Üí Learn from these examples, then edit the YAML</li> </ul>","path":["Examples","Gallery"],"tags":[]},{"location":"examples/gallery/#featured-examples","level":2,"title":"Featured examples","text":"<ul> <li> <p> Penguins</p> <p>Palmer Station penguin measurements with linked selections</p> </li> <li> <p> London Bike Points</p> <p>Real-time bike sharing data with interactive maps and time series</p> </li> <li> <p> Seattle Weather</p> <p>Historical weather patterns with multi-panel layouts</p> </li> <li> <p> NYC Taxi</p> <p>Million-row taxi trip analysis with pickup/dropoff visualizations</p> </li> <li> <p> Precipitation</p> <p>US precipitation data with geographic visualizations</p> </li> <li> <p> Earthquakes</p> <p>Global earthquake data with magnitude and depth analysis</p> </li> <li> <p> Wind Turbines</p> <p>Wind turbine performance metrics and geographic distribution</p> </li> </ul>","path":["Examples","Gallery"],"tags":[]},{"location":"examples/gallery/#how-to-use-these-examples","level":2,"title":"How to use these examples","text":"<p>Each example includes:</p> <ul> <li>Screenshot of the final dashboard</li> <li>Complete YAML specification</li> <li>Link to download and run locally</li> </ul> <p>To run an example:</p> <ol> <li>Copy the YAML code</li> <li>Save to a file (e.g., <code>dashboard.yaml</code>)</li> <li>Run: <code>lumen serve dashboard.yaml --show</code></li> </ol> <p>To explore with AI:</p> <p>Load the data source and ask Lumen AI to recreate it:</p> <pre><code>lumen-ai serve &lt;data-url&gt;\n</code></pre> <p>Then describe what you want: \"Create a dashboard with a scatter plot and histogram\" - Lumen AI will generate the YAML spec for you.</p>","path":["Examples","Gallery"],"tags":[]},{"location":"examples/gallery/bikes/","level":1,"title":"London Bike Points","text":"<p>Real-time bike sharing data from Transport for London with interactive maps and linked selections.</p> <p></p>","path":["Examples","Gallery","London Bike Points"],"tags":[]},{"location":"examples/gallery/bikes/#features","level":2,"title":"Features","text":"<ul> <li>Live API data - Real-time bike availability from TfL API</li> <li>Geographic visualization - Interactive map with bike counts</li> <li>Linked selections - Select stations on map to filter charts</li> <li>Multiple data sources - Joins station metadata with occupancy data</li> </ul>","path":["Examples","Gallery","London Bike Points"],"tags":[]},{"location":"examples/gallery/bikes/#yaml-specification","level":2,"title":"YAML Specification","text":"bikes.yaml<pre><code>config:\n  title: \"Transport for London: Bike Station Occupancy\"\n  layout: column\nvariables:\n  TFL_API_KEY:\n    type: constant\n    value: a1c692de000b4944af55f59d8e849915\nsources:\n  stations:\n    type: json\n    shared: true\n    tables:\n      stations: \"https://api.tfl.gov.uk/BikePoint/\"\n  occupancy:\n    type: json\n    chunk_size: 15\n    cache_dir: cache\n    tables:\n      occupancy: \"https://api.tfl.gov.uk/Occupancy/BikePoints/${stations.stations.id}?app_key=${variables.TFL_API_KEY}\"\n  station_occupancy:\n    type: join\n    sources: [stations, occupancy]\n    tables:\n      station_occupancy:\n        - source: stations\n          table: stations\n          index: id\n        - source: occupancy\n          table: occupancy\n          index: id\npipelines:\n  station_occupancy:\n    source: station_occupancy\n    table: station_occupancy\n    filters:\n      - type: widget\n        field: bikesCount\n      - type: widget\n        field: totalDocks\n      - type: constant\n        field: lat\n        value: [50, 52]\n      - type: constant\n        field: lon\n        value: [-1, 1]\n    transforms:\n      - type: columns\n        columns: [commonName, bikesCount, totalDocks, lat, lon]\n      - type: project_lnglat\n        latitude: lat\n        longitude: lon\n  selected:\n    pipeline: station_occupancy\n    filters:\n      - type: param\n        parameter: locations.selection_expr\nlayouts:\n  - title: \"Occupancy\"\n    layout: [[locations, table], [count_hist, total_hist]]\n    views:\n      locations:\n        type: hvplot\n        pipeline: station_occupancy\n        kind: points\n        x: lon\n        y: lat\n        hover_cols: [commonName]\n        tiles: EsriStreet\n        responsive: true\n        height: 500\n        color: bikesCount\n        line_color: black\n        xaxis: null\n        yaxis: null\n        framewise: false\n        selection_group: bikes\n      table:\n        type: table\n        pipeline: selected\n        height: 500\n        margin: [0, 100]\n        hidden_columns: [lat, lon]\n        show_index: false\n        sizing_mode: stretch_width\n      count_hist:\n        type: hvplot\n        pipeline: station_occupancy\n        kind: hist\n        y: bikesCount\n        responsive: true\n        height: 300\n        streaming: true\n        selection_group: bikes\n      total_hist:\n        type: hvplot\n        pipeline: station_occupancy\n        kind: hist\n        y: totalDocks\n        responsive: true\n        height: 300\n        streaming: true\n        selection_group: bikes\n</code></pre>","path":["Examples","Gallery","London Bike Points"],"tags":[]},{"location":"examples/gallery/bikes/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>bikes.yaml</code> and run:</p> <pre><code>lumen serve bikes.yaml --show\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","London Bike Points"],"tags":[]},{"location":"examples/gallery/bikes/#key-concepts","level":2,"title":"Key concepts","text":"<p>This example demonstrates:</p> <ul> <li>JSON sources - Loading data from REST APIs</li> <li>Variables - Using API keys securely</li> <li>Source joins - Combining multiple data sources</li> <li>Geographic plots - Maps with tiles and hover information</li> <li>Linked selections - Cross-filtering between views</li> </ul>","path":["Examples","Gallery","London Bike Points"],"tags":[]},{"location":"examples/gallery/earthquakes/","level":1,"title":"Earthquakes","text":"<p>Global earthquake data with magnitude and depth analysis.</p> <p></p>","path":["Examples","Gallery","Earthquakes"],"tags":[]},{"location":"examples/gallery/earthquakes/#features","level":2,"title":"Features","text":"<ul> <li>Global map - Earthquake locations worldwide</li> <li>Magnitude analysis - Distribution and trends</li> <li>Depth visualization - Earthquake depth patterns</li> <li>Time filtering - Filter by date range</li> </ul>","path":["Examples","Gallery","Earthquakes"],"tags":[]},{"location":"examples/gallery/earthquakes/#yaml-specification","level":2,"title":"YAML Specification","text":"earthquakes.yaml<pre><code>config:\n  title: Earthquake Dashboard\n  theme: dark\nsources:\n  earthquakes:\n    type: file\n    cache_per_query: false\n    tables:\n      earthquakes: [\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv\", \"csv\"]\npipelines:\n  earthquakes:\n    source: earthquakes\n    table: earthquakes\n    filters:\n      - type: widget\n        field: type\n      - type: widget\n        field: mag\n      - type: widget\n        field: depth\n    transforms:\n      - type: columns\n        columns:\n          - time\n          - longitude\n          - latitude\n          - type\n          - place\n          - mag\n          - depth\n          - rms\n      - type: project_lnglat\n        longitude: longitude\n        latitude: latitude\n  selected:\n    pipeline: earthquakes\n    filters:\n      - type: param\n        parameter: map.selection_expr\nlayouts:\n  - title: Earthquakes\n    views:\n      map:\n        type: hvplot\n        pipeline: earthquakes\n        kind: points\n        x: longitude\n        y: latitude\n        tiles: ESRI\n        responsive: true\n        height: 500\n        fill_color: null\n        line_color: white\n        xaxis: null\n        yaxis: null\n        selection_group: earthquakes\n        streaming: true\n        hover: false\n      table:\n        type: table\n        pipeline: selected\n        hidden_columns:\n          - longitude\n          - latitude\n        page_size: 16\n        pagination: remote\n        sizing_mode: stretch_width\n        show_index: false\n        theme: midnight\n      mag_hist:\n        type: hvplot\n        pipeline: earthquakes\n        kind: hist\n        y: mag\n        fill_color: white\n        responsive: true\n        height: 250\n        selection_group: earthquakes\n        streaming: true\n      depth_hist:\n        type: hvplot\n        pipeline: earthquakes\n        kind: hist\n        y: depth\n        fill_color: white\n        responsive: true\n        height: 250\n        selection_group: earthquakes\n        streaming: true\n      rms_hist:\n        type: hvplot\n        pipeline: earthquakes\n        kind: hist\n        y: rms\n        fill_color: white\n        responsive: true\n        height: 250\n        selection_group: earthquakes\n        streaming: true\n    refresh_rate: 60000\n    layout: [[0, 1], [2, 3, 4]]\n</code></pre>","path":["Examples","Gallery","Earthquakes"],"tags":[]},{"location":"examples/gallery/earthquakes/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>earthquakes.yaml</code> and run:</p> <pre><code>lumen serve earthquakes.yaml --show\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","Earthquakes"],"tags":[]},{"location":"examples/gallery/nyc_taxi/","level":1,"title":"NYC Taxi","text":"<p>Million-row taxi trip analysis with pickup/dropoff maps and fare distribution.</p> <p></p>","path":["Examples","Gallery","NYC Taxi"],"tags":[]},{"location":"examples/gallery/nyc_taxi/#features","level":2,"title":"Features","text":"<ul> <li>Large dataset handling - Efficiently processes millions of taxi trips</li> <li>Geographic maps - Pickup and dropoff locations</li> <li>Fare analysis - Distribution of trip costs</li> <li>Time filtering - Filter by pickup time</li> </ul>","path":["Examples","Gallery","NYC Taxi"],"tags":[]},{"location":"examples/gallery/nyc_taxi/#yaml-specification","level":2,"title":"YAML Specification","text":"nyc_taxi.yaml<pre><code>config:\n  title: \"NYC Taxi Trips\"\nsources:\n  nyc_taxi:\n    type: duckdb\n    shared: true\n    uri: \":memory:\"\n    tables:\n      nyc_taxi: \"read_parquet('s3://datasets.holoviz.org/nyc_taxi/v2/nyc_taxi_wide.parq')\"\n    initializers:\n      - \"INSTALL httpfs;\"\n      - \"LOAD httpfs;\"\nlayouts:\n  - title: Trip Data\n    source: nyc_taxi\n    views:\n      - table: nyc_taxi\n        type: hvplot\n        kind: points\n        x: pickup_x\n        y: pickup_y\n        tiles: EsriStreet\n        rasterize: true\n        cnorm: eq_hist\n        responsive: true\n        height: 500\n        colorbar: false\n        selection_group: taxi\n        xaxis: null\n        yaxis: null\n      - table: nyc_taxi\n        type: hvplot\n        kind: points\n        x: dropoff_x\n        y: dropoff_y\n        tiles: EsriStreet\n        rasterize: true\n        cnorm: eq_hist\n        responsive: true\n        height: 500\n        colorbar: false\n        selection_group: taxi\n        xaxis: null\n        yaxis: null\n      - table: nyc_taxi\n        type: hvplot\n        kind: hist\n        y: trip_distance\n        bin_range: [0, 20]\n        height: 300\n        responsive: true\n        selection_group: taxi\n      - table: nyc_taxi\n        type: hvplot\n        kind: hist\n        y: tip_amount\n        bin_range: [0, 20]\n        height: 300\n        responsive: true\n        selection_group: taxi\n      - table: nyc_taxi\n        type: hvplot\n        kind: hist\n        y: fare_amount\n        bin_range: [0, 50]\n        height: 300\n        responsive: true\n        selection_group: taxi\n    sizing_mode: stretch_both\n    layout: [[0, 1], [2, 3, 4]]\n</code></pre>","path":["Examples","Gallery","NYC Taxi"],"tags":[]},{"location":"examples/gallery/nyc_taxi/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>nyc_taxi.yaml</code> and run:</p> <pre><code>lumen serve nyc_taxi.yaml --show\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","NYC Taxi"],"tags":[]},{"location":"examples/gallery/penguins/","level":1,"title":"Palmer Penguins","text":"<p>Interactive dashboard exploring Palmer Station penguin measurements with linked selections.</p> <p></p>","path":["Examples","Gallery","Palmer Penguins"],"tags":[]},{"location":"examples/gallery/penguins/#features","level":2,"title":"Features","text":"<ul> <li>Linked selections - Select points in scatter plot to filter histograms</li> <li>Multiple filters - Species, island, and sex</li> <li>Interactive table - Shows selected data with pagination</li> </ul>","path":["Examples","Gallery","Palmer Penguins"],"tags":[]},{"location":"examples/gallery/penguins/#yaml-specification","level":2,"title":"YAML Specification","text":"penguins.yaml<pre><code>config:\n  title: Palmer Penguins\n  theme: dark\n  layout: tabs\nsources:\n  penguins:\n    type: file\n    cache_per_query: false\n    cache_dir: ./cache\n    tables:\n      penguins: https://datasets.holoviz.org/penguins/v1/penguins.csv\npipelines:\n  penguins:\n    source: penguins\n    table: penguins\n    filters:\n      species:\n        type: widget\n        field: species\n      island:\n        type: widget\n        field: island\n      sex:\n        type: widget\n        field: sex\n  selected:\n    pipeline: penguins\n    filters:\n      expr:\n        type: param\n        parameter: scatter.selection_expr\nlayouts:\n  - title: Plots\n    pipeline: penguins\n    views:\n      scatter:\n        type: hvplot\n        kind: points\n        x: bill_length_mm\n        y: bill_depth_mm\n        color: species\n        responsive: true\n        height: 350\n        selection_group: penguin\n      depth_hist:\n        type: hvplot\n        kind: hist\n        y: bill_length_mm\n        responsive: true\n        height: 350\n        selection_group: penguin\n      length_hist:\n        type: hvplot\n        kind: hist\n        y: bill_depth_mm\n        responsive: true\n        height: 350\n        selection_group: penguin\n      mass_hist:\n        type: hvplot\n        kind: hist\n        y: body_mass_g\n        responsive: true\n        height: 350\n        selection_group: penguin\n    layout: [[scatter], [depth_hist, length_hist, mass_hist]]\n    sizing_mode: stretch_width\n  - title: Table\n    pipeline: selected\n    views:\n      table:\n        type: table\n        layout: fit_data_fill\n        show_index: false\n        theme: midnight\n        sizing_mode: stretch_both\n        pagination: remote\n        page_size: 50\n</code></pre>","path":["Examples","Gallery","Palmer Penguins"],"tags":[]},{"location":"examples/gallery/penguins/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>penguins.yaml</code> and run:</p> <pre><code>lumen serve penguins.yaml --show\n</code></pre> <p>Or explore with AI:</p> <pre><code>lumen-ai serve https://datasets.holoviz.org/penguins/v1/penguins.csv\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","Palmer Penguins"],"tags":[]},{"location":"examples/gallery/precip/","level":1,"title":"Precipitation","text":"<p>US precipitation data with geographic visualizations and temporal analysis.</p> <p></p>","path":["Examples","Gallery","Precipitation"],"tags":[]},{"location":"examples/gallery/precip/#features","level":2,"title":"Features","text":"<ul> <li>Geographic visualization - Precipitation patterns across the US</li> <li>Time series - Historical precipitation trends</li> <li>Regional analysis - Compare different areas</li> </ul>","path":["Examples","Gallery","Precipitation"],"tags":[]},{"location":"examples/gallery/precip/#yaml-specification","level":2,"title":"YAML Specification","text":"precipitation.yaml<pre><code>config:\n  title: \"Precipitation Dashboard\"\nsources:\n  rockies:\n    type: intake\n    shared: true\n    cache_dir: cache\n    catalog:\n      sources:\n        southern_rockies:\n          driver: csv\n          args:\n            urlpath: 's3://datasets.holoviz.org/precipitation/v1/SRLCC_{emissions}_Precip_{model}.csv'\n            csv_kwargs:\n              skiprows: 3\n              names: ['time', 'precip']\n              parse_dates: ['time']\n            storage_options:\n              anon: true\npipelines:\n  rockies:\n    source: rockies\n    table: southern_rockies\n    filters:\n      - type: widget\n        field: model\n      - type: widget\n        field: model\nlayouts:\n  - title: Southern Rockies\n    pipeline: rockies\n    height: 250\n    facet:\n      by: [model]\n      layout: column\n    views:\n      - type: hvplot\n        kind: line\n        x: time\n        y: precip\n        by: [model, emissions]\n        height: 200\n        responsive: true\n</code></pre>","path":["Examples","Gallery","Precipitation"],"tags":[]},{"location":"examples/gallery/precip/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>precipitation.yaml</code> and run:</p> <pre><code>lumen serve precipitation.yaml --show\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","Precipitation"],"tags":[]},{"location":"examples/gallery/seattle/","level":1,"title":"Seattle Weather","text":"<p>Historical weather patterns from 2012-2015 with multi-panel time series and heatmap visualizations.</p> <p></p>","path":["Examples","Gallery","Seattle Weather"],"tags":[]},{"location":"examples/gallery/seattle/#features","level":2,"title":"Features","text":"<ul> <li>Temperature heatmap - Daily highs by month and day</li> <li>Time series - Maximum temperature with precipitation size encoding</li> <li>Weather distribution - Bar chart of weather type frequency</li> <li>URL syncing - Filters sync with browser URL</li> </ul>","path":["Examples","Gallery","Seattle Weather"],"tags":[]},{"location":"examples/gallery/seattle/#yaml-specification","level":2,"title":"YAML Specification","text":"seattle.yaml<pre><code>config:\n  title: Altair Seattle Weather\n  reloadable: false\n  sync_with_url: true\nsources:\n  seattle:\n    type: file\n    cache_per_query: false\n    tables:\n      weather: https://raw.githubusercontent.com/vega/vega/main/docs/data/seattle-weather.csv\n    kwargs:\n      parse_dates: [date]\npipelines:\n  seattle:\n    source: seattle\n    table: weather\n    filters:\n      - type: widget\n        field: date\n      - type: widget\n        field: weather\nlayouts:\n  - title: Seattle Weather\n    pipeline: seattle\n    views:\n      - type: altair\n        marker: rect\n        chart:\n          title: 2012-2015 Daily High Temperature (F) in Seattle, WA\n        x:\n          shorthand: date(date):O\n          title: Day\n        y:\n          shorthand: month(date):O\n          title: Month\n        encode:\n          color:\n            shorthand: max(temp_max):Q\n            scale:\n              scheme: inferno\n        properties:\n          width: container\n      - type: altair\n        x:\n          shorthand: monthdate(date):T\n          title: Date\n        y:\n          shorthand: temp_max:Q\n          title: 'Maximum Daily Temperature (C)'\n        marker: point\n        encode:\n          color: weather:N\n          size:\n            shorthand: precipitation:Q\n            scale: [5, 200]\n        properties:\n          width: container\n      - type: altair\n        x: count()\n        y: weather:N\n        encode:\n          color: weather:N\n        marker: bar\n        properties:\n          width: container\n    sizing_mode: stretch_width\n</code></pre>","path":["Examples","Gallery","Seattle Weather"],"tags":[]},{"location":"examples/gallery/seattle/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>seattle.yaml</code> and run:</p> <pre><code>lumen serve seattle.yaml --show\n</code></pre> <p>Or explore with AI:</p> <pre><code>lumen-ai serve https://raw.githubusercontent.com/vega/vega/main/docs/data/seattle-weather.csv\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","Seattle Weather"],"tags":[]},{"location":"examples/gallery/seattle/#key-concepts","level":2,"title":"Key concepts","text":"<p>This example demonstrates:</p> <ul> <li>Altair views - Declarative Vega-Lite visualizations</li> <li>Date filtering - Filter by date ranges</li> <li>Multiple encodings - Color and size channels</li> <li>URL synchronization - Shareable filtered states</li> </ul>","path":["Examples","Gallery","Seattle Weather"],"tags":[]},{"location":"examples/gallery/windturbines/","level":1,"title":"Wind Turbines","text":"<p>Wind turbine performance metrics and geographic distribution across the US.</p> <p></p>","path":["Examples","Gallery","Wind Turbines"],"tags":[]},{"location":"examples/gallery/windturbines/#features","level":2,"title":"Features","text":"<ul> <li>Geographic distribution - Turbine locations across the US</li> <li>Performance metrics - Capacity and output analysis</li> <li>Manufacturer comparison - Compare different turbine makers</li> <li>Interactive filtering - Filter by state, manufacturer, capacity</li> </ul>","path":["Examples","Gallery","Wind Turbines"],"tags":[]},{"location":"examples/gallery/windturbines/#yaml-specification","level":2,"title":"YAML Specification","text":"windturbines.yaml<pre><code>config:\n  title: Windturbine Database Viewer\n  theme: dark\n  template: material\nsources:\n  windturbines:\n    type: duckdb\n    cache_dir: ./cache\n    uri: \":memory:\"\n    tables:\n      windturbines: \"read_parquet('s3://datasets.holoviz.org/windturbines/v1/windturbines.parq')\"\n    initializers:\n      - \"INSTALL httpfs;\"\n      - \"LOAD httpfs;\"\nvariables:\n  state:\n    type: url\n  color_by:\n    type: widget\n    kind: panel.widgets.Select\n    options:\n      - t_manu\n      - t_year\n    value: t_manu\npipelines:\n  continental:\n    source: windturbines\n    filters:\n      - type: constant\n        field: xlong\n        value: [-125, -66]\n      - type: constant\n        field: ylat\n        value: [24, 50]\n      - type: constant\n        field: t_state\n        value: $variables.state\n  windturbines:\n    pipeline: continental\n    filters:\n      - type: widget\n        field: t_state\n      - type: widget\n        field: t_manu\n      - type: widget\n        field: p_year\n      - type: widget\n        field: t_cap\n  filtered:\n    pipeline: windturbines\n    filters:\n      - type: param\n        parameter: points.selection_expr\n  table:\n    pipeline: filtered\n    transforms:\n      - type: columns\n        columns: [t_state, t_county, p_name, t_manu, t_model, p_year, t_cap, t_hh, t_rd, t_rsa, t_ttlh]\n  count:\n    pipeline: filtered\n    transforms:\n      - type: count\n      - type: rename\n        columns:\n          case_id: Count\n  sum:\n    pipeline: filtered\n    transforms:\n      - type: columns\n        columns:\n          - t_cap\n      - type: sum\n      - type: eval\n        expr: \"Capacity = table.t_cap / 10**6\"\nlayouts:\n  - title: Overview\n    layout: [[points, [count, capacity]], [table, [cap_hist, year_hist]]]\n    sizing_mode: stretch_width\n    views:\n      points:\n        type: hvplot\n        kind: points\n        pipeline: windturbines\n        x: easting\n        y: northing\n        c: $variables.color_by\n        tiles: ESRI\n        rasterize: true\n        dynspread: true\n        responsive: true\n        height: 500\n        xaxis: null\n        yaxis: null\n        streaming: true\n        selection_group: windturbines\n      table:\n        type: table\n        pipeline: table\n        header_filters: true\n        sizing_mode: stretch_width\n        height: 500\n        page_size: 20\n      count:\n        type: indicator\n        indicator: number\n        pipeline: count\n        field: Count\n        format: '{value:,}'\n        width: 300\n        default_color: white\n      capacity:\n        type: indicator\n        indicator: number\n        pipeline: sum\n        field: Capacity\n        format: '{value:.0f} TWh'\n        width: 300\n        default_color: white\n      cap_hist:\n        type: hvplot\n        kind: hist\n        pipeline: windturbines\n        y: t_cap\n        frame_width: 400\n        height: 250\n        selection_group: windturbines\n      year_hist:\n        type: hvplot\n        kind: hist\n        pipeline: windturbines\n        y: p_year\n        frame_width: 400\n        height: 250\n        selection_group: windturbines\n</code></pre>","path":["Examples","Gallery","Wind Turbines"],"tags":[]},{"location":"examples/gallery/windturbines/#run-this-example","level":2,"title":"Run this example","text":"<p>Save the YAML above as <code>windturbines.yaml</code> and run:</p> <pre><code>lumen serve windturbines.yaml --show\n</code></pre> <p>Download YAML</p>","path":["Examples","Gallery","Wind Turbines"],"tags":[]},{"location":"examples/tutorials/","level":1,"title":"Tutorials","text":"<p>Step-by-step guides to build real-world applications with Lumen.</p>","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/#available-tutorials","level":2,"title":"Available Tutorials","text":"","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/#weather-data-explorer","level":3,"title":"Weather Data Explorer","text":"<p>Build a domain-specific data exploration application that analyzes atmospheric soundings and displays Skew-T diagrams. Learn how to create custom agents and tools for specialized data analysis.</p> <p>You'll learn:</p> <ul> <li>Creating custom agents for domain-specific analysis</li> <li>Building specialized visualization tools</li> <li>Configuring Lumen for scientific data exploration</li> </ul>","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/#census-data-ai-explorer","level":3,"title":"Census Data AI Explorer","text":"<p>Build a custom data source control that integrates U.S. Census Bureau data with Lumen AI. Fetch demographic data through an interactive UI and explore it using natural language queries.</p> <p>You'll learn:</p> <ul> <li>Creating custom source controls for external APIs</li> <li>Building reactive UI with Material-UI components</li> <li>Handling async data fetching and loading states</li> <li>Registering dynamic data sources with DuckDB</li> <li>Best practices for API integration</li> </ul>","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/#build-dashboard-with-spec","level":3,"title":"Build Dashboard with Spec","text":"<p>Create a complete Lumen dashboard in under 15 minutes using YAML specifications. While Lumen AI can generate these specs automatically, understanding them gives you full control.</p> <p>You'll learn:</p> <ul> <li>Writing YAML specs for dashboards</li> <li>Connecting multiple data sources</li> <li>Creating interactive visualizations</li> <li>Deploying dashboards for sharing</li> </ul>","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/#saas-executive-dashboard","level":3,"title":"SaaS Executive Dashboard","text":"<p>Turn recurring analytics requests into one-click reproducible reports. Build an executive dashboard that combines SQL queries, custom visualizations, and AI-generated insights‚Äîthen export to Jupyter notebooks or deploy as a web app.</p> <p>You'll learn:</p> <ul> <li>Creating custom Actions for specialized visualizations</li> <li>Using SQLQuery for deterministic metrics with AI captions</li> <li>Wrapping agents with ActorTask for narrative insights</li> <li>Organizing reports with Sections and sharing context between tasks</li> </ul>","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/#more-coming-soon","level":2,"title":"More Coming Soon","text":"<p>We're constantly adding new tutorials. Check back regularly or contribute your own!</p>","path":["Examples","Tutorials"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/","level":1,"title":"Building a Census Data AI Explorer","text":"<p>Build a data exploration application that integrates U.S. Census Bureau data using Lumen AI.</p> <p>This tutorial creates a custom data source control that lets you fetch demographic data through a simple interface.</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#final-result","level":2,"title":"Final result","text":"<p>A chat interface that can fetch and analyze U.S. Census data with custom controls for selecting datasets and years.</p> <p>Time: 15-20 minutes</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#what-youll-build","level":2,"title":"What you'll build","text":"<p>A custom data source control that integrates with the Census API and lets users explore demographic data through natural language queries. The tutorial follows three steps:</p> <ol> <li>Start with a minimal example - Build a basic year selector with ~70 lines of runnable code</li> <li>Understand the components - Learn how each part works</li> <li>Extend to full version - Add dynamic options and more features</li> </ol> <p>Each step introduces key Lumen AI concepts for building custom data source integrations.</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#why-custom-data-source-controls","level":2,"title":"Why custom data source controls?","text":"<p>Lumen AI ships with built-in support for common data sources like CSV files, DuckDB, and SQL databases. But what if your data lives behind an API that requires authentication, has complex query parameters, or needs real-time fetching?</p> <p>Custom data source controls let you (see Source Controls):</p> <ul> <li>Connect to external APIs - Fetch data from REST APIs, government data portals, or proprietary services</li> <li>Add interactive parameters - Let users select years, regions, variables, or filters before loading data</li> <li>Handle authentication - Manage API keys, OAuth tokens, or other credentials securely</li> <li>Transform on-the-fly - Process and clean data as it arrives</li> <li>Cache intelligently - Store expensive API responses to avoid redundant calls</li> </ul> <p>This tutorial uses the U.S. Census Bureau API as an example, but the same patterns apply to:</p> <ul> <li>Financial data APIs (Federal Reserve, Yahoo Finance)</li> <li>Weather and climate data (NOAA, NASA)</li> <li>Scientific datasets (genomics, astronomy, earth observation)</li> <li>Internal corporate APIs and data warehouses</li> </ul> <p>Once you create a custom control, users can fetch data through a simple UI without writing code, then immediately ask natural language questions about it using Lumen AI's conversational interface.</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#prerequisites","level":2,"title":"Prerequisites","text":"<p>Install the required packages:</p> <pre><code>pip install lumen-ai censusdis\n</code></pre>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#1-minimal-runnable-example","level":2,"title":"1. Minimal runnable example","text":"<p>Copy this complete example to <code>census_explorer.py</code> and run it with <code>panel serve census_explorer.py --show</code>:</p> census_explorer.py<pre><code>import asyncio\nimport censusdis.data as ced\nimport panel as pn\nimport param\nimport lumen.ai as lmai\nfrom lumen.ai.controls import DownloadControls\nfrom lumen.sources.duckdb import DuckDBSource\nfrom panel_material_ui import Button, IntSlider, Column\n\npn.extension()\n\n\nclass CensusControls(DownloadControls):\n    \"\"\"Fetch U.S. Census population data.\"\"\"\n\n    vintage = param.Integer(default=2023, bounds=(2011, 2023), doc=\"Year of data\")\n    label = '&lt;span class=\"material-icons\"&gt;assessment&lt;/span&gt; Census Data'\n\n    def __init__(self, **params):\n        super().__init__(**params)\n\n        self._year_select = IntSlider.from_param(self.param.vintage, label=\"Year\")\n        self._fetch_button = Button(label=\"Fetch Population Data\", on_click=self._on_fetch)\n        self._layout = Column(self._year_select, self._fetch_button)\n\n    async def _on_fetch(self, event):\n        \"\"\"Fetch census population data.\"\"\"\n        with self._layout.param.update(loading=True):\n            await asyncio.sleep(0.01)\n            df = await asyncio.to_thread(\n                ced.download,\n                dataset=\"acs/acs5\",  # ACS 5-Year\n                vintage=self.vintage,\n                download_variables=[\"NAME\"],\n                group=\"B01003\",  # Total population\n                state=\"*\",  # All states\n            )\n            if df is not None and not df.empty:\n                await self._add_table(df)\n                self.param.trigger(\"upload_successful\")\n\n    async def _add_table(self, df):\n        \"\"\"Register DataFrame as a DuckDB source.\"\"\"\n        table_name = f\"census_{self.vintage}_population\"\n        source = DuckDBSource.from_df(tables={table_name: df})\n        source.tables[table_name] = f\"SELECT * FROM {table_name}\"\n        self.outputs[\"source\"] = source\n        self.outputs[\"sources\"] = self.outputs.get(\"sources\", []) + [source]\n        self.outputs[\"table\"] = table_name\n        self.param.trigger(\"outputs\")\n\n    def __panel__(self):\n        return self._layout\n\n\nui = lmai.ExplorerUI(\n    source_controls=[CensusControls],\n    title=\"Census Data Explorer\",\n    log_level=\"DEBUG\",\n)\n\nui.servable()\n</code></pre> <p>This ~70 line example is immediately runnable! Try clicking on \"Sources\" in the sidebar, selecting the desired year, and clicking \"Fetch Population Data\".</p> <p>Once the data loads, you can ask question like:</p> <ul> <li>\"What is the total population?\"</li> <li>\"Show me the top 10 states by population\"</li> <li>\"Which state has the largest population?\"</li> </ul>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#2-understanding-the-components","level":2,"title":"2. Understanding the components","text":"<p>Let's break down the key concepts:</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#custom-controls","level":3,"title":"Custom controls","text":"<p>Custom controls extend data sources by subclassing <code>lmai.controls.DownloadControls</code> (see Source Controls):</p> <pre><code>class CensusControls(DownloadControls):\n    vintage = param.Integer(default=2023, bounds=(2011, 2023), doc=\"Year of data\")\n    label = '&lt;span class=\"material-icons\"&gt;assessment&lt;/span&gt; Census Data'\n</code></pre> <p>The <code>bounds</code> parameter defines the valid range for the slider. The label appears in the sidebar with a Material Design icon.</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#ui-components","level":3,"title":"UI components","text":"<p>IntSlider with from_param creates a bound widget directly from the parameter:</p> <pre><code>self._year_select = IntSlider.from_param(self.param.vintage, label=\"Year\")\n</code></pre> <p>This automatically handles two-way binding between the widget and parameter.</p> <p>Inline button setup is more concise:</p> <pre><code>self._fetch_button = Button(label=\"Fetch Population Data\", on_click=self._on_fetch)\n</code></pre> <p>Column layout arranges components vertically:</p> <pre><code>self._layout = Column(self._year_select, self._fetch_button)\n</code></pre>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#data-fetching","level":3,"title":"Data fetching","text":"<p>Loading indicator with context manager:</p> <pre><code>with self._layout.param.update(loading=True):\n    await asyncio.sleep(0.01)  # Ensure UI updates\n    df = await asyncio.to_thread(ced.download(...))\n</code></pre> <p>Don't block the main thread by using <code>asyncio.to_thread()</code>:</p> <pre><code>df = await asyncio.to_thread(\n    ced.download,\n    dataset=\"acs/acs5\",  # ACS 5-Year dataset\n    vintage=self.vintage,\n    download_variables=[\"NAME\"],  # Include place names\n    group=\"B01003\",  # Total population variable group\n    state=\"*\",  # All states\n)\n</code></pre>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#duckdb-integration","level":3,"title":"DuckDB integration","text":"<p>Simplified source creation with <code>from_df()</code>:</p> <pre><code>table_name = f\"census_{self.vintage}_population\"\nsource = DuckDBSource.from_df(tables={table_name: df})\nsource.tables[table_name] = f\"SELECT * FROM {table_name}\"\n\n# Make available to Lumen AI\nself.outputs[\"source\"] = source\nself.outputs[\"table\"] = table_name\nself.param.trigger(\"outputs\")\n</code></pre> <p>Note the dynamic table name that includes the year for clarity.</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#3-extend-to-full-version","level":2,"title":"3. Extend to full version","text":"<p>The minimal example uses fixed values: ACS 5-Year dataset, population data (group B01003), state geography. The full example below adds nice-to-have features like progress bars and error messages, plus:</p> <p>Dynamic variable groups - Load and display all available Census variable groups:</p> <pre><code>def _get_group_options(self):\n    \"\"\"Fetch variable groups and return {label: value} dict.\"\"\"\n    cache_key = (self.dataset, self.vintage)\n\n    if cache_key not in self._groups_cache:\n        groups_df = ced.variables.all_groups(self.dataset, self.vintage)\n        self._groups_cache[cache_key] = {\n            row[\"GROUP\"]: row[\"DESCRIPTION\"]\n            for _, row in groups_df.iterrows()\n        }\n\n    groups = self._groups_cache[cache_key]\n    return {f\"{code}: {groups[code]}\": code for code in groups.keys()}\n</code></pre> <p>Multiple datasets - Choose between ACS 1-Year and 5-Year:</p> <pre><code>from censusdis.datasets import ACS1, ACS5\n\ndataset = param.Selector(default=ACS5, objects=[ACS5, ACS1])\n</code></pre> <p>Geography levels - Select state, county, tract, block group, etc.:</p> <pre><code>import censusdis.geography as cgeo\n\ndef _get_geo_options(self):\n    \"\"\"Fetch geographies and return {label: value} dict.\"\"\"\n    geo_specs = cgeo.geo_path_snake_specs(self.dataset, self.vintage)\n    # Return unique leaf geographies with friendly names\n</code></pre> <p>State filtering - Limit data to specific states:</p> <pre><code>from censusdis.states import NAMES_FROM_IDS\n\nSTATES = {\"All States\": \"*\", **{name: fips for fips, name in NAMES_FROM_IDS.items()}}\nstate_filter = param.String(default=\"All States\")\n</code></pre> <p>Reactive updates - Options update when dataset/year changes:</p> <pre><code>@param.depends(\"dataset\", \"vintage\", watch=True)\ndef _on_dataset_vintage_change(self):\n    \"\"\"Update group and geo options when dataset or vintage changes.\"\"\"\n    self._group_select.options = self._get_group_options()\n    self._geo_select.options = self._get_geo_options()\n</code></pre>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#full-example","level":2,"title":"Full example","text":"<p>Here's a complete implementation with all the features described above:</p> census_explorer_full.py<pre><code>\"\"\"\nCensus Data Explorer - Full Example\nComplete implementation with dynamic options and features\n\"\"\"\n\nimport asyncio\nimport censusdis.data as ced\nimport censusdis.geography as cgeo\nimport panel as pn\nimport param\nimport lumen.ai as lmai\nfrom censusdis.datasets import ACS1, ACS5\nfrom censusdis.states import NAMES_FROM_IDS\nfrom lumen.ai.controls import DownloadControls\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.util import normalize_table_name\nfrom panel_material_ui import Button, FlexBox, Select, TextInput, Markdown\n\npn.extension()\n\n# State FIPS codes\nSTATES = {\"All States\": \"*\", **{name: fips for fips, name in NAMES_FROM_IDS.items()}}\n\n# Available years per dataset\nDATASET_YEARS = {\n    ACS5: [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011],\n    ACS1: [2023, 2022, 2021, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011],\n}\n\nclass CensusControlsFull(DownloadControls):\n    \"\"\"Full-featured Census data control with dynamic options.\"\"\"\n\n    dataset = param.Selector(default=ACS5, objects=[ACS5, ACS1], doc=\"Census dataset\")\n    vintage = param.Integer(default=2023, doc=\"Year of data\")\n    group = param.String(default=\"B01003\", doc=\"Variable group code\")\n    geography = param.String(default=\"state\", doc=\"Geographic level\")\n    state_filter = param.String(default=\"All States\", doc=\"State to filter by\")\n    table_alias = param.String(default=\"census_data\", doc=\"Table name in database\")\n\n    label = '&lt;span class=\"material-icons\"&gt;assessment&lt;/span&gt; Census Data'\n\n    def __init__(self, **params):\n        super().__init__(**params)\n\n        # Caches for API data\n        self._groups_cache = {}\n        self._geo_cache = {}\n\n        # Load initial options\n        group_options = self._get_group_options()\n        geo_options = self._get_geo_options()\n        year_options = self._get_year_options()\n\n        # Build UI\n        self._dataset_select = Select(\n            value=self.dataset,\n            options={\"ACS 5-Year\": ACS5, \"ACS 1-Year\": ACS1},\n            label=\"Dataset\",\n            sizing_mode=\"stretch_width\",\n        )\n\n        self._vintage_select = Select(\n            value=self.vintage,\n            options=year_options,\n            label=\"Year\",\n            sizing_mode=\"stretch_width\",\n        )\n\n        self._group_select = Select(\n            value=self.group,\n            options=group_options,\n            label=\"Variable Group\",\n            sizing_mode=\"stretch_width\",\n        )\n\n        self._geo_select = Select(\n            value=self.geography,\n            options=geo_options,\n            label=\"Geography\",\n            sizing_mode=\"stretch_width\",\n        )\n\n        self._state_select = Select(\n            value=self.state_filter,\n            options={name: name for name in STATES.keys()},\n            label=\"State Filter\",\n            sizing_mode=\"stretch_width\",\n        )\n\n        self._alias_input = TextInput.from_param(\n            self.param.table_alias,\n            label=\"Table Name\",\n            sizing_mode=\"stretch_width\",\n        )\n\n        self._fetch_button = Button(\n            label=\"Fetch Census Data\",\n            icon=\"download\",\n            color=\"primary\",\n            sizing_mode=\"stretch_width\",\n            height=42,\n        )\n        self._fetch_button.on_click(self._on_fetch)\n\n        self._layout = FlexBox(\n            Markdown(\"### Census Data\"),\n            FlexBox(\n                self._dataset_select,\n                self._vintage_select,\n                flex_direction=\"row\",\n                gap=\"10px\",\n                sizing_mode=\"stretch_width\",\n            ),\n            self._group_select,\n            FlexBox(\n                self._geo_select,\n                self._state_select,\n                flex_direction=\"row\",\n                gap=\"10px\",\n                sizing_mode=\"stretch_width\",\n            ),\n            self._alias_input,\n            self._fetch_button,\n            self._error_placeholder,\n            self._message_placeholder,\n            self._progress_bar,\n            self._progress_description,\n            flex_direction=\"column\",\n            gap=\"10px\",\n            sizing_mode=\"stretch_width\",\n            margin=(10, 10),\n        )\n\n        # Link widgets to params\n        self._dataset_select.link(self, value='dataset')\n        self._vintage_select.link(self, value='vintage')\n        self._group_select.link(self, value='group')\n        self._geo_select.link(self, value='geography')\n        self._state_select.link(self, value='state_filter')\n\n    def _get_year_options(self):\n        \"\"\"Get available years for current dataset.\"\"\"\n        years = DATASET_YEARS.get(self.dataset, [2023])\n        return {str(y): y for y in years}\n\n    def _get_group_options(self):\n        \"\"\"Fetch variable groups from Census API.\"\"\"\n        cache_key = (self.dataset, self.vintage)\n\n        if cache_key not in self._groups_cache:\n            try:\n                groups_df = ced.variables.all_groups(self.dataset, self.vintage)\n                self._groups_cache[cache_key] = {\n                    row[\"GROUP\"]: row[\"DESCRIPTION\"]\n                    for _, row in groups_df.iterrows()\n                }\n            except Exception as e:\n                print(f\"Failed to load groups: {e}\")\n                self._groups_cache[cache_key] = {}\n\n        groups = self._groups_cache[cache_key]\n\n        # Prioritize common groups\n        popular = [\"B01003\", \"B01001\", \"B19013\", \"B02001\", \"B25001\", \"B15003\", \"B17001\"]\n        options = {}\n\n        for code in popular:\n            if code in groups:\n                options[f\"{code}: {groups[code]}\"] = code\n\n        for code in sorted(groups.keys()):\n            if code not in popular and len(options) &lt; 500:\n                options[f\"{code}: {groups[code]}\"] = code\n\n        return options\n\n    def _get_geo_options(self):\n        \"\"\"Fetch geographies from Census API.\"\"\"\n        cache_key = (self.dataset, self.vintage)\n\n        if cache_key not in self._geo_cache:\n            try:\n                self._geo_cache[cache_key] = cgeo.geo_path_snake_specs(self.dataset, self.vintage)\n            except Exception as e:\n                print(f\"Failed to load geographies: {e}\")\n                self._geo_cache[cache_key] = {}\n\n        geo_specs = self._geo_cache[cache_key]\n\n        friendly_names = {\n            \"state\": \"State\",\n            \"county\": \"County\",\n            \"tract\": \"Census Tract\",\n            \"block_group\": \"Block Group\",\n            \"place\": \"Place (City/Town)\",\n            \"county_subdivision\": \"County Subdivision\",\n            \"us\": \"United States (National)\",\n            \"region\": \"Region\",\n            \"division\": \"Division\",\n        }\n\n        # Get unique leaf geographies\n        options = {}\n        seen = set()\n        for hierarchy in geo_specs.values():\n            leaf = hierarchy[-1]\n            if leaf not in seen:\n                seen.add(leaf)\n                label = friendly_names.get(leaf, leaf.replace(\"_\", \" \").title())\n                options[label] = leaf\n\n        return options\n\n    @param.depends(\"dataset\", watch=True)\n    def _on_dataset_change(self):\n        \"\"\"Update year options when dataset changes.\"\"\"\n        new_year_options = self._get_year_options()\n        self._vintage_select.options = new_year_options\n\n        if self.vintage not in new_year_options.values():\n            first_year = list(new_year_options.values())[0]\n            self._vintage_select.value = first_year\n            self.vintage = first_year\n\n    @param.depends(\"dataset\", \"vintage\", watch=True)\n    def _on_dataset_vintage_change(self):\n        \"\"\"Update group and geo options when dataset or vintage changes.\"\"\"\n        new_group_options = self._get_group_options()\n        current_group = self.group\n        self._group_select.options = new_group_options\n        if current_group in new_group_options.values():\n            self._group_select.value = current_group\n        elif new_group_options:\n            self._group_select.value = list(new_group_options.values())[0]\n\n        new_geo_options = self._get_geo_options()\n        current_geo = self.geography\n        self._geo_select.options = new_geo_options\n        if current_geo in new_geo_options.values():\n            self._geo_select.value = current_geo\n        elif new_geo_options:\n            self._geo_select.value = list(new_geo_options.values())[0]\n\n    def _build_geo_kwargs(self):\n        \"\"\"Build geography kwargs for ced.download.\"\"\"\n        cache_key = (self.dataset, self.vintage)\n        geo_specs = self._geo_cache.get(cache_key, {})\n\n        # Find hierarchy ending with selected geography\n        target_geo = self.geography\n        hierarchy = None\n        for h in geo_specs.values():\n            if h[-1] == target_geo:\n                hierarchy = h\n                break\n\n        if not hierarchy:\n            return {\"state\": \"*\"}\n\n        # Build kwargs\n        kwargs = {}\n        state_fips = STATES.get(self.state_filter, \"*\")\n\n        for level in hierarchy:\n            if level == \"state\":\n                kwargs[\"state\"] = state_fips\n            else:\n                kwargs[level] = \"*\"\n\n        return kwargs\n\n    async def _on_fetch(self, event):\n        \"\"\"Fetch census data.\"\"\"\n        if not self.group:\n            self._error_placeholder.object = \"‚ö†Ô∏è Please select a variable group\"\n            self._error_placeholder.visible = True\n            return\n\n        self._error_placeholder.visible = False\n        self._message_placeholder.visible = False\n        self._progress_bar.visible = True\n        self._progress_bar.variant = \"indeterminate\"\n        self._progress_description.object = \"Fetching data...\"\n        self._progress_description.visible = True\n        self._fetch_button.disabled = True\n\n        try:\n            geo_kwargs = self._build_geo_kwargs()\n\n            df = await asyncio.to_thread(\n                ced.download,\n                dataset=self.dataset,\n                vintage=self.vintage,\n                download_variables=[\"NAME\"],\n                group=self.group,\n                **geo_kwargs,\n            )\n\n            if df is None or df.empty:\n                self._error_placeholder.object = \"‚ö†Ô∏è No data returned\"\n                self._error_placeholder.visible = True\n                return\n\n            await self._add_table(df)\n            self._message_placeholder.object = f\"‚úì Loaded {len(df):,} rows into '{self.table_alias}'\"\n            self._message_placeholder.visible = True\n            self.param.trigger(\"upload_successful\")\n\n        except Exception as e:\n            self._error_placeholder.object = f\"‚ö†Ô∏è Error: {e}\"\n            self._error_placeholder.visible = True\n        finally:\n            self._progress_bar.visible = False\n            self._progress_description.visible = False\n            self._fetch_button.disabled = False\n\n    async def _add_table(self, df):\n        \"\"\"Register DataFrame as a DuckDB source.\"\"\"\n        table_name = normalize_table_name(self.table_alias)\n        source = DuckDBSource.from_df(tables={table_name: df})\n        source.tables[table_name] = f\"SELECT * FROM {table_name}\"\n\n        source.metadata = {\n            table_name: {\n                \"dataset\": self.dataset,\n                \"vintage\": self.vintage,\n                \"group\": self.group,\n                \"geography\": self.geography,\n            }\n        }\n\n        self.outputs[\"source\"] = source\n        self.outputs[\"sources\"] = self.outputs.get(\"sources\", []) + [source]\n        self.outputs[\"table\"] = table_name\n        self.param.trigger(\"outputs\")\n        self._last_table = table_name\n        self._count += 1\n\n    def __panel__(self):\n        return self._layout\n\n\nui = lmai.ExplorerUI(\n    source_controls=[CensusControlsFull],\n    title=\"Census Data Explorer - Full\",\n    suggestions=[\n        (\"bar_chart\", \"Show the top 10 states by population\"),\n        (\"compare_arrows\", \"Compare different demographic variables\"),\n        (\"question_mark\", \"What are the demographic patterns?\"),\n    ],\n    log_level=\"DEBUG\",\n)\n\nui.servable()\n</code></pre> <p>This complete version includes all the features discussed: dynamic variable groups, multiple datasets, geography selection, state filtering, progress indicators, error handling, and reactive UI updates.</p>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#next-steps","level":2,"title":"Next steps","text":"<p>Extend this example by:</p> <ul> <li>Add custom analyses: Create specialized visualizations for demographic data (see Analyses configuration)</li> <li>Customize agents: Add domain expertise about Census variables and geography (see Agents configuration)</li> <li>Multiple sources: Combine Census data with other datasets for richer analysis (see Sources configuration)</li> </ul>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/census_data_ai_explorer/#see-also","level":2,"title":"See also","text":"<ul> <li>Source Controls ‚Äî Complete guide to creating custom source controls</li> <li>Data Sources ‚Äî File and database connections  </li> <li>Custom Analyses ‚Äî Building specialized visualizations</li> </ul>","path":["Examples","Tutorials","Building a Census Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/","level":1,"title":"Building a Dashboard with YAML","text":"<p>Build a complete Lumen dashboard using YAML specifications. This tutorial creates an interactive penguin data explorer with filters and multiple visualizations.</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#final-result","level":2,"title":"Final result","text":"<p>Time: 15 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#what-youll-build","level":2,"title":"What you'll build","text":"<p>An interactive dashboard with filtering, multiple chart types, and responsive layout. The tutorial follows nine steps:</p> <ol> <li>Create a YAML file - Set up the specification</li> <li>Add a data source - Load the Palmer Penguins dataset</li> <li>Add a table view - Display raw data</li> <li>Create a plot - Basic visualization</li> <li>Configure a scatter plot - Specific axes and colors</li> <li>Add filters and transforms - Interactive filtering and column selection</li> <li>Add multiple views - Histogram and table alongside scatter plot</li> <li>Improve the layout - Responsive sizing and positioning</li> <li>Add title and theme - Final polish</li> </ol> <p>Each step shows the YAML code and resulting output.</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#prerequisites","level":2,"title":"Prerequisites","text":"<p>Install Lumen:</p> <pre><code>pip install lumen\n</code></pre> <p>Why YAML specs?</p> <p>Lumen AI generates these specs automatically through conversation. Learn specs to:</p> <ul> <li>Customize AI outputs</li> <li>Version control dashboards</li> <li>Understand how Lumen works</li> <li>Access features not yet in AI</li> </ul> <p>Prefer AI? See Using Lumen AI instead.</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#1-create-a-yaml-file","level":2,"title":"1. Create a YAML file","text":"<p>Create <code>penguins.yaml</code> in your text editor.</p> <p>Time: 30 seconds</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#2-add-a-data-source","level":2,"title":"2. Add a data source","text":"<p>Load the Palmer Penguins dataset:</p> penguins.yaml<pre><code>sources:\n  penguin_source: # (1)!\n    type: file # (2)!\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv # (3)!\n</code></pre> <ol> <li>Source name - reference this in layouts</li> <li>File type handles CSV, Parquet, JSON</li> <li>Remote URL or local file path</li> </ol> <p>Launch the dashboard:</p> <pre><code>lumen serve penguins.yaml --show --autoreload\n</code></pre> <p>The <code>--autoreload</code> flag refreshes automatically when you save changes.</p> <p>Your browser opens, but the dashboard is empty‚Äîyou haven't added views yet.</p> <p>Time: 2 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#3-add-a-table-view","level":2,"title":"3. Add a table view","text":"<p>Display the raw data:</p> penguins.yaml<pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguins\n    source: penguin_source\n    views:\n      - type: table\n        table: penguin_table\n</code></pre> <p></p> <p>The table shows all columns. Note the column names for later plots.</p> <p>Time: 3 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#4-create-a-plot","level":2,"title":"4. Create a plot","text":"<p>Replace the table with a plot:</p> penguins.yaml<pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguins\n    source: penguin_source\n    views:\n      - type: hvplot # (1)!\n        table: penguin_table\n</code></pre> <ol> <li>hvPlot automatically chooses visualization</li> </ol> <p></p> <p>This default plot shows too much. Let's make it specific.</p> <p>Time: 4 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#5-configure-a-scatter-plot","level":2,"title":"5. Configure a scatter plot","text":"<p>Create a scatter plot with specific axes:</p> penguins.yaml<pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\nlayouts:\n  - title: Penguins\n    source: penguin_source\n    views:\n      - type: hvplot\n        table: penguin_table\n        kind: scatter # (1)!\n        x: bill_length_mm # (2)!\n        y: bill_depth_mm\n        color: species # (3)!\n</code></pre> <ol> <li>Scatter plot type</li> <li>X and Y axes from table columns</li> <li>Color points by species</li> </ol> <p></p> <p>Now you see the relationship between bill length and depth, colored by species.</p> <p>Time: 6 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#6-add-filters-and-transforms","level":2,"title":"6. Add filters and transforms","text":"<p>Add interactive filters and select columns:</p> penguins.yaml<pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines: # (1)!\n  penguin_pipeline:\n    source: penguin_source\n    table: penguin_table\n    filters: # (2)!\n      - type: widget\n        field: sex\n      - type: widget\n        field: island\n    transforms: # (3)!\n      - type: columns\n        columns: ['species', 'island', 'sex', 'year', \n                  'bill_length_mm', 'bill_depth_mm']\n\nlayouts:\n  - title: Penguins\n    pipeline: penguin_pipeline # (4)!\n    views:\n      - type: hvplot\n        x: bill_length_mm\n        y: bill_depth_mm\n        kind: scatter\n        color: species\n</code></pre> <ol> <li>Pipelines connect sources to views with filters and transforms</li> <li>Widget filters create interactive dropdowns</li> <li>Column transform selects specific columns</li> <li>Reference pipeline instead of source</li> </ol> <p></p> <p>Users can now filter by sex and island using sidebar widgets.</p> <p>Time: 8 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#7-add-multiple-views","level":2,"title":"7. Add multiple views","text":"<p>Add histogram and table views:</p> penguins.yaml<pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  penguin_pipeline:\n    source: penguin_source\n    table: penguin_table\n    filters:\n      - type: widget\n        field: sex\n      - type: widget\n        field: island\n    transforms:\n      - type: columns\n        columns: ['species', 'island', 'sex', 'year', \n                  'bill_length_mm', 'bill_depth_mm']\n\nlayouts:\n  - title: Penguins\n    pipeline: penguin_pipeline\n    views:\n      - type: hvplot\n        x: bill_length_mm\n        y: bill_depth_mm\n        kind: scatter\n        color: species\n      - type: hvplot\n        kind: hist\n        y: bill_length_mm\n      - type: table\n        show_index: false\n</code></pre> <p></p> <p>All three views update when you change filters.</p> <p>Time: 10 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#8-improve-the-layout","level":2,"title":"8. Improve the layout","text":"<p>Configure positioning and sizing:</p> penguins.yaml<pre><code>sources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  penguin_pipeline:\n    source: penguin_source\n    table: penguin_table\n    filters:\n      - type: widget\n        field: sex\n      - type: widget\n        field: island\n    transforms:\n      - type: columns\n        columns: ['species', 'island', 'sex', 'year', \n                  'bill_length_mm', 'bill_depth_mm']\n\nlayouts:\n  - title: Penguins\n    pipeline: penguin_pipeline\n    layout: [[0], [1, 2]] # (1)!\n    sizing_mode: stretch_width # (2)!\n    height: 800\n    views:\n      - type: hvplot\n        x: bill_length_mm\n        y: bill_depth_mm\n        kind: scatter\n        color: species\n        responsive: true # (3)!\n        height: 400\n      - type: hvplot\n        kind: hist\n        y: bill_length_mm\n        responsive: true\n        height: 300\n      - type: table\n        show_index: false\n        height: 300\n</code></pre> <ol> <li>Scatter on top row, histogram and table side-by-side on bottom</li> <li>Views expand to fill width</li> <li>Plots resize with browser window</li> </ol> <p></p> <p>Time: 12 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#9-add-title-and-theme","level":2,"title":"9. Add title and theme","text":"<p>Final polish:</p> penguins.yaml<pre><code>config:\n  title: Palmer Penguins\n  theme: dark # (1)!\n\nsources:\n  penguin_source:\n    type: file\n    tables:\n      penguin_table: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  penguin_pipeline:\n    source: penguin_source\n    table: penguin_table\n    filters:\n      - type: widget\n        field: sex\n      - type: widget\n        field: island\n    transforms:\n      - type: columns\n        columns: ['species', 'island', 'sex', 'year', \n                  'bill_length_mm', 'bill_depth_mm']\n\nlayouts:\n  - title: Penguins\n    pipeline: penguin_pipeline\n    layout: [[0], [1, 2]]\n    sizing_mode: stretch_width\n    height: 800\n    views:\n      - type: hvplot\n        x: bill_length_mm\n        y: bill_depth_mm\n        kind: scatter\n        color: species\n        responsive: true\n        height: 400\n      - type: hvplot\n        kind: hist\n        y: bill_length_mm\n        responsive: true\n        height: 300\n      - type: table\n        show_index: false\n        height: 300\n        theme: midnight\n</code></pre> <ol> <li>Dark theme for the entire dashboard</li> </ol> <p></p> <p>üéâ Done! You've built a complete interactive dashboard.</p> <p>Total time: 15 minutes</p>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#what-you-learned","level":2,"title":"What you learned","text":"<ul> <li>Create YAML specifications</li> <li>Load data from remote sources</li> <li>Add interactive filters</li> <li>Create multiple visualization types</li> <li>Configure responsive layouts</li> <li>Apply themes and styling</li> </ul>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/penguins_dashboard_spec/#next-steps","level":2,"title":"Next steps","text":"<p>Learn the system:</p> <ul> <li>Core Concepts - Understand sources, pipelines, views</li> <li>Sources Guide - Load from databases and APIs</li> <li>Pipelines Guide - All filters and transforms</li> <li>Views Guide - All visualization types</li> </ul> <p>Try these challenges:</p> <ul> <li>üìä Replace histogram with box plot (<code>kind: box</code>)</li> <li>üé® Color scatter by different field</li> <li>üîç Add year filter</li> <li>üì• Enable downloads (see Downloads guide)</li> </ul>","path":["Building a Dashboard with YAML"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/","level":1,"title":"Building a SaaS Executive Dashboard","text":"<p>Executive dashboards often start as one-off analyses that become recurring requests‚Äî\"Can you update the metrics for Monday's meeting?\" turns into hours of manual work each week. Lumen Reports solves this by making dashboards reproducible with a single click: define your queries and visualizations once, then execute them whenever you need fresh results.</p> <p>This tutorial builds an executive dashboard for CloudSync, a fictional B2B SaaS company. You'll combine SQL queries for precise metrics, custom visualizations for trends, and AI-generated insights‚Äîall exportable as Jupyter notebooks or deployable as web apps.</p>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#final-result","level":2,"title":"Final result","text":"<p>Time: 15-20 minutes</p>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#what-youll-build","level":2,"title":"What you'll build","text":"<p>An interactive executive dashboard with three collapsible sections that combine SQL queries, custom visualizations, and AI-generated insights. The tutorial walks through setting up a DuckDB data source, creating custom Actions for visualizations, adding SQLQuery tasks for deterministic metrics, integrating ChatAgent for AI insights, and assembling everything into a deployable report. Each step introduces key Lumen Reports concepts with links to detailed configuration guides.</p>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#prerequisites","level":2,"title":"Prerequisites","text":"<p>Install the required packages:</p> <pre><code>pip install lumen-ai panel\n</code></pre>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#1-duckdb-provides-in-memory-data-for-prototyping","level":2,"title":"1. DuckDB provides in-memory data for prototyping","text":"<p>DuckDBSource connects to databases or creates sources from DataFrames. The sample data below represents a typical SaaS company‚Äîin production, you would connect to your actual database.</p> <p>Key concepts: DuckDBSource connects to DuckDB databases or creates in-memory sources from DataFrames (see Sources configuration). The <code>from_df()</code> method creates a source from pandas DataFrames for prototyping.</p> saas_dashboard.py<pre><code>import pandas as pd\nimport panel as pn\n\nfrom lumen.ai.llm import OpenAI\nfrom lumen.ai.report import Action, Report, Section, ActorTask\nfrom lumen.ai.actions import SQLQuery\nfrom lumen.ai.agents import ChatAgent\nfrom lumen.ai.editors import LumenEditor\nfrom lumen.pipeline import Pipeline\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.views import VegaLiteView\n\npn.extension(\"tabulator\", \"vega\")\n\n# Sample data for CloudSync SaaS company\ncustomers_df = pd.DataFrame({\n    \"customer_id\": [f\"C{str(i).zfill(4)}\" for i in range(1, 51)],\n    \"company_name\": [\n        \"Acme Corp\", \"TechFlow\", \"DataPrime\", \"CloudNine\", \"SyncWave\",\n        \"ByteForce\", \"NetSphere\", \"CodeCraft\", \"InfoPulse\", \"DigiCore\",\n        \"WebMatrix\", \"AppVault\", \"LogicHub\", \"CyberEdge\", \"PixelWorks\",\n        \"StreamLine\", \"NodeStack\", \"ApiFirst\", \"DevOps Inc\", \"ScaleUp Co\",\n        \"GrowthLab\", \"StartupXYZ\", \"InnovateCo\", \"FutureTech\", \"SmartSys\",\n        \"RapidDev\", \"AgileTeam\", \"SprintCo\", \"LaunchPad\", \"RocketFuel\",\n        \"TurboCode\", \"FastTrack\", \"QuickByte\", \"SwiftApp\", \"ZoomData\",\n        \"FlashNet\", \"InstantIO\", \"RealTime\", \"LiveSync\", \"HotDeploy\",\n        \"CoolStack\", \"FreshCode\", \"NewWave\", \"NextGen\", \"TopTier\",\n        \"EliteTech\", \"PrimeSoft\", \"AlphaNet\", \"BetaLabs\", \"GammaSys\"\n    ],\n    \"industry\": ([\"Technology\"] * 15 + [\"Healthcare\"] * 10 + [\"Finance\"] * 10 + \n                 [\"Retail\"] * 8 + [\"Manufacturing\"] * 7),\n    \"signup_date\": pd.to_datetime([\n        \"2023-01-15\", \"2023-02-20\", \"2023-02-28\", \"2023-03-10\", \"2023-03-22\",\n        \"2023-04-05\", \"2023-04-18\", \"2023-05-01\", \"2023-05-15\", \"2023-06-01\",\n        \"2023-06-20\", \"2023-07-08\", \"2023-07-25\", \"2023-08-12\", \"2023-08-30\",\n        \"2023-09-15\", \"2023-09-28\", \"2023-10-10\", \"2023-10-25\", \"2023-11-05\",\n        \"2023-11-20\", \"2023-12-01\", \"2023-12-15\", \"2024-01-08\", \"2024-01-22\",\n        \"2024-02-05\", \"2024-02-19\", \"2024-03-04\", \"2024-03-18\", \"2024-04-01\",\n        \"2024-04-15\", \"2024-05-01\", \"2024-05-15\", \"2024-06-01\", \"2024-06-15\",\n        \"2024-07-01\", \"2024-07-15\", \"2024-08-01\", \"2024-08-15\", \"2024-09-01\",\n        \"2024-09-15\", \"2024-10-01\", \"2024-10-15\", \"2024-11-01\", \"2024-11-15\",\n        \"2024-12-01\", \"2024-12-15\", \"2025-01-05\", \"2025-01-10\", \"2025-01-15\"\n    ]),\n    \"region\": ([\"North America\"] * 20 + [\"Europe\"] * 15 + \n               [\"Asia Pacific\"] * 10 + [\"Latin America\"] * 5),\n    \"company_size\": ([\"enterprise\"] * 10 + [\"smb\"] * 25 + [\"startup\"] * 15),\n    \"status\": ([\"active\"] * 42 + [\"churned\"] * 5 + [\"trial\"] * 3)\n})\n\nsubscriptions_df = pd.DataFrame({\n    \"subscription_id\": [f\"S{str(i).zfill(4)}\" for i in range(1, 51)],\n    \"customer_id\": [f\"C{str(i).zfill(4)}\" for i in range(1, 51)],\n    \"plan_name\": ([\"enterprise\"] * 10 + [\"professional\"] * 20 + [\"starter\"] * 20),\n    \"mrr\": ([2500] * 10 + [500] * 20 + [99] * 20),\n    \"start_date\": customers_df[\"signup_date\"].tolist(),\n    \"end_date\": [None] * 45 + [\"2024-12-01\"] * 5,\n    \"billing_cycle\": ([\"annual\"] * 15 + [\"monthly\"] * 35)\n})\n\nemployees_df = pd.DataFrame({\n    \"employee_id\": [f\"E{str(i).zfill(3)}\" for i in range(1, 36)],\n    \"name\": [\n        \"Alice Chen\", \"Bob Smith\", \"Carol Davis\", \"Dan Wilson\", \"Eva Martinez\",\n        \"Frank Brown\", \"Grace Lee\", \"Henry Taylor\", \"Ivy Anderson\", \"Jack Thomas\",\n        \"Kate Johnson\", \"Leo Garcia\", \"Mia Robinson\", \"Noah Clark\", \"Olivia Lewis\",\n        \"Paul Walker\", \"Quinn Hall\", \"Rose Allen\", \"Sam Young\", \"Tina King\",\n        \"Uma Wright\", \"Vic Scott\", \"Wendy Green\", \"Xavier Adams\", \"Yara Baker\",\n        \"Zack Nelson\", \"Amy Hill\", \"Ben Moore\", \"Chloe Jackson\", \"Derek White\",\n        \"Emma Harris\", \"Felix Martin\", \"Gina Thompson\", \"Hugo Garcia\", \"Iris Lee\"\n    ],\n    \"department\": ([\"engineering\"] * 14 + [\"sales\"] * 8 + \n                   [\"support\"] * 7 + [\"marketing\"] * 6),\n    \"role\": (\n        [\"Senior Engineer\"] * 4 + [\"Engineer\"] * 6 + [\"Junior Engineer\"] * 4 +\n        [\"Sales Director\"] * 2 + [\"Account Executive\"] * 6 +\n        [\"Support Lead\"] * 2 + [\"Support Specialist\"] * 5 +\n        [\"Marketing Manager\"] * 2 + [\"Marketing Specialist\"] * 4\n    ),\n    \"hire_date\": pd.to_datetime([\n        \"2022-01-15\", \"2022-03-01\", \"2022-06-15\", \"2022-09-01\", \"2023-01-10\",\n        \"2023-02-15\", \"2023-04-01\", \"2023-05-15\", \"2023-07-01\", \"2023-08-15\",\n        \"2023-09-01\", \"2023-10-15\", \"2023-11-01\", \"2023-12-01\", \"2024-01-15\",\n        \"2024-02-01\", \"2024-03-15\", \"2024-04-01\", \"2024-05-01\", \"2024-06-01\",\n        \"2024-07-01\", \"2024-08-01\", \"2024-09-01\", \"2024-09-15\", \"2024-10-01\",\n        \"2024-10-15\", \"2024-11-01\", \"2024-11-15\", \"2024-12-01\", \"2024-12-15\",\n        \"2025-01-02\", \"2025-01-05\", \"2025-01-08\", \"2025-01-10\", \"2025-01-12\"\n    ]),\n    \"salary\": (\n        [150000] * 4 + [120000] * 6 + [85000] * 4 +\n        [140000] * 2 + [95000] * 6 +\n        [90000] * 2 + [55000] * 5 +\n        [110000] * 2 + [70000] * 4\n    ),\n    \"status\": [\"active\"] * 33 + [\"on_leave\"] * 2\n})\n\nsource = DuckDBSource.from_df(tables={\n    \"customers\": customers_df,\n    \"subscriptions\": subscriptions_df,\n    \"employees\": employees_df\n})\n\nllm = OpenAI()  # (1)!\n</code></pre> <ol> <li>The LLM is used for AI-generated captions on <code>SQLQuery</code> and insights from <code>ChatAgent</code></li> </ol>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#2-custom-actions-enable-specialized-visualizations","level":2,"title":"2. Custom Actions enable specialized visualizations","text":"<p>Actions let you write custom Python logic for specialized visualizations. The <code>CustomerAcquisitionChart</code> below shows growth trends by subclassing <code>Action</code> and implementing <code>_execute</code>.</p> <p>Key concepts: Custom Actions extend Lumen Reports by subclassing <code>Action</code> (see Reports configuration). The <code>_execute</code> method contains visualization logic and returns <code>(outputs, context_updates)</code>. Tasks communicate through a shared context dictionary. LumenEditor wraps components with titles for the report UI.</p> saas_dashboard.py<pre><code>class CustomerAcquisitionChart(Action):\n    \"\"\"Visualize customer acquisition trends by company size.\"\"\"\n\n    async def _execute(self, context, **kwargs):\n        src = context[\"source\"]  # (1)!\n\n        acquisition_src = src.create_sql_expr_source(tables={\n            \"acquisition\": \"\"\"\n                SELECT \n                    DATE_TRUNC('month', signup_date) AS month,\n                    company_size,\n                    COUNT(*) AS new_customers\n                FROM customers\n                WHERE status != 'churned'\n                GROUP BY month, company_size\n                ORDER BY month\n            \"\"\"\n        })\n\n        pipeline = Pipeline(source=acquisition_src, table=\"acquisition\")\n\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": \"bar\",\n                \"encoding\": {\n                    \"x\": {\"field\": \"month\", \"type\": \"temporal\", \"title\": \"Month\"},\n                    \"y\": {\"field\": \"new_customers\", \"type\": \"quantitative\", \n                          \"title\": \"New Customers\"},\n                    \"color\": {\n                        \"field\": \"company_size\", \n                        \"type\": \"nominal\", \n                        \"title\": \"Segment\",\n                        \"scale\": {\"scheme\": \"tableau10\"}\n                    }\n                },\n                \"width\": \"container\",\n                \"height\": 300\n            },\n            sizing_mode=\"stretch_width\",\n            height=350\n        )\n\n        return [LumenEditor(component=chart, title=\"Customer Acquisition by Segment\")], {}  # (2)!\n</code></pre> <ol> <li>Access shared data from the context dictionary</li> <li>Return a tuple of <code>(outputs, context_updates)</code> ‚Äî use <code>{}</code> when not updating context</li> </ol>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#mrr-donut-chart-shows-revenue-distribution-by-plan","level":3,"title":"MRR donut chart shows revenue distribution by plan","text":"saas_dashboard.py<pre><code>class MRRDonutChart(Action):\n    \"\"\"Visualize MRR distribution by plan as a donut chart.\"\"\"\n\n    async def _execute(self, context, **kwargs):\n        src = context[\"source\"]\n\n        mrr_src = src.create_sql_expr_source(tables={\n            \"mrr_by_plan\": \"\"\"\n                SELECT \n                    s.plan_name,\n                    SUM(s.mrr) AS total_mrr,\n                    COUNT(*) AS subscriptions\n                FROM subscriptions s\n                JOIN customers c ON s.customer_id = c.customer_id\n                WHERE c.status = 'active' AND s.end_date IS NULL\n                GROUP BY s.plan_name\n            \"\"\"\n        })\n\n        pipeline = Pipeline(source=mrr_src, table=\"mrr_by_plan\")\n\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": {\"type\": \"arc\", \"innerRadius\": 60},\n                \"encoding\": {\n                    \"theta\": {\"field\": \"total_mrr\", \"type\": \"quantitative\"},\n                    \"color\": {\n                        \"field\": \"plan_name\", \n                        \"type\": \"nominal\", \n                        \"title\": \"Plan\",\n                        \"scale\": {\"scheme\": \"category10\"}\n                    },\n                    \"tooltip\": [\n                        {\"field\": \"plan_name\", \"title\": \"Plan\"},\n                        {\"field\": \"total_mrr\", \"title\": \"MRR\", \"format\": \"$,.0f\"},\n                        {\"field\": \"subscriptions\", \"title\": \"Count\"}\n                    ]\n                },\n                \"width\": 300,\n                \"height\": 300\n            },\n            height=350\n        )\n\n        return [LumenEditor(component=chart, title=\"MRR by Plan\")], {}\n</code></pre>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#headcount-bar-chart-shows-team-composition","level":3,"title":"Headcount bar chart shows team composition","text":"saas_dashboard.py<pre><code>class HeadcountChart(Action):\n    \"\"\"Visualize headcount distribution by department.\"\"\"\n\n    async def _execute(self, context, **kwargs):\n        src = context[\"source\"]\n\n        dept_src = src.create_sql_expr_source(tables={\n            \"headcount\": \"\"\"\n                SELECT \n                    department,\n                    COUNT(*) AS headcount,\n                    ROUND(AVG(salary), 0) AS avg_salary\n                FROM employees\n                WHERE status = 'active'\n                GROUP BY department\n                ORDER BY headcount DESC\n            \"\"\"\n        })\n\n        pipeline = Pipeline(source=dept_src, table=\"headcount\")\n\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": {\"type\": \"bar\", \"cornerRadiusEnd\": 4},\n                \"encoding\": {\n                    \"y\": {\"field\": \"department\", \"type\": \"nominal\", \n                          \"sort\": \"-x\", \"title\": \"Department\"},\n                    \"x\": {\"field\": \"headcount\", \"type\": \"quantitative\", \n                          \"title\": \"Employees\"},\n                    \"color\": {\n                        \"field\": \"department\", \n                        \"type\": \"nominal\", \n                        \"legend\": None,\n                        \"scale\": {\"scheme\": \"tableau10\"}\n                    },\n                    \"tooltip\": [\n                        {\"field\": \"department\", \"title\": \"Department\"},\n                        {\"field\": \"headcount\", \"title\": \"Headcount\"},\n                        {\"field\": \"avg_salary\", \"title\": \"Avg Salary\", \"format\": \"$,.0f\"}\n                    ]\n                },\n                \"width\": \"container\",\n                \"height\": 200\n            },\n            sizing_mode=\"stretch_width\",\n            height=250\n        )\n\n        return [LumenEditor(component=chart, title=\"Headcount by Department\")], {}\n</code></pre>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#3-sqlquery-executes-deterministic-metrics-without-custom-code","level":2,"title":"3. SQLQuery executes deterministic metrics without custom code","text":"<p>SQLQuery provides SQL execution with AI-generated captions‚Äîuse it for known metrics that don't require custom visualization logic.</p> <p>Key concepts: SQLQuery executes SQL and displays results as tables (see Reports configuration). The <code>llm</code> parameter enables AI-generated captions explaining the results. The <code>source</code> parameter specifies the data source to query against.</p> saas_dashboard.py<pre><code># Customer metrics\ncustomer_by_region = SQLQuery(\n    source=source,\n    table=\"customers_by_region\",\n    sql_expr=\"\"\"\n        SELECT \n            region,\n            COUNT(*) AS total_customers,\n            SUM(CASE WHEN status = 'active' THEN 1 ELSE 0 END) AS active,\n            SUM(CASE WHEN status = 'churned' THEN 1 ELSE 0 END) AS churned,\n            ROUND(100.0 * SUM(CASE WHEN status = 'churned' THEN 1 ELSE 0 END) \n                  / COUNT(*), 1) AS churn_rate_pct\n        FROM customers\n        GROUP BY region\n        ORDER BY total_customers DESC\n    \"\"\",\n    title=\"Customers by Region\",\n    llm=llm\n)\n\ncustomer_by_industry = SQLQuery(\n    source=source,\n    table=\"customers_by_industry\",\n    sql_expr=\"\"\"\n        SELECT \n            industry,\n            company_size,\n            COUNT(*) AS customer_count\n        FROM customers\n        WHERE status = 'active'\n        GROUP BY industry, company_size\n        ORDER BY customer_count DESC\n    \"\"\",\n    title=\"Active Customers by Industry &amp; Size\",\n    llm=llm\n)\n\n# Revenue metrics\nrevenue_summary = SQLQuery(\n    source=source,\n    table=\"revenue_summary\",\n    sql_expr=\"\"\"\n        SELECT \n            SUM(s.mrr) AS total_mrr,\n            COUNT(DISTINCT s.customer_id) AS paying_customers,\n            ROUND(SUM(s.mrr) / COUNT(DISTINCT s.customer_id), 2) AS arpu,\n            SUM(CASE WHEN s.plan_name = 'enterprise' THEN s.mrr ELSE 0 END) \n                AS enterprise_mrr,\n            SUM(CASE WHEN s.plan_name = 'professional' THEN s.mrr ELSE 0 END) \n                AS professional_mrr,\n            SUM(CASE WHEN s.plan_name = 'starter' THEN s.mrr ELSE 0 END) \n                AS starter_mrr\n        FROM subscriptions s\n        JOIN customers c ON s.customer_id = c.customer_id\n        WHERE c.status = 'active' AND s.end_date IS NULL\n    \"\"\",\n    title=\"Revenue Summary\",\n    llm=llm\n)\n\ntop_customers = SQLQuery(\n    source=source,\n    table=\"top_customers\",\n    sql_expr=\"\"\"\n        SELECT \n            c.company_name,\n            c.industry,\n            s.plan_name,\n            s.mrr,\n            ROUND(100.0 * s.mrr / (SELECT SUM(mrr) FROM subscriptions \n                  WHERE end_date IS NULL), 2) AS pct_of_total\n        FROM customers c\n        JOIN subscriptions s ON c.customer_id = s.customer_id\n        WHERE c.status = 'active' AND s.end_date IS NULL\n        ORDER BY s.mrr DESC\n        LIMIT 10\n    \"\"\",\n    title=\"Top 10 Customers by MRR\",\n    llm=llm\n)\n\n# Employee metrics\nemployee_summary = SQLQuery(\n    source=source,\n    table=\"employee_summary\",\n    sql_expr=\"\"\"\n        SELECT \n            COUNT(*) AS total_employees,\n            SUM(CASE WHEN status = 'active' THEN 1 ELSE 0 END) AS active,\n            SUM(CASE WHEN hire_date &gt;= CURRENT_DATE - INTERVAL '90 days' \n                THEN 1 ELSE 0 END) AS recent_hires,\n            ROUND(AVG(salary), 0) AS avg_salary,\n            ROUND(AVG(DATEDIFF('day', hire_date, CURRENT_DATE)), 0) \n                AS avg_tenure_days\n        FROM employees\n    \"\"\",\n    title=\"Workforce Summary\",\n    llm=llm\n)\n\ncompensation_by_role = SQLQuery(\n    source=source,\n    table=\"compensation\",\n    sql_expr=\"\"\"\n        SELECT \n            department,\n            role,\n            COUNT(*) AS count,\n            MIN(salary) AS min_salary,\n            ROUND(AVG(salary), 0) AS avg_salary,\n            MAX(salary) AS max_salary\n        FROM employees\n        WHERE status = 'active'\n        GROUP BY department, role\n        ORDER BY department, avg_salary DESC\n    \"\"\",\n    title=\"Compensation by Role\",\n    llm=llm\n)\n</code></pre>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#4-actortask-wraps-agents-for-ai-powered-analysis","level":2,"title":"4. ActorTask wraps agents for AI-powered analysis","text":"<p>ActorTask wraps any Agent for use in Reports. ChatAgent generates narrative insights based on the data.</p> <p>Key concepts: ActorTask wraps any Agent for use in Reports (see Reports configuration). ChatAgent generates natural language responses. The <code>instruction</code> parameter guides the AI on what to analyze and how to format the response.</p> saas_dashboard.py<pre><code>customer_insights = ActorTask(\n    ChatAgent(llm=llm),\n    title=\"Customer Insights\",\n    instruction=\"\"\"\n        Based on the customer data above, provide a brief analysis:\n        1. Key growth trends (2-3 points)\n        2. Regional performance highlights  \n        3. One actionable recommendation\n        Keep response under 150 words.\n    \"\"\"\n)\n\nrevenue_insights = ActorTask(\n    ChatAgent(llm=llm),\n    title=\"Revenue Insights\",\n    instruction=\"\"\"\n        Analyze the subscription and revenue data to identify:\n        1. Revenue concentration observations\n        2. Plan mix analysis\n        3. Growth opportunities\n        Be specific with numbers. Keep under 150 words.\n    \"\"\"\n)\n\nteam_insights = ActorTask(\n    ChatAgent(llm=llm),\n    title=\"Team Insights\",\n    instruction=\"\"\"\n        Based on the employee data, summarize:\n        1. Team structure observations\n        2. Hiring momentum\n        3. Compensation insights\n        Keep factual and under 150 words.\n    \"\"\"\n)\n</code></pre>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#5-report-and-section-containers-organize-tasks-into-collapsible-groups","level":2,"title":"5. Report and Section containers organize tasks into collapsible groups","text":"<p>Report is the top-level container with controls to execute, export, and configure. Sections group related tasks as collapsible accordions.</p> <p>Key concepts: Report is the top-level container with execution, export, and configuration controls. Section groups related tasks as collapsible accordions. The <code>context</code> parameter shares data across all tasks in the report. Task ordering matters‚Äîeach task can access outputs from previous tasks.</p> saas_dashboard.py<pre><code>report = Report(\n    # Section 1: Customer Analytics\n    Section(\n        CustomerAcquisitionChart(title=\"Acquisition Trends\"),\n        customer_by_region,\n        customer_by_industry,\n        customer_insights,\n        title=\"üìä Customer Analytics\"\n    ),\n\n    # Section 2: Subscription &amp; Revenue\n    Section(\n        MRRDonutChart(title=\"MRR Distribution\"),\n        revenue_summary,\n        top_customers,\n        revenue_insights,\n        title=\"üí∞ Subscription &amp; Revenue\"\n    ),\n\n    # Section 3: Employee Analytics\n    Section(\n        HeadcountChart(title=\"Team Composition\"),\n        employee_summary,\n        compensation_by_role,\n        team_insights,\n        title=\"üë• Employee Analytics\"\n    ),\n\n    title=\"CloudSync Executive Dashboard\",\n    context={\"source\": source}  # (1)!\n)\n\n# Run the report\nasync def main():\n    await report.execute()\n    report.show(port=5006)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre> <ol> <li>The <code>context</code> parameter makes <code>source</code> available to all tasks via <code>context[\"source\"]</code></li> </ol>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#run-the-dashboard-with-panel-serve","level":2,"title":"Run the dashboard with Panel serve","text":"<pre><code>panel serve saas_dashboard.py --show\n</code></pre> <p>Your browser opens to the executive dashboard. The controls at the top let you execute all sections (‚ñ∂), clear outputs (‚úï), export to Jupyter notebook (‚Üì), and configure options (‚öô). Click section headers to expand or collapse each area.</p>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#complete-code","level":2,"title":"Complete code","text":"saas_dashboard.py<pre><code>\"\"\"\nCloudSync Executive Dashboard\nBuild a one-click reproducible analytics dashboard using Lumen Reports.\n\"\"\"\n\nimport pandas as pd\nimport panel as pn\n\nfrom lumen.ai.llm import OpenAI\nfrom lumen.ai.report import Action, Report, Section, ActorTask\nfrom lumen.ai.actions import SQLQuery\nfrom lumen.ai.agents import ChatAgent\nfrom lumen.ai.editors import LumenEditor\nfrom lumen.pipeline import Pipeline\nfrom lumen.sources.duckdb import DuckDBSource\nfrom lumen.views import VegaLiteView\n\npn.extension(\"tabulator\", \"vega\")\n\n\n# =============================================================================\n# DATA SOURCE\n# =============================================================================\n\ncustomers_df = pd.DataFrame({\n    \"customer_id\": [f\"C{str(i).zfill(4)}\" for i in range(1, 51)],\n    \"company_name\": [\n        \"Acme Corp\", \"TechFlow\", \"DataPrime\", \"CloudNine\", \"SyncWave\",\n        \"ByteForce\", \"NetSphere\", \"CodeCraft\", \"InfoPulse\", \"DigiCore\",\n        \"WebMatrix\", \"AppVault\", \"LogicHub\", \"CyberEdge\", \"PixelWorks\",\n        \"StreamLine\", \"NodeStack\", \"ApiFirst\", \"DevOps Inc\", \"ScaleUp Co\",\n        \"GrowthLab\", \"StartupXYZ\", \"InnovateCo\", \"FutureTech\", \"SmartSys\",\n        \"RapidDev\", \"AgileTeam\", \"SprintCo\", \"LaunchPad\", \"RocketFuel\",\n        \"TurboCode\", \"FastTrack\", \"QuickByte\", \"SwiftApp\", \"ZoomData\",\n        \"FlashNet\", \"InstantIO\", \"RealTime\", \"LiveSync\", \"HotDeploy\",\n        \"CoolStack\", \"FreshCode\", \"NewWave\", \"NextGen\", \"TopTier\",\n        \"EliteTech\", \"PrimeSoft\", \"AlphaNet\", \"BetaLabs\", \"GammaSys\"\n    ],\n    \"industry\": ([\"Technology\"] * 15 + [\"Healthcare\"] * 10 + [\"Finance\"] * 10 + \n                 [\"Retail\"] * 8 + [\"Manufacturing\"] * 7),\n    \"signup_date\": pd.to_datetime([\n        \"2023-01-15\", \"2023-02-20\", \"2023-02-28\", \"2023-03-10\", \"2023-03-22\",\n        \"2023-04-05\", \"2023-04-18\", \"2023-05-01\", \"2023-05-15\", \"2023-06-01\",\n        \"2023-06-20\", \"2023-07-08\", \"2023-07-25\", \"2023-08-12\", \"2023-08-30\",\n        \"2023-09-15\", \"2023-09-28\", \"2023-10-10\", \"2023-10-25\", \"2023-11-05\",\n        \"2023-11-20\", \"2023-12-01\", \"2023-12-15\", \"2024-01-08\", \"2024-01-22\",\n        \"2024-02-05\", \"2024-02-19\", \"2024-03-04\", \"2024-03-18\", \"2024-04-01\",\n        \"2024-04-15\", \"2024-05-01\", \"2024-05-15\", \"2024-06-01\", \"2024-06-15\",\n        \"2024-07-01\", \"2024-07-15\", \"2024-08-01\", \"2024-08-15\", \"2024-09-01\",\n        \"2024-09-15\", \"2024-10-01\", \"2024-10-15\", \"2024-11-01\", \"2024-11-15\",\n        \"2024-12-01\", \"2024-12-15\", \"2025-01-05\", \"2025-01-10\", \"2025-01-15\"\n    ]),\n    \"region\": ([\"North America\"] * 20 + [\"Europe\"] * 15 + \n               [\"Asia Pacific\"] * 10 + [\"Latin America\"] * 5),\n    \"company_size\": ([\"enterprise\"] * 10 + [\"smb\"] * 25 + [\"startup\"] * 15),\n    \"status\": ([\"active\"] * 42 + [\"churned\"] * 5 + [\"trial\"] * 3)\n})\n\nsubscriptions_df = pd.DataFrame({\n    \"subscription_id\": [f\"S{str(i).zfill(4)}\" for i in range(1, 51)],\n    \"customer_id\": [f\"C{str(i).zfill(4)}\" for i in range(1, 51)],\n    \"plan_name\": ([\"enterprise\"] * 10 + [\"professional\"] * 20 + [\"starter\"] * 20),\n    \"mrr\": ([2500] * 10 + [500] * 20 + [99] * 20),\n    \"start_date\": customers_df[\"signup_date\"].tolist(),\n    \"end_date\": [None] * 45 + [\"2024-12-01\"] * 5,\n    \"billing_cycle\": ([\"annual\"] * 15 + [\"monthly\"] * 35)\n})\n\nemployees_df = pd.DataFrame({\n    \"employee_id\": [f\"E{str(i).zfill(3)}\" for i in range(1, 36)],\n    \"name\": [\n        \"Alice Chen\", \"Bob Smith\", \"Carol Davis\", \"Dan Wilson\", \"Eva Martinez\",\n        \"Frank Brown\", \"Grace Lee\", \"Henry Taylor\", \"Ivy Anderson\", \"Jack Thomas\",\n        \"Kate Johnson\", \"Leo Garcia\", \"Mia Robinson\", \"Noah Clark\", \"Olivia Lewis\",\n        \"Paul Walker\", \"Quinn Hall\", \"Rose Allen\", \"Sam Young\", \"Tina King\",\n        \"Uma Wright\", \"Vic Scott\", \"Wendy Green\", \"Xavier Adams\", \"Yara Baker\",\n        \"Zack Nelson\", \"Amy Hill\", \"Ben Moore\", \"Chloe Jackson\", \"Derek White\",\n        \"Emma Harris\", \"Felix Martin\", \"Gina Thompson\", \"Hugo Garcia\", \"Iris Lee\"\n    ],\n    \"department\": ([\"engineering\"] * 14 + [\"sales\"] * 8 + \n                   [\"support\"] * 7 + [\"marketing\"] * 6),\n    \"role\": (\n        [\"Senior Engineer\"] * 4 + [\"Engineer\"] * 6 + [\"Junior Engineer\"] * 4 +\n        [\"Sales Director\"] * 2 + [\"Account Executive\"] * 6 +\n        [\"Support Lead\"] * 2 + [\"Support Specialist\"] * 5 +\n        [\"Marketing Manager\"] * 2 + [\"Marketing Specialist\"] * 4\n    ),\n    \"hire_date\": pd.to_datetime([\n        \"2022-01-15\", \"2022-03-01\", \"2022-06-15\", \"2022-09-01\", \"2023-01-10\",\n        \"2023-02-15\", \"2023-04-01\", \"2023-05-15\", \"2023-07-01\", \"2023-08-15\",\n        \"2023-09-01\", \"2023-10-15\", \"2023-11-01\", \"2023-12-01\", \"2024-01-15\",\n        \"2024-02-01\", \"2024-03-15\", \"2024-04-01\", \"2024-05-01\", \"2024-06-01\",\n        \"2024-07-01\", \"2024-08-01\", \"2024-09-01\", \"2024-09-15\", \"2024-10-01\",\n        \"2024-10-15\", \"2024-11-01\", \"2024-11-15\", \"2024-12-01\", \"2024-12-15\",\n        \"2025-01-02\", \"2025-01-05\", \"2025-01-08\", \"2025-01-10\", \"2025-01-12\"\n    ]),\n    \"salary\": (\n        [150000] * 4 + [120000] * 6 + [85000] * 4 +\n        [140000] * 2 + [95000] * 6 +\n        [90000] * 2 + [55000] * 5 +\n        [110000] * 2 + [70000] * 4\n    ),\n    \"status\": [\"active\"] * 33 + [\"on_leave\"] * 2\n})\n\nsource = DuckDBSource.from_df(tables={\n    \"customers\": customers_df,\n    \"subscriptions\": subscriptions_df,\n    \"employees\": employees_df\n})\n\nllm = OpenAI()\n\n\n# =============================================================================\n# CUSTOM ACTIONS\n# =============================================================================\n\nclass CustomerAcquisitionChart(Action):\n    \"\"\"Visualize customer acquisition trends by company size.\"\"\"\n\n    async def _execute(self, context, **kwargs):\n        src = context[\"source\"]\n\n        acquisition_src = src.create_sql_expr_source(tables={\n            \"acquisition\": \"\"\"\n                SELECT \n                    DATE_TRUNC('month', signup_date) AS month,\n                    company_size,\n                    COUNT(*) AS new_customers\n                FROM customers\n                WHERE status != 'churned'\n                GROUP BY month, company_size\n                ORDER BY month\n            \"\"\"\n        })\n\n        pipeline = Pipeline(source=acquisition_src, table=\"acquisition\")\n\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": \"bar\",\n                \"encoding\": {\n                    \"x\": {\"field\": \"month\", \"type\": \"temporal\", \"title\": \"Month\"},\n                    \"y\": {\"field\": \"new_customers\", \"type\": \"quantitative\", \n                          \"title\": \"New Customers\"},\n                    \"color\": {\n                        \"field\": \"company_size\", \n                        \"type\": \"nominal\", \n                        \"title\": \"Segment\",\n                        \"scale\": {\"scheme\": \"tableau10\"}\n                    }\n                },\n                \"width\": \"container\",\n                \"height\": 300\n            },\n            sizing_mode=\"stretch_width\",\n            height=350\n        )\n\n        return [LumenEditor(component=chart, title=\"Customer Acquisition by Segment\")], {}\n\n\nclass MRRDonutChart(Action):\n    \"\"\"Visualize MRR distribution by plan as a donut chart.\"\"\"\n\n    async def _execute(self, context, **kwargs):\n        src = context[\"source\"]\n\n        mrr_src = src.create_sql_expr_source(tables={\n            \"mrr_by_plan\": \"\"\"\n                SELECT \n                    s.plan_name,\n                    SUM(s.mrr) AS total_mrr,\n                    COUNT(*) AS subscriptions\n                FROM subscriptions s\n                JOIN customers c ON s.customer_id = c.customer_id\n                WHERE c.status = 'active' AND s.end_date IS NULL\n                GROUP BY s.plan_name\n            \"\"\"\n        })\n\n        pipeline = Pipeline(source=mrr_src, table=\"mrr_by_plan\")\n\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": {\"type\": \"arc\", \"innerRadius\": 60},\n                \"encoding\": {\n                    \"theta\": {\"field\": \"total_mrr\", \"type\": \"quantitative\"},\n                    \"color\": {\n                        \"field\": \"plan_name\", \n                        \"type\": \"nominal\", \n                        \"title\": \"Plan\",\n                        \"scale\": {\"scheme\": \"category10\"}\n                    },\n                    \"tooltip\": [\n                        {\"field\": \"plan_name\", \"title\": \"Plan\"},\n                        {\"field\": \"total_mrr\", \"title\": \"MRR\", \"format\": \"$,.0f\"},\n                        {\"field\": \"subscriptions\", \"title\": \"Count\"}\n                    ]\n                },\n                \"width\": 300,\n                \"height\": 300\n            },\n            height=350\n        )\n\n        return [LumenEditor(component=chart, title=\"MRR by Plan\")], {}\n\n\nclass HeadcountChart(Action):\n    \"\"\"Visualize headcount distribution by department.\"\"\"\n\n    async def _execute(self, context, **kwargs):\n        src = context[\"source\"]\n\n        dept_src = src.create_sql_expr_source(tables={\n            \"headcount\": \"\"\"\n                SELECT \n                    department,\n                    COUNT(*) AS headcount,\n                    ROUND(AVG(salary), 0) AS avg_salary\n                FROM employees\n                WHERE status = 'active'\n                GROUP BY department\n                ORDER BY headcount DESC\n            \"\"\"\n        })\n\n        pipeline = Pipeline(source=dept_src, table=\"headcount\")\n\n        chart = VegaLiteView(\n            pipeline=pipeline,\n            spec={\n                \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n                \"mark\": {\"type\": \"bar\", \"cornerRadiusEnd\": 4},\n                \"encoding\": {\n                    \"y\": {\"field\": \"department\", \"type\": \"nominal\", \n                          \"sort\": \"-x\", \"title\": \"Department\"},\n                    \"x\": {\"field\": \"headcount\", \"type\": \"quantitative\", \n                          \"title\": \"Employees\"},\n                    \"color\": {\n                        \"field\": \"department\", \n                        \"type\": \"nominal\", \n                        \"legend\": None,\n                        \"scale\": {\"scheme\": \"tableau10\"}\n                    },\n                    \"tooltip\": [\n                        {\"field\": \"department\", \"title\": \"Department\"},\n                        {\"field\": \"headcount\", \"title\": \"Headcount\"},\n                        {\"field\": \"avg_salary\", \"title\": \"Avg Salary\", \"format\": \"$,.0f\"}\n                    ]\n                },\n                \"width\": \"container\",\n                \"height\": 200\n            },\n            sizing_mode=\"stretch_width\",\n            height=250\n        )\n\n        return [LumenEditor(component=chart, title=\"Headcount by Department\")], {}\n\n\n# =============================================================================\n# SQL QUERIES\n# =============================================================================\n\ncustomer_by_region = SQLQuery(\n    source=source,\n    table=\"customers_by_region\",\n    sql_expr=\"\"\"\n        SELECT \n            region,\n            COUNT(*) AS total_customers,\n            SUM(CASE WHEN status = 'active' THEN 1 ELSE 0 END) AS active,\n            SUM(CASE WHEN status = 'churned' THEN 1 ELSE 0 END) AS churned,\n            ROUND(100.0 * SUM(CASE WHEN status = 'churned' THEN 1 ELSE 0 END) \n                  / COUNT(*), 1) AS churn_rate_pct\n        FROM customers\n        GROUP BY region\n        ORDER BY total_customers DESC\n    \"\"\",\n    title=\"Customers by Region\",\n    llm=llm\n)\n\ncustomer_by_industry = SQLQuery(\n    source=source,\n    table=\"customers_by_industry\",\n    sql_expr=\"\"\"\n        SELECT \n            industry,\n            company_size,\n            COUNT(*) AS customer_count\n        FROM customers\n        WHERE status = 'active'\n        GROUP BY industry, company_size\n        ORDER BY customer_count DESC\n    \"\"\",\n    title=\"Active Customers by Industry &amp; Size\",\n    llm=llm\n)\n\nrevenue_summary = SQLQuery(\n    source=source,\n    table=\"revenue_summary\",\n    sql_expr=\"\"\"\n        SELECT \n            SUM(s.mrr) AS total_mrr,\n            COUNT(DISTINCT s.customer_id) AS paying_customers,\n            ROUND(SUM(s.mrr) / COUNT(DISTINCT s.customer_id), 2) AS arpu,\n            SUM(CASE WHEN s.plan_name = 'enterprise' THEN s.mrr ELSE 0 END) \n                AS enterprise_mrr,\n            SUM(CASE WHEN s.plan_name = 'professional' THEN s.mrr ELSE 0 END) \n                AS professional_mrr,\n            SUM(CASE WHEN s.plan_name = 'starter' THEN s.mrr ELSE 0 END) \n                AS starter_mrr\n        FROM subscriptions s\n        JOIN customers c ON s.customer_id = c.customer_id\n        WHERE c.status = 'active' AND s.end_date IS NULL\n    \"\"\",\n    title=\"Revenue Summary\",\n    llm=llm\n)\n\ntop_customers = SQLQuery(\n    source=source,\n    table=\"top_customers\",\n    sql_expr=\"\"\"\n        SELECT \n            c.company_name,\n            c.industry,\n            s.plan_name,\n            s.mrr,\n            ROUND(100.0 * s.mrr / (SELECT SUM(mrr) FROM subscriptions \n                  WHERE end_date IS NULL), 2) AS pct_of_total\n        FROM customers c\n        JOIN subscriptions s ON c.customer_id = s.customer_id\n        WHERE c.status = 'active' AND s.end_date IS NULL\n        ORDER BY s.mrr DESC\n        LIMIT 10\n    \"\"\",\n    title=\"Top 10 Customers by MRR\",\n    llm=llm\n)\n\nemployee_summary = SQLQuery(\n    source=source,\n    table=\"employee_summary\",\n    sql_expr=\"\"\"\n        SELECT \n            COUNT(*) AS total_employees,\n            SUM(CASE WHEN status = 'active' THEN 1 ELSE 0 END) AS active,\n            SUM(CASE WHEN hire_date &gt;= CURRENT_DATE - INTERVAL '90 days' \n                THEN 1 ELSE 0 END) AS recent_hires,\n            ROUND(AVG(salary), 0) AS avg_salary,\n            ROUND(AVG(DATEDIFF('day', hire_date, CURRENT_DATE)), 0) \n                AS avg_tenure_days\n        FROM employees\n    \"\"\",\n    title=\"Workforce Summary\",\n    llm=llm\n)\n\ncompensation_by_role = SQLQuery(\n    source=source,\n    table=\"compensation\",\n    sql_expr=\"\"\"\n        SELECT \n            department,\n            role,\n            COUNT(*) AS count,\n            MIN(salary) AS min_salary,\n            ROUND(AVG(salary), 0) AS avg_salary,\n            MAX(salary) AS max_salary\n        FROM employees\n        WHERE status = 'active'\n        GROUP BY department, role\n        ORDER BY department, avg_salary DESC\n    \"\"\",\n    title=\"Compensation by Role\",\n    llm=llm\n)\n\n\n# =============================================================================\n# REPORT ASSEMBLY\n# =============================================================================\n\nreport = Report(\n    Section(\n        CustomerAcquisitionChart(title=\"Acquisition Trends\"),\n        customer_by_region,\n        customer_by_industry,\n        ActorTask(\n            ChatAgent(llm=llm),\n            title=\"Customer Insights\",\n            instruction=\"\"\"\n                Based on the customer data above, provide a brief analysis:\n                1. Key growth trends (2-3 points)\n                2. Regional performance highlights  \n                3. One actionable recommendation\n                Keep response under 150 words.\n            \"\"\"\n        ),\n        title=\"üìä Customer Analytics\"\n    ),\n    Section(\n        MRRDonutChart(title=\"MRR Distribution\"),\n        revenue_summary,\n        top_customers,\n        ActorTask(\n            ChatAgent(llm=llm),\n            title=\"Revenue Insights\",\n            instruction=\"\"\"\n                Analyze the subscription and revenue data to identify:\n                1. Revenue concentration observations\n                2. Plan mix analysis\n                3. Growth opportunities\n                Be specific with numbers. Keep under 150 words.\n            \"\"\"\n        ),\n        title=\"üí∞ Subscription &amp; Revenue\"\n    ),\n    Section(\n        HeadcountChart(title=\"Team Composition\"),\n        employee_summary,\n        compensation_by_role,\n        ActorTask(\n            ChatAgent(llm=llm),\n            title=\"Team Insights\",\n            instruction=\"\"\"\n                Based on the employee data, summarize:\n                1. Team structure observations\n                2. Hiring momentum\n                3. Compensation insights\n                Keep factual and under 150 words.\n            \"\"\"\n        ),\n        title=\"üë• Employee Analytics\"\n    ),\n    title=\"CloudSync Executive Dashboard\",\n    context={\"source\": source}\n)\n\n\nasync def main():\n    await report.execute()\n    report.show(port=5006)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())\n</code></pre>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/saas_company_report_dashboard/#next-steps","level":2,"title":"Next steps","text":"<p>Extend the dashboard by implementing cohort analysis, LTV calculations, or revenue forecasting. Add nested reports for drill-down analysis. Connect to your actual database using Sources configuration. Schedule execution and export to notebooks. Learn more about styling in Views configuration.</p>","path":["Examples","Tutorials","Building a SaaS Executive Dashboard"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/","level":1,"title":"Building a Weather Data AI Explorer","text":"<p>Build a domain-specific data exploration application using Lumen AI. This tutorial creates a weather data explorer that analyzes atmospheric soundings and displays Skew-T diagrams.</p>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#final-result","level":2,"title":"Final result","text":"<p>Time: 15-20 minutes</p>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#what-youll-build","level":2,"title":"What you'll build","text":"<p>A chat interface that understands meteorological concepts and generates specialized visualizations. The tutorial follows five steps:</p> <ol> <li>Create a custom analysis - Build <code>SkewTAnalysis</code> to render Skew-T diagrams</li> <li>Configure the data source - Set up DuckDB to load atmospheric sounding data</li> <li>Add domain expertise - Teach agents meteorological concepts through template overrides</li> <li>Build the interface - Create the UI with helpful suggestions</li> <li>Run and test - Launch the application and interact with it</li> </ol> <p>Each step introduces key Lumen AI concepts with links to detailed configuration guides.</p>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#prerequisites","level":2,"title":"Prerequisites","text":"<p>Install the required packages:</p> <pre><code>pip install lumen-ai metpy panel matplotlib\n</code></pre>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#1-create-a-custom-analysis","level":2,"title":"1. Create a custom analysis","text":"<p>Analyses allow developers to create deterministic flows for specialized visualizations. While agents handle data queries and interpretation, analyses ensure visualizations render correctly every time. Create <code>SkewTAnalysis</code> to generate Skew-T diagrams:</p> <p>Key concepts:</p> <ul> <li>Custom analyses extend Lumen AI by subclassing <code>lmai.analysis.Analysis</code> (see Analyses configuration)</li> <li>Required columns specify data requirements using the <code>columns</code> attribute</li> <li>Parameters make analyses configurable using Param</li> <li>Autorun determines if the analysis executes automatically when conditions are met</li> </ul> weather_sounding.py<pre><code>import param\nimport lumen.ai as lmai\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom metpy.plots import SkewT\nfrom metpy.units import units\nimport metpy.calc as mpcalc\n\nclass SkewTAnalysis(lmai.analysis.Analysis):\n    \"\"\"\n    Creates a Skew-T log-P diagram from upper air sounding data.\n    Shows temperature, dew point, and wind profiles.\n\n    To include wind barbs, also include speed_kts and drct columns.\n    \"\"\"\n\n    autorun = param.Boolean(default=True) # (1)!\n\n    barbs_interval = param.Integer(\n        default=3, \n        doc=\"Interval for plotting wind barbs to avoid crowding\"\n    )\n\n    columns = [\"validUTC\", \"pressure_mb\", \"tmpc\", \"dwpc\"] # (2)!\n</code></pre> <ol> <li><code>autorun=True</code> runs this analysis automatically when the required columns are present</li> <li>The <code>columns</code> attribute tells Lumen AI which data columns this analysis needs</li> </ol>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#implement-the-visualization","level":3,"title":"Implement the visualization","text":"<p>The <code>__call__</code> method contains the core visualization logic:</p> weather_sounding.py<pre><code>    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data.copy()\n        df[\"validUTC\"] = pd.to_datetime(df[\"validUTC\"])\n        latest_time = df[\"validUTC\"].max()\n        sounding = df[df[\"validUTC\"] == latest_time].copy() # (1)!\n\n        # Extract variables with units\n        pressure = sounding[\"pressure_mb\"].values * units.hPa # (2)!\n        temperature = sounding[\"tmpc\"].values * units.degC\n        dewpoint = sounding[\"dwpc\"].values * units.degC\n\n        # Create Skew-T plot\n        fig = plt.figure(figsize=(7, 7))\n        skew = SkewT(fig, rotation=45) # (3)!\n        skew.plot_dry_adiabats(alpha=0.25, color=\"orangered\")\n        skew.plot_moist_adiabats(alpha=0.25, color=\"tab:green\")\n        skew.plot_mixing_lines(alpha=0.25, color=\"tab:blue\")\n        skew.plot(pressure, temperature, \"r\", linewidth=2, label=\"Temperature\")\n        skew.plot(pressure, dewpoint, \"g\", linewidth=2, label=\"Dew Point\")\n\n        # Add wind barbs if available\n        if \"drct\" in sounding.columns and \"speed_kts\" in sounding.columns:\n            wind_data = sounding[[\"speed_kts\", \"drct\"]].apply(pd.to_numeric, errors=\"coerce\")\n            wind_speed = wind_data[\"speed_kts\"].values * units.knots\n            wind_direction = wind_data[\"drct\"].values * units.degrees\n            u_wind, v_wind = mpcalc.wind_components(wind_speed, wind_direction)\n            skew.plot_barbs(\n                pressure[:: self.barbs_interval], \n                u_wind[:: self.barbs_interval], \n                v_wind[:: self.barbs_interval]\n            )\n\n        time_str = latest_time.strftime(\"%Y-%m-%d %H:%M UTC\")\n        plt.title(\n            f\"Atmospheric Sounding - Oakland, CA\\n{time_str}\", \n            fontsize=14, \n            fontweight=\"bold\"\n        )\n        return pn.pane.Matplotlib(fig, sizing_mode=\"stretch_both\") # (4)!\n</code></pre> <ol> <li>Filter to the most recent sounding</li> <li>MetPy requires units for meteorological calculations</li> <li>Skew-T uses a 45¬∞ rotation coordinate system</li> <li>Return a Panel pane for the Lumen UI</li> </ol>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#2-configure-the-data-source","level":2,"title":"2. Configure the data source","text":"<p>Set up DuckDB to load weather data from GitHub:</p> weather_sounding.py<pre><code>from lumen.sources.duckdb import DuckDBSource\n\nsource = DuckDBSource(\n    uri=\":memory:\",\n    tables={\n        \"raob_soundings\": \"\"\"\n            SELECT * FROM read_csv_auto(\n                'https://raw.githubusercontent.com/holoviz/lumen/main/examples/raob.csv'\n            )\n        \"\"\",\n    },\n)\n</code></pre> <p>Data comes from the Iowa Environmental Mesonet with atmospheric measurements at different pressure levels.</p>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#3-add-domain-expertise-to-agents","level":2,"title":"3. Add domain expertise to agents","text":"<p>Template overrides inject domain knowledge into agent system prompts. This customizes how agents understand and respond to domain-specific queries.</p> <p>Key concepts:</p> <ul> <li>Template overrides inject specialized knowledge using the <code>template_overrides</code> attribute (see Agents configuration)</li> <li>Global context shares knowledge across all agents by setting overrides on the <code>Actor</code> base class</li> <li>Agent-specific overrides customize individual agent types like <code>ChatAgent</code></li> <li>Jinja2 templates use <code>{{ super() }}</code> to preserve original content while adding customizations</li> <li>Automatic column requirements ‚Äî the <code>columns</code> attribute on Analysis classes automatically informs upstream agents about required columns</li> </ul>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#share-meteorological-knowledge-globally","level":3,"title":"Share meteorological knowledge globally","text":"<p>Template overrides inject domain-specific knowledge into agents' system prompts. This teaches all agents about inversion analysis without requiring users to explain it in every query.</p> weather_sounding.py<pre><code>global_context = \"\"\"\n{{ super() }} # (1)!\n\nTo perform inversion analysis, extract temperatures at different pressure levels and\ncomplete a difference calculation. Then use ChatAgent to determine if the temperature \nincreases with decreasing pressure in a layer, which indicates an inversion.\n\"\"\"\nlmai.actor.Actor.template_overrides = {\"main\": {\"global\": global_context}} # (2)!\n</code></pre> <ol> <li><code>{{ super() }}</code> preserves the original template</li> <li>Apply to <code>Actor</code> base class to affect all agents</li> </ol>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#make-the-chat-agent-speak-like-a-meteorologist","level":3,"title":"Make the chat agent speak like a meteorologist","text":"<p>Specialized instructions make the chat agent use proper meteorological terminology and explain concepts accurately, creating a more professional domain-specific assistant.</p> weather_sounding.py<pre><code>chat_instructions = \"\"\"\n{{ super() }}\n\nYou are a meteorologist. Use proper meteorological terminology and explain \natmospheric concepts clearly.\n\"\"\"\nlmai.agents.ChatAgent.template_overrides = {\n    \"main\": {\"instructions\": chat_instructions}\n}\n</code></pre> <p>Automatic column requirements</p> <p>The <code>columns</code> attribute on <code>SkewTAnalysis</code> (e.g., <code>[\"validUTC\", \"pressure_mb\", \"tmpc\", \"dwpc\"]</code>) automatically tells upstream agents which columns are needed. For optional columns like <code>speed_kts</code> and <code>drct</code> (used for wind barbs), mention them in the docstring so agents know to include them when relevant.</p>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#4-build-the-interface","level":2,"title":"4. Build the interface","text":"<p>Create the explorer with suggestions:</p> weather_sounding.py<pre><code>import panel as pn\n\npn.extension()\n\nui = lmai.ExplorerUI(\n    data=source,\n    analyses=[SkewTAnalysis],\n    title=\"Weather Data Explorer\",\n    suggestions=[\n        (\"question_answer\", \"What is a Skew-T diagram?\"),\n        (\"vertical_align_top\", \"Generate a Skew-T diagram.\"),\n        (\"question_mark\", \"Is there an inversion layer today?\"),\n        (\"search\", \"What's the surface temperature?\"),\n    ],\n    log_level=\"DEBUG\",\n)\n\nui.servable()\n</code></pre>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#5-run-the-application","level":2,"title":"5. Run the application","text":"<p>Start the server:</p> <pre><code>panel serve weather_sounding.py --show\n</code></pre> <p>Your browser opens to the weather explorer. Try these interactions:</p> <ul> <li>\"What is a Skew-T diagram?\" - Get an explanation</li> <li>\"Generate a Skew-T diagram.\" - See the visualization</li> <li>\"Is there an inversion layer today?\" - Perform analysis</li> <li>\"What's the surface temperature?\" - Query the data</li> </ul>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#complete-code","level":2,"title":"Complete code","text":"weather_sounding.py<pre><code>\"\"\"\nWeather Data Explorer with Atmospheric Soundings\n\"\"\"\n\nimport param\nimport lumen.ai as lmai\nfrom lumen.sources.duckdb import DuckDBSource\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport panel as pn\nfrom metpy.plots import SkewT\nfrom metpy.units import units\nimport metpy.calc as mpcalc\n\npn.extension()\nmpl.use(\"agg\")\n\n\nclass SkewTAnalysis(lmai.analysis.Analysis):\n    \"\"\"\n    Creates a Skew-T log-P diagram from upper air sounding data.\n    Shows temperature, dew point, and wind profiles.\n\n    To include wind barbs, also include `speed_kts` and `drct` columns.\n    \"\"\"\n\n    autorun = param.Boolean(default=True)\n    barbs_interval = param.Integer(default=3, doc=\"Interval for plotting wind barbs to avoid crowding\")\n    columns = [\"validUTC\", \"pressure_mb\", \"tmpc\", \"dwpc\"]\n\n    def __call__(self, pipeline, *args, **kwargs):\n        df = pipeline.data.copy()\n        df[\"validUTC\"] = pd.to_datetime(df[\"validUTC\"])\n        latest_time = df[\"validUTC\"].max()\n        sounding = df[df[\"validUTC\"] == latest_time].copy()\n\n        pressure = sounding[\"pressure_mb\"].values * units.hPa\n        temperature = sounding[\"tmpc\"].values * units.degC\n        dewpoint = sounding[\"dwpc\"].values * units.degC\n\n        fig = plt.figure(figsize=(7, 7))\n        skew = SkewT(fig, rotation=45)\n        skew.plot_dry_adiabats(alpha=0.25, color=\"orangered\")\n        skew.plot_moist_adiabats(alpha=0.25, color=\"tab:green\")\n        skew.plot_mixing_lines(alpha=0.25, color=\"tab:blue\")\n        skew.plot(pressure, temperature, \"r\", linewidth=2, label=\"Temperature\")\n        skew.plot(pressure, dewpoint, \"g\", linewidth=2, label=\"Dew Point\")\n\n        if \"drct\" in sounding.columns and \"speed_kts\" in sounding.columns:\n            wind_data = sounding[[\"speed_kts\", \"drct\"]].apply(pd.to_numeric, errors=\"coerce\")\n            wind_speed = wind_data[\"speed_kts\"].values * units.knots\n            wind_direction = wind_data[\"drct\"].values * units.degrees\n            u_wind, v_wind = mpcalc.wind_components(wind_speed, wind_direction)\n            skew.plot_barbs(pressure[:: self.barbs_interval], u_wind[:: self.barbs_interval], v_wind[:: self.barbs_interval])\n\n        time_str = latest_time.strftime(\"%Y-%m-%d %H:%M UTC\")\n        plt.title(f\"Atmospheric Sounding - Oakland, CA\\n{time_str}\", fontsize=14, fontweight=\"bold\")\n        return pn.pane.Matplotlib(fig, sizing_mode=\"stretch_both\")\n\n\nsource = DuckDBSource(\n    uri=\":memory:\",\n    tables={\n        \"raob_soundings\": \"\"\"\n            SELECT * FROM read_csv_auto(\n                'https://mesonet.agron.iastate.edu/cgi-bin/request/raob.py?station=KILX&amp;sts=2026-01-25T09%3A56&amp;ets=2026-01-26T09%3A56'\n            )\n        \"\"\",\n    },\n)\n\nglobal_context = \"\"\"\n{{ super() }}\n\nTo perform inversion analysis, extract temperatures at different pressure levels and\ncomplete a difference calculation. Then use ChatAgent to determine if the temperature increases with decreasing pressure in a layer,\nwhich indicates an inversion.\n\"\"\"\nlmai.actor.Actor.template_overrides = {\"main\": {\"global\": global_context}}\n\nchat_instructions = \"\"\"\n{{ super() }}\n\nYou are a meteorologist. Use proper meteorological terminology and explain atmospheric concepts clearly.\n\"\"\"\nlmai.agents.ChatAgent.template_overrides = {\"main\": {\"instructions\": chat_instructions}}\n\nui = lmai.ExplorerUI(\n    data=source,\n    analyses=[SkewTAnalysis],\n    title=\"Weather Data Explorer\",\n    suggestions=[\n        (\"question_answer\", \"What is a Skew-T diagram?\"),\n        (\"vertical_align_top\", \"Generate a Skew-T diagram.\"),\n        (\"question_mark\", \"Is there an inversion layer today?\"),\n        (\"search\", \"What's the surface temperature?\"),\n    ],\n    log_level=\"DEBUG\",\n)\n\nui.servable()\n</code></pre>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#run-the-application","level":2,"title":"Run the application","text":"<p>Start the server:</p> <pre><code>panel serve weather_sounding.py --show\n</code></pre> <p>Your browser opens to the weather explorer. Try these interactions:</p> <ul> <li>\"What is a Skew-T diagram?\" - Get an explanation</li> <li>\"Generate a Skew-T diagram.\" - See the visualization</li> <li>\"Is there an inversion layer today?\" - Perform analysis</li> <li>\"What's the surface temperature?\" - Query the data</li> </ul>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"examples/tutorials/weather_data_ai_explorer/#next-steps","level":2,"title":"Next steps","text":"<p>Extend this example:</p> <ul> <li>Add calculations: Implement CAPE, CIN, or lifted index (see custom analyses)</li> <li>Create diagrams: Build hodographs or time-height sections</li> <li>Integrate forecasts: Combine observations with model predictions using multiple data sources</li> <li>Add validation: Include quality control for meteorological data</li> <li>Customize agents: Learn more about agent configuration and prompts</li> </ul>","path":["Examples","Tutorials","Building a Weather Data AI Explorer"],"tags":[]},{"location":"getting_started/launching_lumen/","level":1,"title":"Launching Lumen","text":"<p>Start Lumen AI from the command line or Python. Choose the method that fits your workflow.</p> <p>Before launching</p> <p>Make sure you've installed Lumen and configured an LLM provider. See the Installation guide.</p>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#launch-from-the-command-line","level":2,"title":"Launch from the command line","text":"<p>The simplest way to start is with a single command:</p> <pre><code>lumen-ai serve\n</code></pre> <p>This opens the chat interface at <code>localhost:5006</code>.</p>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#pre-load-a-dataset","level":3,"title":"Pre-load a dataset","text":"<p>Start with data already loaded:</p> Single file<pre><code>lumen-ai serve penguins.csv\n</code></pre> From URL<pre><code>lumen-ai serve https://datasets.holoviz.org/penguins/v1/penguins.csv\n</code></pre> Multiple files<pre><code>lumen-ai serve penguins.csv orders.parquet\n</code></pre> Using wildcards<pre><code>lumen-ai serve data/*.csv\n</code></pre>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#configure-the-llm","level":3,"title":"Configure the LLM","text":"<p>Configure the LLM at startup using CLI flags:</p> Specify provider<pre><code>lumen-ai serve --provider openai\n</code></pre> Specify model<pre><code>lumen-ai serve --model-kwargs '{\"default\": {\"model\": \"gpt-4o\"}}'\n</code></pre> Adjust temperature<pre><code>lumen-ai serve --temperature 0.5  # (1)!\n</code></pre> <ol> <li>Controls randomness; higher = more creative (0.0-2.0)</li> </ol> Combine options<pre><code>lumen-ai serve penguins.csv \\\n  --provider openai \\\n  --model-kwargs '{\"default\": {\"model\": \"gpt-4o\"}}' \\\n  --temperature 0.7\n</code></pre> <p>For a complete list of CLI options:</p> <pre><code>lumen-ai serve --help\n</code></pre>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#launch-from-python","level":2,"title":"Launch from Python","text":"<p>For more control, use the Python API:</p> Minimal Python app<pre><code>import lumen.ai as lmai\n\nui = lmai.ExplorerUI()\nui.servable()\n</code></pre> <p>Save as <code>app.py</code>, then launch:</p> <pre><code>panel serve app.py\n</code></pre>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#pre-load-data","level":3,"title":"Pre-load data","text":"Load data in Python<pre><code>import lumen.ai as lmai\n\nui = lmai.ExplorerUI(data='penguins.csv')\nui.servable()\n</code></pre>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#configure-the-llm_1","level":3,"title":"Configure the LLM","text":"Configure LLM in Python<pre><code>import lumen.ai as lmai\n\n# Configure your LLM\nllm = lmai.llm.OpenAI(\n    model_kwargs={\n        'default': {'model': 'gpt-4o-mini'},\n        'sql': {'model': 'gpt-4o'}\n    },\n    temperature=0.7\n)\n\nui = lmai.ExplorerUI(data='penguins.csv', llm=llm)\nui.servable()\n</code></pre> <p>See LLM Providers for advanced LLM configuration.</p>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#add-custom-components","level":3,"title":"Add custom components","text":"Custom agents and analyses<pre><code>import lumen.ai as lmai\nfrom lumen.ai.agents import AnalysisAgent\n\n# Create custom analysis\nanalysis_agent = AnalysisAgent(analyses=[MyAnalysis])\n\nui = lmai.ExplorerUI(\n    data='penguins.csv',\n    agents=[analysis_agent, MyCustomAgent()],\n    tools=[my_custom_tool],\n    suggestions=[\n        (\"search\", \"What data is available?\"),\n        (\"bar_chart\", \"Show me a visualization\"),\n    ]\n)\nui.servable()\n</code></pre>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#common-cli-flags","level":2,"title":"Common CLI flags","text":"Flag Purpose Example <code>--provider</code> Specify LLM provider <code>--provider anthropic</code> <code>--model-kwargs</code> Configure models <code>--model-kwargs '{\"default\": {\"model\": \"claude-sonnet-4-5\"}}'</code> <code>--temperature</code> Control randomness <code>--temperature 0.5</code> <code>--port</code> Custom port <code>--port 8080</code> <code>--address</code> Network address <code>--address 0.0.0.0</code> <code>--show</code> Auto-open browser <code>--show</code> <code>--log-level</code> Debug verbosity <code>--log-level DEBUG</code>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/launching_lumen/#next-steps","level":2,"title":"Next steps","text":"<ul> <li>Navigating the UI ‚Äî Learn how to use the interface</li> <li>Using Lumen AI ‚Äî Start asking questions and exploring data</li> <li>LLM Providers ‚Äî Configure your LLM provider and models</li> </ul>","path":["Getting Started","Launching Lumen"],"tags":[]},{"location":"getting_started/navigating_the_ui/","level":1,"title":"Navigating the Lumen UI","text":"<p>Lumen Explorer combines data exploration and AI-powered analysis in one split-screen interface. This guide shows you where everything is and how to use it.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#get-started","level":2,"title":"Get started","text":"","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#the-splash-screen","level":3,"title":"The splash screen","text":"<p>When you open Lumen Explorer, you'll see two main tabs to get started:</p> <p></p> <p>Chat with data ‚Äî Ask questions about your data in plain English. The AI will generate queries and visualizations automatically.</p> <p>Select data to explore ‚Äî Pick a specific table from your connected sources and start an exploration.</p> <p>Quick action suggestions ‚Äî Below the chat input, you'll see helpful starter prompts like \"What data is available?\", \"Show me a dataset\", \"Visualize the data\", and \"Show a demo\". Click any of these to get started quickly.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#the-chat-panel","level":3,"title":"The chat panel","text":"<p>The chat interface is where you interact with Lumen AI. The input area provides several built-in actions:</p> <p></p> <p>Undo ‚Äî Remove the last message and its response.</p> <p>Rerun ‚Äî Re-execute the last query to regenerate results.</p> <p>Clear ‚Äî Delete all messages and start fresh.</p> <p>Upload files ‚Äî Attach files directly to add new data sources or provide context.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#the-navigation-menu","level":3,"title":"The navigation menu","text":"<p>The left sidebar provides quick access to all major features:</p> <p></p> <p>Explore ‚Äî Main chat and analysis mode (default view)</p> <p>Report ‚Äî Consolidated view of all explorations</p> <p>Sources ‚Äî Manage data connections</p> <p>Settings ‚Äî Configure LLM and analysis options</p> <p>Navigate ‚Äî View and jump between explorations</p> <p>Help ‚Äî Access interface documentation</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#adding-data-sources","level":3,"title":"Adding data sources","text":"<p>Click Sources from the left sidebar to manage your data:</p> <p></p> <p>Upload data ‚Äî Drag and drop files or click Browse. Supports CSV, Parquet, JSON, Excel, and more.</p> <p>Fetch remote data ‚Äî Enter URLs (one per line) and press Shift+Enter to download files from the web.</p> <p>Classify files ‚Äî Choose data (queryable tables) or metadata (documentation for the AI)</p> <p>Control visibility ‚Äî Toggle tables on/off to control what the AI can access. Apply metadata to specific tables or all tables at once.</p> <p>All connections persist within your current session across multiple explorations.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#the-results-screen","level":2,"title":"The results screen","text":"<p>Once you start analyzing, the results screen displays your outputs:</p> <p></p> <p>Exploration sidebar ‚Äî On the left, navigate between different explorations and follow-ups.</p> <p>Result tabs ‚Äî On the right, switch between different analysis outputs (data tables, visualizations, etc.) Use the Data Source tab to explore the original data with Graphic Walker.</p> <p>Code editor ‚Äî Review and modify SQL queries or visualization specs, which will update views in real-time.</p> <p>Interactive views ‚Äî View data tables with sorting, filtering, and pagination. Visualizations support tooltips.</p> <p>Export options ‚Äî Download tables as CSV or Excel files or download visualizations as PNG, PDF, etc.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#understanding-explorations","level":3,"title":"Understanding explorations","text":"<p>Each SQL query that returns data creates a new exploration ‚Äî a persistent workspace for that analysis:</p> <p>Top-level explorations ‚Äî New independent questions start here</p> <p>Nested explorations ‚Äî Follow-up questions appear under their parent</p> <p>Exploration tree ‚Äî Navigate between explorations in the left panel</p> <p>Persistent context ‚Äî Each exploration captures the conversation, queries, and visualizations</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#revising-and-refining","level":3,"title":"Revising and refining","text":"<p>When you need to adjust your analysis, Lumen provides tools to refine and iterate on your results without starting from scratch.</p> <p></p> <p>For plots, there are also annotation controls that allow you to highlight key insights directly on the visualization.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#settings-and-control-options","level":3,"title":"Settings and control options","text":"<p>Use Settings in the left sidebar to configure analysis behavior:</p> <p>Chain of Thought ‚Äî Shows reasoning steps (disabled by default)</p> <p>SQL Planning ‚Äî AI plans queries before executing (disabled by default)</p> <p>Validation Step ‚Äî AI validates results for correctness (enabled by default)</p> <p>Code Execution ‚Äî If enabled by administrator, controls how visualizations are generated. See Code Execution for Visualizations for security implications.</p> <p>LLM Configuration ‚Äî Choose and configure your language model</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#exporting-and-sharing","level":2,"title":"Exporting and sharing","text":"","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#export-tables-and-visualizations","level":3,"title":"Export tables and visualizations","text":"<p>Above every code editor, you'll find export options:</p> <p></p> <ul> <li> <p>Export Table ‚Äî Download data tables as CSV or Excel files.</p> </li> <li> <p>Export Visualization ‚Äî Save visualizations as PNG, PDF, SVG, etc.</p> </li> </ul>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#export-to-jupyter-notebooks","level":3,"title":"Export to Jupyter notebooks","text":"<p>Export explorations as a Jupyter notebook under the exploration sidebar.</p> <p></p> <p>Exported notebooks include all questions, SQL queries, and visualizations, ready to run or share.</p> <p></p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#report-mode","level":3,"title":"Report mode","text":"<p>In Report Mode, export everything as one comprehensive notebook under the Report sidebar.</p> <p>Switch to Report mode from the left sidebar to see all your explorations in a consolidated view. This provides an overview of all your analysis work in one place.</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/navigating_the_ui/#next-steps","level":2,"title":"Next steps","text":"<p>Once you're comfortable with the interface, try the quick action buttons on the splash screen. Then move on to asking more complex questions ‚Äî the AI handles the SQL while you focus on insights.</p> <p>Next: Using Lumen AI ‚Üí</p>","path":["Getting Started","Navigating the Lumen UI"],"tags":[]},{"location":"getting_started/using_lumen_ai/","level":1,"title":"Using Lumen AI","text":"<p>Once you're set up and exploring, here's how to get the most out of Lumen AI.</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#message-examples","level":2,"title":"Message examples","text":"<p>Here are some ideas to spark your exploration:</p> <p>Basic queries:</p> <ul> <li>\"What datasets are available?\"</li> <li>\"Give me a summary of the dataset.\"</li> <li>\"What are the columns in the dataset?\"</li> <li>\"What is the distribution of the 'species' column?\"</li> </ul> <p>Visualizations:</p> <ul> <li>\"Show me a scatter plot of 'flipper_length_mm' vs 'body_mass_g'.\"</li> <li>\"Create a histogram of 'bill_length_mm'.\"</li> <li>\"Show me a bar chart of average values by species.\"</li> </ul> <p>Complex queries:</p> <ul> <li>\"Group by 'species' and show me the average 'flipper_length_mm'. Then plot a bar chart of the result.\"</li> <li>\"Filter the dataset for species 'Chinstrap' and calculate the median 'body_mass_g'. Then display and discuss the result.\"</li> <li>\"Create a histogram of 'bill_length_mm' and a box plot of 'flipper_length_mm' side by side.\"</li> <li>\"Add a new column calculating the ratio of 'flipper_length_mm' to 'body_mass_g'. Then plot a scatter plot of this ratio against 'bill_length_mm'.\"</li> <li>\"Select records where 'body_mass_g' is greater than 3500 and 'flipper_length_mm' is less than 200. Then provide summary statistics for these filtered records.\"</li> </ul> <p>Get inspired:</p> <ul> <li>\"What could be interesting to explore?\"</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#combine-multiple-requests","level":2,"title":"Combine multiple requests","text":"<p>You can ask the AI to perform several steps in one message. This helps you build complex analyses without multiple back-and-forths. For example: \"Filter the data, create a visualization, then summarize the findings.\"</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#choose-your-model","level":2,"title":"Choose your model","text":"<p>The model Lumen AI uses affects both quality and cost. By default, Lumen uses OpenAI's <code>gpt-4.1-mini</code>, but you can choose any supported model from OpenAI, Anthropic, Google, Mistral, or local providers.</p> <p>Configure from Settings: - Click Settings (left sidebar) to select a different provider and model</p> <p>For guidance on model selection: - See LLM Providers for detailed information on model choices, cost optimization, and task-specific recommendations - Use cheaper models like <code>gpt-4.1-mini</code> or <code>claude-haiku-4-5</code> for general tasks - Reserve more powerful models like <code>gpt-4.1</code> or <code>claude-sonnet-4-5</code> for SQL generation and complex analysis</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#understand-the-ais-reasoning","level":2,"title":"Understand the AI's reasoning","text":"<p>If you want to see how the AI arrived at an answer, enable Chain of Thought in Settings (left sidebar). This will show the LLM's reasoning steps in expandable cards within the chat.</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#refine-results","level":2,"title":"Refine results","text":"<p>If results aren't what you expected, you have several options:</p> <p>Rerun the query ‚Äî Click the Rerun button to re-execute the last query. This is useful if there was a temporary error or if you want to see if the AI produces different results.</p> <p>Continue the conversation ‚Äî Send a new message to refine or adjust the results. For example: \"Can you make that chart show only the top 5 items?\" or \"Add a trend line to the visualization.\"</p> <p>Add annotations ‚Äî For visualizations, click the annotation button (üí¨ icon) to add highlights, callouts, or labels. For example: \"Highlight the peak values\" or \"Mark outliers in red.\"</p> <p>Manually edit ‚Äî Directly edit the SQL query or visualization specification in the editor panel. This works if you're comfortable with SQL or need precise control over the output.</p> <p>Use manual editing for small tweaks (like changing chart colors or sort order), and send a new message for bigger changes to the underlying query or analysis approach.</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#explorations","level":2,"title":"Explorations","text":"<p>An Exploration is a persistent, contextual workspace for working with a specific dataset. It is created when a SQL query is first generated and captures the full interaction state, including the conversation, analyses, visualizations, and other data artifacts. An Exploration evolves over time, supports multiple questions and operations on the same data, and can be revisited or exported as a coherent unit.M</p> <p>Explorations start from the global context (available sources and metadata). If a question is a follow-up, the new exploration is nested under the parent; if it is not, Lumen creates a new top-level exploration.</p> <p>Use the navigation menu to move between explorations or nest follow-ups under the exploration they build on.</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#report-mode","level":2,"title":"Report mode","text":"<p>Report mode shows all your analyses on one page. Switch to Report mode from the left sidebar to see your explorations organized into a structured report with collapsible sections.</p> <p>What you can do:</p> <ul> <li>Review everything ‚Äî Scroll through all analyses in one place</li> <li>Edit prompts ‚Äî Click any task to modify its instructions and rerun</li> <li>Customize agents ‚Äî Edit underlying agent prompts to change behavior</li> <li>Export all ‚Äî Download everything as a single Jupyter notebook</li> </ul> <p>Under the hood: Report mode uses Lumen's <code>Report</code> framework. Each exploration becomes a <code>Section</code> containing <code>ActorTask</code> objects. The same classes power both the UI and code-based reports. See the Reports configuration guide for complete documentation.</p> <p>Planned Feature: Report Templates</p> <p>We're working on the ability to export your report structure as a reusable YAML configuration file. This will let you:</p> <ul> <li>Build a skeleton through exploration: Ask questions naturally, and the system captures the underlying report structure (which agents, what order, what prompts).</li> <li>Create templated reports: Export a \"Q3 Customer Analysis\" report, then next quarter reload it, change \"Q3\" to \"Q4\", and run‚Äîno re-prompting needed.</li> <li>Share report structures: Export a config, share with colleagues, and they get the exact same report framework against their own data.</li> <li>Iterate without re-discovery: Tweak the config (reorder sections, adjust prompts, swap one analysis for another) without starting from scratch.</li> </ul> <p>The LLM does the hard work once during exploration, then gets out of the way for repeated execution.</p> <p>Build reports programmatically:</p> <p>The Report framework can also be used directly in Python to create reusable analytical workflows:</p> <pre><code>from lumen.ai.report import Action, Report, Section\n\nclass MyAnalysis(Action):\n    async def _execute(self, context, **kwargs):\n        # Your analysis here\n        return [output], {'result': value}\n\nreport = Report(\n    Section(MyAnalysis(title=\"Analysis\"), title=\"Section\"),\n    title=\"My Report\"\n)\nawait report.execute()\n</code></pre>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#export-results","level":2,"title":"Export results","text":"<p>Export your session as a Jupyter notebook so you can reproduce, share, or build on your work.</p> <p>Export current exploration: Use Export Notebook in the navigation menu to download a notebook containing the current exploration's questions, queries, and visualizations.</p> <p>Export all explorations: Switch to Report mode (via the left sidebar), then use Export Notebook to download everything as a single notebook.</p> <p>The notebook includes:</p> <ul> <li>Markdown cells with your questions and AI responses</li> <li>Code cells with SQL queries and Lumen specifications</li> <li>Visualizations as executable code</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#advanced-options","level":2,"title":"Advanced options","text":"","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#code-excecution","level":3,"title":"Code Excecution","text":"<p>By default, Lumen AI avoids generating and running Python code and instead relies on generating declarative specifications. This means there is no concern about arbitrary code execution, e.g. to exfiltrate secrets or perform destructive operations. For example visualizations are generated using declarative Vega-Lite YAML specifications, which are safe because no code is executed‚Äîthe spec is simply validated and rendered by the Vega library.</p> <p>Lumen does support code generation capabilities, which are often useful (and faster), particularly when working locally, where there is much less concern about malicious use. As an example the <code>VegaLiteAgent</code> can optionally generate and execute Python code using Altair. This enables more sophisticated charts and faster plotting but introduces significant security considerations.</p> <p>Security Warning: Code Execution is Not Safe</p> <p>Code execution must NEVER be enabled in production environments with access to secrets, credentials, or sensitive data.</p> <p>When code execution is enabled, LLM-generated Python code runs in-process with access to your system. This approach cannot be made secure against adversarial prompt injection attacks.</p> <p>Even with AST validation, blacklist-based security fails because injected libraries (like Altair) have full access to Python's internals through their object graphs. An attacker can craft prompts that generate seemingly innocent code which traverses through library internals to access sensitive data like API keys.</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#code-execution-modes","level":4,"title":"Code execution modes","text":"<p>Code execution is controlled via the <code>code_execution</code> parameter on all <code>BaseCodeAgent</code> types (e.g. the <code>VegaLiteAgent</code>). This should generally be configured at the <code>ExplorerUI</code> level and supports a number of modes:</p> Mode Description Security <code>hidden</code> Disabled and not configurable in the UI ‚úÖ Safe <code>disabled</code> Generate only YAML specs (default) ‚ö†Ô∏è User can escalate permissions <code>prompt</code> Ask user for permission before executing code ‚ö†Ô∏è User must review <code>llm</code> LLM validates code before execution ‚ö†Ô∏è Reduces accidental errors only <code>allow</code> Execute all generated code without confirmation ‚ùå Potentially Dangerous even when used locally","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#what-the-safety-measures-provide","level":4,"title":"What the safety measures provide","text":"<p>The AST validation and LLM review in <code>prompt</code> and <code>llm</code> modes:</p> <ul> <li>‚úÖ Catch accidental dangerous patterns (typos, mistakes)</li> <li>‚úÖ Block obvious attack vectors (<code>import os</code>, <code>exec()</code>, etc.)</li> <li>‚úÖ Reduce footgun risk for legitimate users</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#what-they-cannot-provide","level":4,"title":"What they cannot provide","text":"<ul> <li>‚ùå Protection against adversarial prompt injection</li> <li>‚ùå Blocking of object graph traversal through libraries</li> <li>‚ùå Prevention of data exfiltration via output channels (like chart titles)</li> <li>‚ùå A true security boundary</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#safe-vs-unsafe-usage","level":4,"title":"Safe vs unsafe usage","text":"<p>Safe usage:</p> <ul> <li>Local development/exploration with your own prompts</li> <li>Demo environments without production secrets</li> <li>Trusted internal tools where users are authenticated and fully trusted</li> </ul> <p>Unsafe usage:</p> <ul> <li>Production deployments with untrusted users</li> <li>Any environment with secrets in environment variables</li> <li>Public-facing applications</li> <li>Scenarios where prompt injection is possible</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#configuration","level":4,"title":"Configuration","text":"<p>Via the UI: If enabled by the administrator, code execution mode can be selected in Settings ‚Üí Code Execution. A warning dialog will appear when enabling any mode other than <code>disabled</code>.</p> <p>Via Python:</p> <pre><code>import lumen.ai as lmai\n\n# Show code execution option in UI, default to prompting user\nui = lmai.ExplorerUI(\n    data='data.csv',\n    code_execution='prompt'  # Options: 'hidden', 'disabled', 'prompt', 'llm', 'allow'\n)\n</code></pre> <p>Via CLI:</p> <pre><code>lumen-ai serve data.csv --code-execution prompt\n</code></pre> <p>The <code>hidden</code> option (default) completely hides the code execution selector from the UI, ensuring Lumen only generates specifications.</p> <p>Recommendation</p> <p>For most use cases, the default Vega-Lite generation (<code>disabled</code> mode) provides excellent visualization capabilities without any security risk. Only enable code execution when you need Altair-specific features and understand the security implications.</p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#command-line-configuration","level":3,"title":"Command-line configuration","text":"<p>Pass additional options when launching Lumen AI:</p> Specify agents<pre><code>lumen-ai serve data.csv --agents SQLAgent VegaLiteAgent ChatAgent\n</code></pre> Configure temperature<pre><code>lumen-ai serve data.csv --temperature 0.8\n</code></pre> Use specific provider<pre><code>lumen-ai serve data.csv --provider anthropic --api-key sk-...\n</code></pre> <p>Run <code>lumen-ai serve --help</code> to see all available options.</p> <p>Agent names are flexible</p> <p>Agent names are case-insensitive and the \"Agent\" suffix is optional: <code>SQLAgent</code> = <code>sqlagent</code> = <code>sql</code></p>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#python-api-configuration","level":3,"title":"Python API configuration","text":"<p>For fine-grained control, use the Python API:</p> Advanced Python configuration<pre><code>import lumen.ai as lmai\n\nui = lmai.ExplorerUI(\n    data='data.csv',\n    llm=lmai.llm.Anthropic(),  # (1)!\n    default_agents=[lmai.agents.SQLAgent, lmai.agents.ChatAgent],\n    log_level='INFO',\n)\nui.servable()\n</code></pre> <ol> <li>Use Anthropic instead of default OpenAI</li> </ol> <p>See the configuration guides for all available options:</p> <ul> <li>LLM Providers ‚Äî Configure your LLM, choose models, and optimize costs</li> <li>Prompts ‚Äî Customize agent behavior</li> <li>Sources ‚Äî Connect to databases and files</li> <li>Agents ‚Äî Use and customize agents</li> <li>Tools ‚Äî Extend capabilities with custom tools</li> <li>Analyses ‚Äî Add domain-specific analyses</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"getting_started/using_lumen_ai/#next-steps","level":2,"title":"Next steps","text":"<p>Now that you know the basics, dive deeper into specific topics:</p> <ul> <li>Agents ‚Äî Learn about the different agent types and how to customize them</li> <li>Prompts ‚Äî Fine-tune how agents respond</li> <li>Context ‚Äî Understand how agents share data</li> <li>Reports ‚Äî Build structured, reproducible analytical workflows</li> </ul>","path":["Getting Started","Using Lumen AI"],"tags":[]},{"location":"reference/api/","level":1,"title":"API Reference","text":"<p>Welcome to the Lumen API documentation. Browse the modules below:</p>","path":["API Reference"],"tags":[]},{"location":"reference/api/#modules","level":2,"title":"Modules","text":"<ul> <li>AI Module - AI-powered agents and analysis</li> <li>Pipeline - Data pipeline components</li> <li>Sources - Data source connectors</li> <li>Transforms - Data transformation utilities</li> <li>Views - Visualization components</li> </ul>","path":["API Reference"],"tags":[]},{"location":"reference/api/#how-to-guides","level":2,"title":"How-To Guides","text":"<p>These API modules are for reference. For practical guides on using these components, see the Configuration guides:</p> <ul> <li>Agents ‚Äî Create custom agents</li> <li>Data Sources ‚Äî Connect to databases and files</li> <li>Prompts ‚Äî Customize agent behavior</li> <li>Tools ‚Äî Build custom tools</li> <li>LLM Providers ‚Äî Configure your AI models</li> </ul>","path":["API Reference"],"tags":[]},{"location":"reference/api/ai/","level":1,"title":"AI Module","text":"<p>The AI module provides AI-powered agents, analysis tools, and related functionality.</p>","path":["AI Module"],"tags":[]},{"location":"reference/api/ai/#submodules","level":2,"title":"Submodules","text":"<ul> <li>Agents - AI agent implementations</li> <li>Coordinator - Coordination and orchestration</li> <li>Models - LLM models and interfaces</li> <li>Tools - AI tools and utilities</li> <li>Core Components - Core AI functionality</li> </ul>","path":["AI Module"],"tags":[]},{"location":"reference/api/ai/#how-to-guides","level":2,"title":"How-To Guides","text":"<p>For practical guides on building with these components:</p> <ul> <li>Creating Custom Agents ‚Äî Step-by-step guide to custom agents</li> <li>LLM Provider Configuration ‚Äî Configure models and temperature</li> <li>Building Tools ‚Äî Create tools for agents</li> <li>Agent Context &amp; Schemas ‚Äî Manage data passing between agents</li> </ul>","path":["AI Module"],"tags":[]},{"location":"reference/api/pipeline/","level":1,"title":"Pipeline","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline","level":2,"title":"<code>lumen.pipeline</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.VARIABLE_RE","level":3,"title":"<code>VARIABLE_RE = re.compile('\\\\$variables\\\\.([a-zA-Z_]\\\\w*)')</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.state","level":3,"title":"<code>state = _session_state()</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Component","level":3,"title":"<code>Component</code>","text":"<p>               Bases: <code>Parameterized</code></p> <p>Baseclass for all Lumen component types including Source, Filter, Transform, Variable and View types. Components must implement serialization and deserialization into a specification dictionary via the <code>from_spec</code> and <code>to_spec</code> protocol. Additonally they should implement validation.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Component.refs","level":4,"title":"<code>refs</code>  <code>property</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Component.from_spec","level":4,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"<p>Creates a Component instance from a specification.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict or str</code> <p>Specification declared as a dictionary of parameter values or a string referencing a source in the sources dictionary.</p> required <p>Returns:</p> Type Description <code>Resolved and instantiated Component object</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Component.to_spec","level":4,"title":"<code>to_spec(context=None)</code>","text":"<p>Exports the full specification to reconstruct this component.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Dict[str, Any]</code> <p>Context contains the specification of all previously serialized components, e.g. to allow resolving of references.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>Declarative specification of this component.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Component.validate","level":4,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"<p>Validates the component specification given the validation context.</p> Arguments <p>spec: dict | str   The specification for the component being validated (or a referene to the component) context: dict   Validation context contains the specification of all previously validated components,   e.g. to allow resolving of references.</p> <p>Returns:</p> Type Description <code>Validated specification.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.DataFrame","level":3,"title":"<code>DataFrame</code>","text":"<p>               Bases: <code>DataFrame</code></p> <p>DataFrame parameter that resolves data on access.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter","level":3,"title":"<code>Filter</code>","text":"<p>               Bases: <code>MultiTypeComponent</code></p> <p><code>Filter</code> components supply the filter values used by <code>Source</code> components to query data. .</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.field","level":4,"title":"<code>field = param.String(doc='The field being filtered.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.filter_type","level":4,"title":"<code>filter_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.label","level":4,"title":"<code>label = param.String(doc='A label for the Filter.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.panel","level":4,"title":"<code>panel</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>Viewable or None</code> <p>A Panel Viewable object representing the filter.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.query","level":4,"title":"<code>query</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>object</code> <p>The current filter query which will be used by the Source to filter the data.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.schema","level":4,"title":"<code>schema = param.Dict(doc='\\n        The JSON schema provided by the Source declaring information\\n        about the data to be filtered.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.shared","level":4,"title":"<code>shared = param.Boolean(default=False, doc='\\n        Whether the filter is shared across all layouts.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.sync_with_url","level":4,"title":"<code>sync_with_url = param.Boolean(default=True, doc='\\n        Whether to sync the filter state with the URL parameters.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.table","level":4,"title":"<code>table = param.String(default=None, doc='\\n        The table being filtered. If None applies to all tables.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.value","level":4,"title":"<code>value = param.Parameter(doc='The current filter value.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.from_spec","level":4,"title":"<code>from_spec(spec, source_schema, source_filters=None)</code>  <code>classmethod</code>","text":"<p>Resolves a Filter specification given the schema of the Source (and optionally the table) it will be filtering on.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict[str, Any] | str</code> <p>Specification declared as a dictionary of parameter values.</p> required <code>source_schema</code> <code>dict[str, dict[str, Any]]</code> <p>A dictionary containing the JSON schema of the Source to be filtered on.</p> required <code>source_filters</code> <code>dict[str, Filter] | None</code> <p>A dictionary of filters associated with the Source</p> <code>None</code> <p>Returns:</p> Type Description <code>The resolved Filter object.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.to_spec","level":4,"title":"<code>to_spec(context=None)</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Filter.validate","level":4,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.FilterTransform","level":3,"title":"<code>FilterTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Filter</code> transform implement the filtering behavior of <code>Filter</code> components.</p> <p>The filter <code>conditions</code> must be declared as a list of tuple containing the name of the column to be filtered and one of the following:</p> <ul> <li>scalar: A scalar value will be matched using equality operators</li> <li>tuple:  A tuple value specifies a numeric or date range.</li> <li>list:   A list value specifies a set of categories to match against.</li> <li>list(tuple): A list of tuples specifies a list of ranges.</li> </ul>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.FilterTransform.conditions","level":4,"title":"<code>conditions = param.List(doc='\\n      List of filter conditions expressed as tuples of the column\\n      name and the filter value.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.FilterTransform.apply","level":4,"title":"<code>apply(df)</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.ParamFilter","level":3,"title":"<code>ParamFilter</code>","text":"<p>               Bases: <code>Filter</code></p> <p><code>ParamFilter</code> reflects the value of a parameter declared on a <code>View</code>.</p> <p>The <code>ParamFilter</code> can be used to implement cross-filtering between different views.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.ParamFilter.filter_type","level":4,"title":"<code>filter_type = 'param'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.ParamFilter.parameter","level":4,"title":"<code>parameter = param.ClassSelector(default=None, class_=(param.Parameter, str), doc='\\n        Reference to a Parameter on an existing View.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline","level":3,"title":"<code>Pipeline</code>","text":"<p>               Bases: <code>Viewer</code>, <code>Component</code></p> <p><code>Pipeline</code> encapsulates filters and transformations applied to a :class:<code>lumen.sources.base.Source</code> table.</p> <p>A <code>Pipeline</code> ingests data from a :class:<code>lumen.sources.base.Source</code> table or another <code>Pipeline</code> applying the declared :class:<code>lumen.filters.base.Filter</code>, :class:<code>lumen.transforms.base.Transform</code> and :class:<code>lumen.transforms.sql.SQLTransform</code> definitions. It can be used to drive one or more visual outputs or leveraged as a standalone component to encapsulate multiple data processing steps.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.auto_update","level":4,"title":"<code>auto_update = param.Boolean(default=True, constant=True, doc='\\n        Whether changes in filters, transforms and references automatically\\n        trigger updates in the data or whether an update has to be triggered\\n        manually using the update event or the update button in the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.control_panel","level":4,"title":"<code>control_panel</code>  <code>property</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.data","level":4,"title":"<code>data = DataFrame(doc='The current data on this source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.filters","level":4,"title":"<code>filters = param.List(item_type=Filter, doc='\\n        A list of Filters to apply to the source data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.pipeline","level":4,"title":"<code>pipeline = param.ClassSelector(class_=None, doc='\\n        Optionally a pipeline may be chained to another pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.refs","level":4,"title":"<code>refs</code>  <code>property</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.schema","level":4,"title":"<code>schema = param.Dict(doc='The schema of the input data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.source","level":4,"title":"<code>source = param.ClassSelector(class_=Source, doc='\\n        The Source this pipeline is fed by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.sql_transforms","level":4,"title":"<code>sql_transforms = param.List(item_type=SQLTransform, doc='\\n        A list of SQLTransforms to apply to the source data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.table","level":4,"title":"<code>table = param.String(doc='\\n        The name of the table driving this pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.transforms","level":4,"title":"<code>transforms = param.List(item_type=Transform, doc='\\n        A list of Transforms to apply to the source data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.update","level":4,"title":"<code>update = param.Event(label='Apply update', doc='\\n        Update event trigger (if manual update is set).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.add_filter","level":4,"title":"<code>add_filter(filt, field=None, **kwargs)</code>","text":"<p>Add a filter to the pipeline.</p> Arguments <p>filt: Filter | Type[Filter]    The filter instance or filter type to add. field: str | None    The field to filter on (required to instantiate Filter type).</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.add_transform","level":4,"title":"<code>add_transform(transform, **kwargs)</code>","text":"<p>Add a (SQL)Transform to the pipeline.</p> Arguments <p>filt: Transform    The Transform instance to add.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.chain","level":4,"title":"<code>chain(filters=None, transforms=None, sql_transforms=None, **kwargs)</code>","text":"<p>Chains additional filtering, transform and sql_transform operations on an existing pipeline. Note that if one or more sql_transforms are provided the existing table will be mirrored into a DuckDB database.</p> Arguments <p>filters: List[Filter] | None   Additional filters to apply on top of existing pipeline. transforms: List[Transform] | None   Additional transforms to apply on top of existing pipeline. sql_transforms: List[SQLTransform] | None   Additional filters to apply on top of existing pipeline.</p> <p>Returns:</p> Type Description <code>Pipeline</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.clone","level":4,"title":"<code>clone(**params)</code>","text":"<p>Create a new instance of the pipeline with optionally overridden parameter values.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.from_spec","level":4,"title":"<code>from_spec(spec, source=None, source_filters=None)</code>  <code>classmethod</code>","text":"<p>Creates a Pipeline from a specification.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict or str</code> <p>Specification declared as a dictionary of parameter values or a string referencing a source in the sources dictionary.</p> required <p>Returns:</p> Type Description <code>Resolved and instantiated Pipeline object</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.get_schema","level":4,"title":"<code>get_schema()</code>","text":"<p>Generates a JSON schema for the current data held by the Pipeline.</p> <p>Returns:</p> Name Type Description <code>schema</code> <code>dict[str, any]</code> <p>JSON schema for each column in the current data.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.precache","level":4,"title":"<code>precache(queries)</code>","text":"<p>Populates the cache of the :class:<code>lumen.sources.base.Source</code> with the provided queries.</p> <p>Queries can be provided in two formats:</p> <ul> <li> <p>A dictionary containing 'filters' and 'variables'     dictionaries each containing lists of values to compute     a cross-product for, e.g.</p> <p>{     'filters': {       ': ['a', 'b', 'c', ...],       ...     },     'variables': {       : [0, 2, 4, ...],       ...     }   }   - A list containing dictionaries of explicit values for each filter and variables. <p>[{      'filters': {: 'a'},      'variables': {: 0}    },    {      'filters': {: 'a'},      'variables': {: 1}    },    ...   ]","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.to_spec","level":4,"title":"<code>to_spec(context=None)</code>","text":"<p>Exports the full specification to reconstruct this component.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>dict[str, Any] | None</code> <p>Context contains the specification of all previously serialized components, e.g. to allow resolving of references.</p> <code>None</code> <p>Returns:</p> Type Description <code>Declarative specification of this component.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.traverse","level":4,"title":"<code>traverse(type)</code>","text":"<p>Returns all Filter or Transform objects in a potentially chained pipeline.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Pipeline.validate","level":4,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform","level":3,"title":"<code>SQLTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Base class for SQL transforms using sqlglot.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.comments","level":4,"title":"<code>comments = param.Boolean(default=False, doc='Whether to include comments in the output SQL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.error_level","level":4,"title":"<code>error_level = param.ClassSelector(class_=(sqlglot.ErrorLevel), default=(sqlglot.ErrorLevel.RAISE), doc='Error level for parsing')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.identify","level":4,"title":"<code>identify = param.Boolean(default=False, doc='\\n        Delimit all identifiers, e.g. turn `FROM database.table` into `FROM \"database\".\"table\"`.\\n        This is useful for dialects that don\\'t support unquoted identifiers.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.optimize","level":4,"title":"<code>optimize = param.Boolean(default=False, doc=\"\\n        Whether to optimize the generated SQL query; may produce invalid results, especially with\\n        duckdb's read_* functions.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.pretty","level":4,"title":"<code>pretty = param.Boolean(default=False, doc='Prettify output SQL, i.e. add newlines and indentation')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.read","level":4,"title":"<code>read = param.String(default=None, doc='Source dialect for parsing; if None, automatically detects')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.unsupported_level","level":4,"title":"<code>unsupported_level = param.ClassSelector(class_=(sqlglot.ErrorLevel), default=(sqlglot.ErrorLevel.WARN), doc='When using `to_sql`, how to handle unsupported dialect features.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.write","level":4,"title":"<code>write = param.String(default=None, doc='Target dialect for output; if None, defaults to read dialect')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.apply","level":4,"title":"<code>apply(sql_in)</code>","text":"<p>Given an SQL statement, manipulate it, and return a new SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> <p>The initial SQL query to be manipulated.</p> required <p>Returns:</p> Type Description <code>string</code> <p>New SQL query derived from the above query.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.apply_to","level":4,"title":"<code>apply_to(sql_in, **kwargs)</code>  <code>classmethod</code>","text":"<p>Calls the apply method based on keyword arguments passed to define transform.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> required <p>Returns:</p> Type Description <code>SQL statement after application of transformation.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.parse_sql","level":4,"title":"<code>parse_sql(sql_in)</code>","text":"<p>Parse SQL string into sqlglot AST.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> <p>SQL string to parse</p> required <p>Returns:</p> Type Description <code>Expression</code> <p>Parsed SQL expression</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.SQLTransform.to_sql","level":4,"title":"<code>to_sql(expression)</code>","text":"<p>Convert sqlglot expression back to SQL string.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>Expression</code> <p>Expression to convert to SQL</p> required <p>Returns:</p> Type Description <code>string</code> <p>SQL string representation</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source","level":3,"title":"<code>Source</code>","text":"<p>               Bases: <code>MultiTypeComponent</code></p> <p><code>Source</code> components provide allow querying all kinds of data.</p> <p>A <code>Source</code> can return one or more tables queried using the <code>.get_tables</code> method, a description of the data returned by each table in the form of a JSON schema accessible via the <code>.get_schema</code> method and lastly a <code>.get</code> method that allows filtering the data.</p> <p>The Source base class also implements both in-memory and disk caching which can be enabled if a <code>cache_dir</code> is provided. Data cached to disk is stored as parquet files.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.cache_data","level":4,"title":"<code>cache_data = param.Boolean(default=True, doc='\\n        Whether to cache actual data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.cache_dir","level":4,"title":"<code>cache_dir = param.String(default=None, doc='\\n        Whether to enable local cache and write file to disk.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.cache_metadata","level":4,"title":"<code>cache_metadata = param.Boolean(default=True, doc='\\n        Whether to cache metadata.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.cache_per_query","level":4,"title":"<code>cache_per_query = param.Boolean(default=True, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.cache_schema","level":4,"title":"<code>cache_schema = param.Boolean(default=True, doc='\\n        Whether to cache table schemas.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.cache_with_dask","level":4,"title":"<code>cache_with_dask = param.Boolean(default=True, doc='\\n        Whether to read and write cache files with dask if available.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.metadata","level":4,"title":"<code>metadata = param.Dict(default={}, doc='\\n        Optional metadata about the source tables. Should follow the format:\\n        {\"table_name\": {\"description\": ..., \"columns\": {\"column_name\": \"...\"}}}')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.metadata_func","level":4,"title":"<code>metadata_func = param.Callable(default=None, doc='\\n        Function to implement custom metadata lookup for tables.\\n        Given a list of tables it should return a dictionary of the form:\\n\\n        {\\n            &lt;table&gt;: {\"description\": ..., \"columns\": {\"column_name\": \"...\"}}\\n        }\\n\\n        May be used to override the default _get_table_metadata\\n        implementation of the Source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.panel","level":4,"title":"<code>panel</code>  <code>property</code>","text":"<p>A Source can return a Panel object which displays information about the Source or controls how the Source queries data.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.root","level":4,"title":"<code>root = param.ClassSelector(class_=Path, precedence=(-1), doc='\\n        Root folder of the cache_dir, default is config.root')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.shared","level":4,"title":"<code>shared = param.Boolean(default=False, doc='\\n        Whether the Source can be shared across all instances of the\\n        dashboard. If set to `True` the Source will be loaded on\\n        initial server load.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.source_type","level":4,"title":"<code>source_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.clear_cache","level":4,"title":"<code>clear_cache(*events)</code>","text":"<p>Clears any cached data.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.from_spec","level":4,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"<p>Creates a Source object from a specification. If a Source specification references other sources these may be supplied in the sources dictionary and be referenced by name.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict or str</code> <p>Specification declared as a dictionary of parameter values or a string referencing a source in the sources dictionary.</p> required <p>Returns:</p> Type Description <code>Resolved and instantiated Source object</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.get","level":4,"title":"<code>get(table, **query)</code>","text":"<p>Return a table; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.get_async","level":4,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Return a table asynchronously; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.get_metadata","level":4,"title":"<code>get_metadata(table)</code>","text":"<p>Returns metadata for one, multiple or all tables provided by the source.</p> <p>The metadata for a table is structured as:</p> <p>{     \"description\": ...,     \"columns\": {         : {            \"description\": ...,            \"data_type\": ...,         }     },     **other_metadata } <p>If a list of tables or no table is provided the metadata is nested one additional level:</p> <p>{     \"table_name\": {         {             \"description\": ...,             \"columns\": {                 : {                 \"description\": ...,                 \"data_type\": ...,                 }             },             **other_metadata         }     } } <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | list[str] | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> required <p>Returns:</p> Name Type Description <code>metadata</code> <code>dict</code> <p>Dictionary of metadata indexed by table (if no table was was provided or individual table metdata.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.get_schema","level":4,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"<p>Returns JSON schema describing the tables returned by the Source.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limits the number of rows considered for the schema calculation</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON schema(s) for one or all the tables.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.get_tables","level":4,"title":"<code>get_tables()</code>","text":"<p>Returns the list of tables available on this source.</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of available tables on this source.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Source.validate","level":4,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform","level":3,"title":"<code>Transform</code>","text":"<p>               Bases: <code>MultiTypeComponent</code></p> <p><code>Transform</code> components implement transforms of <code>DataFrame</code> objects.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform.control_panel","level":4,"title":"<code>control_panel</code>  <code>property</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform.controls","level":4,"title":"<code>controls = param.List(default=[], doc='\\n        Parameters that should be exposed as widgets in the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform.transform_type","level":4,"title":"<code>transform_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform.apply","level":4,"title":"<code>apply(table)</code>","text":"<p>Given a table transform it in some way and return it.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> <p>The queried table as a DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the transformed data.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform.apply_to","level":4,"title":"<code>apply_to(table, **kwargs)</code>  <code>classmethod</code>","text":"<p>Calls the apply method based on keyword arguments passed to define transform.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> required <p>Returns:</p> Type Description <code>A DataFrame with the results of the transformation.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.Transform.from_spec","level":4,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"<p>Resolves a Transform specification.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict[str, Any] | str</code> <p>Specification declared as a dictionary of parameter values.</p> required <p>Returns:</p> Type Description <code>The resolved Transform object.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.ValidationError","level":3,"title":"<code>ValidationError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>A ValidationError is raised when the specification of a component has missing required keys, an incorrect value or is otherwise malformed.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter","level":3,"title":"<code>WidgetFilter</code>","text":"<p>               Bases: <code>BaseWidgetFilter</code></p> <p><code>WidgetFilter</code> generates a Widget from the table schema provided by a Source.</p> <p>By default the widget type will be inferred from the data and depending on whether <code>multi</code> value selection is enabled.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.empty_select","level":4,"title":"<code>empty_select = param.Boolean(default=True, doc='\\n        Add an option to Select widgets to indicate no filtering.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.filter_type","level":4,"title":"<code>filter_type = 'widget'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.max_options","level":4,"title":"<code>max_options = param.Integer(default=500, doc='\\n        Maximum number of options to render.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.multi","level":4,"title":"<code>multi = param.Boolean(default=True, doc='\\n        Whether to use a single-value or multi-value selection widget,\\n        e.g. for a numeric value this could be a regular slider or a\\n        range slider.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.query","level":4,"title":"<code>query</code>  <code>property</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.widget","level":4,"title":"<code>widget = JSONSchema(schema=(self.schema), sizing_mode='stretch_width', multi=(self.multi), widgets=({self.field: wtype} if wtype else {}))._widgets[self.field]</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.WidgetFilter.to_spec","level":4,"title":"<code>to_spec(context=None)</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.auto_filters","level":3,"title":"<code>auto_filters(schema)</code>","text":"<p>Automatically generates filter specifications from a schema.</p> Arguments <p>schema:   A schema describing the types of various fields.</p> <p>Returns:</p> Name Type Description <code>filter_specs</code> <code>A list of filter specifications.</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.catch_and_notify","level":3,"title":"<code>catch_and_notify(message=None)</code>","text":"<p>Catch exception and notify user</p> <p>A decorator which catches all the exception of a function. When an error occurs a panel notification will be send to the dashboard with the message and logged the error and which method it arrived from.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str | None</code> <p>The notification message, by default None. None will give this \"Error: {e}\" where e is the exception message.</p> <code>None</code>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.expand_queries","level":3,"title":"<code>expand_queries(values, groups=('filters', 'variables'))</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.get_dataframe_schema","level":3,"title":"<code>get_dataframe_schema(df, columns=None)</code>","text":"<p>Returns a JSON schema optionally filtered by a subset of the columns.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame or DataFrame</code> <p>The DataFrame to describe with the schema</p> required <code>columns</code> <p>List of columns to include in schema</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>The JSON schema describing the DataFrame</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.is_ref","level":3,"title":"<code>is_ref(value)</code>","text":"<p>Whether the value is a reference.</p>","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/pipeline/#lumen.pipeline.match_suggestion_message","level":3,"title":"<code>match_suggestion_message(word, possibilities, msg='', n=3)</code>","text":"","path":["Reference","API","Pipeline"],"tags":[]},{"location":"reference/api/sources/","level":1,"title":"Sources","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources","level":2,"title":"<code>lumen.sources</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5","level":3,"title":"<code>ae5</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source","level":4,"title":"<code>AE5Source</code>","text":"<p>               Bases: <code>Source</code></p> <p>The AE5Source queries an Anaconda Enterprise 5 instance for statistics.</p> <p>Specifically it provides tables with information nodes, deployments, sessions, jobs and resource profiles.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.admin_password","level":5,"title":"<code>admin_password = param.String(doc='Password to authenticate admin with AE5.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.admin_username","level":5,"title":"<code>admin_username = param.String(doc='Username to authenticate admin with AE5.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.hostname","level":5,"title":"<code>hostname = param.String(doc='URL of the AE5 host.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.k8s_endpoint","level":5,"title":"<code>k8s_endpoint = param.String(default='k8s')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.password","level":5,"title":"<code>password = param.String(doc='Password to authenticate with AE5.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.pool_size","level":5,"title":"<code>pool_size = param.Integer(default=100, doc='\\n      Size of HTTP socket pool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.private","level":5,"title":"<code>private = param.Boolean(default=True, doc='\\n      Whether to limit the deployments visible to a user based on\\n      their authorization.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.source_type","level":5,"title":"<code>source_type = 'ae5'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.username","level":5,"title":"<code>username = param.String(doc='Username to authenticate with AE5.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.ae5.AE5Source.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base","level":3,"title":"<code>base</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DataFrame","level":4,"title":"<code>DataFrame = pd.DataFrame | dDataFrame</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DataFrameTypes","level":4,"title":"<code>DataFrameTypes = (pd.DataFrame, dd.DataFrame)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Series","level":4,"title":"<code>Series = pd.Series | dSeries</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource","level":4,"title":"<code>BaseSQLSource</code>","text":"<p>               Bases: <code>Source</code></p> <p>The BaseSQLSource implements the additional API required by a SQL based data source.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.dialect","level":5,"title":"<code>dialect = 'any'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.excluded_tables","level":5,"title":"<code>excluded_tables = param.List(default=[], doc=\"\\n        List of table names that should be excluded from the results. Supports:\\n        - Fully qualified name: 'DATABASE.SCHEMA.TABLE'\\n        - Schema qualified name: 'SCHEMA.TABLE'\\n        - Table name only: 'TABLE'\\n        - Wildcards: 'SCHEMA.*'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.load_schema","level":5,"title":"<code>load_schema = param.Boolean(default=True, doc='Whether to load the schema')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.table_params","level":5,"title":"<code>table_params = param.Dict(default={}, doc=\"\\n        Dictionary mapping table names to SQL parameters.\\n        Parameters can be:\\n        - list: Positional parameters for placeholder (?) syntax\\n        - dict: Named parameters for :name, %(name)s, etc. syntax\\n        Each table maps to either a list or dict of parameters.\\n        Example: {'my_table': [2024, 'active'], 'other_table': {'year': 2024}}\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.create_sql_expr_source","level":5,"title":"<code>create_sql_expr_source(tables, params=None, **kwargs)</code>","text":"<p>Creates a new SQL Source given a set of table names and corresponding SQL expressions.</p> Arguments <p>tables: dict[str, str]     Mapping from table name to SQL expression. params: dict[str, list | dict] | None     Optional mapping from table name to parameters:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax kwargs: any     Additional keyword arguments.</p> <p>Returns:</p> Name Type Description <code>source</code> <code>BaseSQLSource subclass</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.execute","level":5,"title":"<code>execute(sql_query, params=None, *args, **kwargs)</code>","text":"<p>Executes a SQL query and returns the result as a DataFrame.</p> Arguments <p>sql_query : str     The SQL Query to execute params : list | dict | None     Parameters to use in the SQL query:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax     - None: No parameters args : list     Additional positional arguments to pass to the SQL query *kwargs : dict     Keyword arguments to pass to the SQL query</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.execute_async","level":5,"title":"<code>execute_async(sql_query, params=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>Executes a SQL query asynchronously and returns the result as a DataFrame.</p> <p>This default implementation runs the synchronous execute() method in a thread to avoid blocking the event loop. Subclasses can override this method to provide truly asynchronous implementations.</p> Arguments <p>sql_query : str     The SQL Query to execute params : list | dict | None     Parameters to use in the SQL query:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax     - None: No parameters args : list     Additional positional arguments to pass to the SQL query *kwargs : dict     Keyword arguments to pass to the SQL query</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.get_async","level":5,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Return a table asynchronously; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.get_sql_expr","level":5,"title":"<code>get_sql_expr(table)</code>","text":"<p>Returns the SQL expression corresponding to a particular table.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.BaseSQLSource.normalize_table","level":5,"title":"<code>normalize_table(table)</code>","text":"<p>Allows implementing table name normalization to allow fuzze matching of the table name for minor variations such as quoting differences.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource","level":4,"title":"<code>DerivedSource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>DerivedSource</code> applies filtering and transforms to tables from other sources.</p> <p>A DerivedSource references tables on other sources and optionally allows applying filters and transforms to the returned data which is then made available as a new (derived) table.</p> <p>The DerivedSource has two modes:</p> <p>Table Mode</p> <p>When an explicit <code>tables</code> specification is provided full control over the exact tables to filter and transform is available. This is referred to as the 'table' mode.</p> <p>In 'table' mode the tables can reference any table on any source using the reference syntax and declare filters and transforms to apply to that specific table, e.g. a table specification might look like this::</p> <pre><code>{\n  'derived_table': {\n    'source': 'original_source',\n    'table': 'original_table'\n    'filters': [\n      ...\n    ],\n    'transforms': [\n      ...\n    ]\n  }\n}\n</code></pre> <p>Mirror mode</p> <p>When a <code>source</code> is declared all tables on that Source are mirrored and filtered and transformed according to the supplied <code>filters</code> and <code>transforms</code>. This is referred to as 'mirror' mode.</p> <p>In mirror mode the DerivedSource may reference an existing source directly, e.g.::</p> <pre><code>{\n    'type': 'derived',\n    'source': 'original_source',\n    'filters': [...],\n    'transforms': [...],\n}\n</code></pre>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.filters","level":5,"title":"<code>filters = param.List(doc='\\n        A list of filters to apply to all tables of this source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.source","level":5,"title":"<code>source = param.ClassSelector(class_=Source, doc='\\n        A source to mirror the tables on.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.source_type","level":5,"title":"<code>source_type = 'derived'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.tables","level":5,"title":"<code>tables = param.Dict(default={}, doc='\\n        The dictionary of tables and associated filters and transforms.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.transforms","level":5,"title":"<code>transforms = param.List(doc='\\n        A list of transforms to apply to all tables of this source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.clear_cache","level":5,"title":"<code>clear_cache()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.DerivedSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource","level":4,"title":"<code>FileSource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>FileSource</code> loads CSV, Excel and Parquet files using pandas and dask <code>read_*</code> functions.</p> <p>The <code>FileSource</code> can declare a list or dictionary of local or remote files which are then loaded using either <code>pandas.read_*</code> or <code>dask.dataframe.read_*</code> functions depending on whether <code>use_dask</code> is enabled.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.dask","level":5,"title":"<code>dask = param.Boolean(default=False, doc='\\n        Whether to return a Dask dataframe.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.kwargs","level":5,"title":"<code>kwargs = param.Dict(doc='\\n        Keyword arguments to the pandas/dask loading function.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.source_type","level":5,"title":"<code>source_type = 'file'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.tables","level":5,"title":"<code>tables = param.ClassSelector(class_=(list, dict), doc=\"\\n        List or dictionary of tables to load. If a list is supplied the\\n        names are computed from the filenames, otherwise the keys are\\n        the names. The values must filepaths or URLs to the data:\\n\\n        ```\\n        {\\n            'local' : '/home/user/local_file.csv',\\n            'remote': 'https://test.com/test.csv'\\n        }\\n        ```\\n\\n        if the filepath does not have a declared extension an extension\\n        may be provided in a list or tuple, e.g.:\\n\\n        ```\\n        {'table': ['http://test.com/api', 'json']}\\n        ```\\n        \")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.use_dask","level":5,"title":"<code>use_dask = param.Boolean(default=True, doc='\\n        Whether to use dask to load files.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.FileSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.InMemorySource","level":4,"title":"<code>InMemorySource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>InMemorySource</code> can be used to work with in-memory data.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.InMemorySource.tables","level":5,"title":"<code>tables = param.Dict(default={})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.InMemorySource.add_table","level":5,"title":"<code>add_table(name, table)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.InMemorySource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.InMemorySource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.InMemorySource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JSONSource","level":4,"title":"<code>JSONSource</code>","text":"<p>               Bases: <code>FileSource</code></p> <p>The JSONSource is very similar to the FileSource but loads json files.</p> <p>Both local and remote JSON files can be fetched by declaring them as a list or dictionaries of <code>tables</code>.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JSONSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JSONSource.chunk_size","level":5,"title":"<code>chunk_size = param.Integer(default=0, doc='\\n        Number of items to load per chunk if a template variable\\n        is provided.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JSONSource.source_type","level":5,"title":"<code>source_type = 'json'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JSONSource.tables","level":5,"title":"<code>tables = param.ClassSelector(class_=(list, dict), doc=\"\\n        List or dictionary of tables to load. If a list is supplied the\\n        names are computed from the filenames, otherwise the keys are\\n        the names. The values must filepaths or URLs to the data:\\n\\n        ```\\n        {\\n            'local' : '/home/user/local_file.csv',\\n            'remote': 'https://test.com/test.csv'\\n        }\\n        ```\\n    \")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource","level":4,"title":"<code>JoinedSource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>JoinedSource</code> performs a join on tables from one or more sources.</p> <p>A JoinedSource applies a join on two or more sources returning new table(s) with data from all sources. It iterates over the <code>tables</code> specification and merges the specified tables from the declared sources on the supplied index.</p> <p>In this way multiple tables from multiple sources can be merged. Individual tables from sources that should not be joined may also be surfaced by declaring a single source and table in the specification.</p> <p>As a simple example we may have sources A and B, which contain tables 'foo' and 'bar' respectively. We now want to merge these tables on column 'a' in Table A with column 'b' in Table B::</p> <pre><code>{'new_table': [\n  {'source': 'A', 'table': 'foo', 'index': 'a'},\n  {'source': 'B', 'table': 'bar', 'index': 'b'}\n]}\n</code></pre> <p>The joined source will now publish the \"new_table\" with all columns from tables \"foo\" and \"bar\" except for the index column from table \"bar\", which was merged with the index column \"a\" from table \"foo\".</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.panel","level":5,"title":"<code>panel</code>  <code>property</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.source_type","level":5,"title":"<code>source_type = 'join'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.sources","level":5,"title":"<code>sources = param.ClassSelector(class_=(list, dict), doc='\\n        A dictionary of sources indexed by their assigned name.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.tables","level":5,"title":"<code>tables = param.Dict(default={}, doc='\\n        A dictionary with the names of the joined sources as keys\\n        and a specification of the source, table and index to merge\\n        on.\\n\\n        ```\\n        {\"new_table\": [\\n            {\\'source\\': &lt;source_name&gt;,\\n \\'table\\': &lt;table_name&gt;,\\n \\'index\\': &lt;index_name&gt;\\n            },\\n            {\\'source\\': &lt;source_name&gt;,\\n \\'table\\': &lt;table_name&gt;,\\n \\'index\\': &lt;index_name&gt;\\n            },\\n            ...\\n        ]}\\n        ```\\n        ')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.clear_cache","level":5,"title":"<code>clear_cache()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.JoinedSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource","level":4,"title":"<code>PanelSessionSource</code>","text":"<p>               Bases: <code>Source</code></p> <p>\" <code>PanelSessionSource</code> queries the session_info endpoint of a Panel application.</p> <p>Panel applications with --rest-session-info enabled can be queried about session statistics. This source makes this data available to Lumen for monitoring.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.endpoint","level":5,"title":"<code>endpoint = param.String(default='rest/session_info')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.source_type","level":5,"title":"<code>source_type = 'session_info'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.timeout","level":5,"title":"<code>timeout = param.Parameter(default=5)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.urls","level":5,"title":"<code>urls = param.List(doc='URL of the websites to monitor.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.PanelSessionSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.RESTSource","level":4,"title":"<code>RESTSource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>RESTSource</code> allows querying REST endpoints conforming to the Lumen REST specification.</p> <p>The <code>url</code> must offer two endpoints, the <code>/data</code> endpoint must return data in a records format while the <code>/schema</code> endpoint must return a valid Lumen JSON schema.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.RESTSource.source_type","level":5,"title":"<code>source_type = 'rest'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.RESTSource.url","level":5,"title":"<code>url = param.String(doc='URL of the REST endpoint to monitor.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.RESTSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.RESTSource.get_async","level":5,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Return a table asynchronously; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame containing the queried table.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.RESTSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source","level":4,"title":"<code>Source</code>","text":"<p>               Bases: <code>MultiTypeComponent</code></p> <p><code>Source</code> components provide allow querying all kinds of data.</p> <p>A <code>Source</code> can return one or more tables queried using the <code>.get_tables</code> method, a description of the data returned by each table in the form of a JSON schema accessible via the <code>.get_schema</code> method and lastly a <code>.get</code> method that allows filtering the data.</p> <p>The Source base class also implements both in-memory and disk caching which can be enabled if a <code>cache_dir</code> is provided. Data cached to disk is stored as parquet files.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.cache_data","level":5,"title":"<code>cache_data = param.Boolean(default=True, doc='\\n        Whether to cache actual data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.cache_dir","level":5,"title":"<code>cache_dir = param.String(default=None, doc='\\n        Whether to enable local cache and write file to disk.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.cache_metadata","level":5,"title":"<code>cache_metadata = param.Boolean(default=True, doc='\\n        Whether to cache metadata.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=True, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.cache_schema","level":5,"title":"<code>cache_schema = param.Boolean(default=True, doc='\\n        Whether to cache table schemas.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.cache_with_dask","level":5,"title":"<code>cache_with_dask = param.Boolean(default=True, doc='\\n        Whether to read and write cache files with dask if available.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.metadata","level":5,"title":"<code>metadata = param.Dict(default={}, doc='\\n        Optional metadata about the source tables. Should follow the format:\\n        {\"table_name\": {\"description\": ..., \"columns\": {\"column_name\": \"...\"}}}')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.metadata_func","level":5,"title":"<code>metadata_func = param.Callable(default=None, doc='\\n        Function to implement custom metadata lookup for tables.\\n        Given a list of tables it should return a dictionary of the form:\\n\\n        {\\n            &lt;table&gt;: {\"description\": ..., \"columns\": {\"column_name\": \"...\"}}\\n        }\\n\\n        May be used to override the default _get_table_metadata\\n        implementation of the Source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.panel","level":5,"title":"<code>panel</code>  <code>property</code>","text":"<p>A Source can return a Panel object which displays information about the Source or controls how the Source queries data.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.root","level":5,"title":"<code>root = param.ClassSelector(class_=Path, precedence=(-1), doc='\\n        Root folder of the cache_dir, default is config.root')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.shared","level":5,"title":"<code>shared = param.Boolean(default=False, doc='\\n        Whether the Source can be shared across all instances of the\\n        dashboard. If set to `True` the Source will be loaded on\\n        initial server load.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.source_type","level":5,"title":"<code>source_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.clear_cache","level":5,"title":"<code>clear_cache(*events)</code>","text":"<p>Clears any cached data.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.from_spec","level":5,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"<p>Creates a Source object from a specification. If a Source specification references other sources these may be supplied in the sources dictionary and be referenced by name.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict or str</code> <p>Specification declared as a dictionary of parameter values or a string referencing a source in the sources dictionary.</p> required <p>Returns:</p> Type Description <code>Resolved and instantiated Source object</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.get","level":5,"title":"<code>get(table, **query)</code>","text":"<p>Return a table; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.get_async","level":5,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Return a table asynchronously; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.get_metadata","level":5,"title":"<code>get_metadata(table)</code>","text":"<p>Returns metadata for one, multiple or all tables provided by the source.</p> <p>The metadata for a table is structured as:</p> <p>{     \"description\": ...,     \"columns\": {         : {            \"description\": ...,            \"data_type\": ...,         }     },     **other_metadata } <p>If a list of tables or no table is provided the metadata is nested one additional level:</p> <p>{     \"table_name\": {         {             \"description\": ...,             \"columns\": {                 : {                 \"description\": ...,                 \"data_type\": ...,                 }             },             **other_metadata         }     } } <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | list[str] | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> required <p>Returns:</p> Name Type Description <code>metadata</code> <code>dict</code> <p>Dictionary of metadata indexed by table (if no table was was provided or individual table metdata.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"<p>Returns JSON schema describing the tables returned by the Source.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limits the number of rows considered for the schema calculation</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON schema(s) for one or all the tables.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.get_tables","level":5,"title":"<code>get_tables()</code>","text":"<p>Returns the list of tables available on this source.</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of available tables on this source.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.Source.validate","level":5,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource","level":4,"title":"<code>WebsiteSource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>WebsiteSource</code> queries whether a website responds with a 400 status code.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource.source_type","level":5,"title":"<code>source_type = 'live'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource.urls","level":5,"title":"<code>urls = param.List(doc='URLs of the websites to monitor.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.WebsiteSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.cached","level":4,"title":"<code>cached(method, locks=None)</code>","text":"<p>Adds caching to a Source.get query.</p> <p>Returns:</p> Type Description <code>Returns method wrapped in caching functionality.</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.cached_metadata","level":4,"title":"<code>cached_metadata(method, locks=None)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.base.cached_schema","level":4,"title":"<code>cached_schema(method, locks=None)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery","level":3,"title":"<code>bigquery</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource","level":4,"title":"<code>BigQuerySource</code>","text":"<p>               Bases: <code>BaseSQLSource</code></p> <p>BigQuerySource provides access to a Google BigQuery project.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.datasets","level":5,"title":"<code>datasets = param.List(default=None, doc='List of datasets to include')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.dialect","level":5,"title":"<code>dialect = 'bigquery'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.filter_in_sql","level":5,"title":"<code>filter_in_sql = param.Boolean(default=True, doc='Whether to apply filters in SQL or in-memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.location","level":5,"title":"<code>location = param.String(doc='Location where the project resides.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.project_id","level":5,"title":"<code>project_id = param.String(doc=\"The Google Cloud's project ID.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.tables","level":5,"title":"<code>tables = param.ClassSelector(class_=(list, dict), doc='\\n       A list of tables or a dictionary mapping from table name to a SQL query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.close","level":5,"title":"<code>close()</code>","text":"<p>Close the BigQuery client connections, releasing associated resources.</p> <p>This method should be called when the source is no longer needed to prevent connection leaks and properly clean up resources.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.create_sql_expr_source","level":5,"title":"<code>create_sql_expr_source(tables, params=None, **kwargs)</code>","text":"<p>Creates a new SQL Source given a set of table names and corresponding SQL expressions.</p> Arguments <p>tables: dict[str, str]     Mapping from table name to SQL expression. params: dict[str, list | dict] | None     Optional mapping from table name to parameters:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax kwargs: any     Additional keyword arguments.</p> <p>Returns:</p> Name Type Description <code>source</code> <code>BigQuerySource</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.execute","level":5,"title":"<code>execute(sql_query, params=None, *args, **kwargs)</code>","text":"<p>Executes a SQL query and returns the result as a DataFrame.</p> Arguments <p>sql_query : str     The SQL Query to execute params : list | dict | None     Parameters to use in the SQL query:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax     - None: No parameters args : list     Additional positional arguments to pass to the SQL query *kwargs : dict     Keyword arguments to pass to the SQL query</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.execute_async","level":5,"title":"<code>execute_async(sql_query, params=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>Executes a SQL query asynchronously and returns the result as a DataFrame.</p> <p>This implementation runs queries asynchronously using BigQuery's job API.</p> Arguments <p>sql_query : str     The SQL Query to execute params : list | dict | None     Parameters to use in the SQL query:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax     - None: No parameters args : list     Additional positional arguments to pass to the SQL query *kwargs : dict     Keyword arguments to pass to the SQL query</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.get_async","level":5,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Retrieve a table from BigQuery asynchronously with optional filtering.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The table name to query</p> required <code>**query</code> <code>dict</code> <p>Query parameters and filters to apply</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The filtered table data as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"<p>Determine the schema of the given <code>table</code>.</p> <p>This method overrides the inherited <code>get_schema</code> from the base class <code>Source</code>. The reason why we override</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | None</code> <p>The name of the table. Must be in the form: f\"{project_id}.{dataset_id}.{table_id}\" or reference a table in the tables dictionary.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>The maximum number of rows to sample from the table.</p> <code>None</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the rows of the table.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]] | dict[str, Any]</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.get_sql_expr","level":5,"title":"<code>get_sql_expr(table)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.bigquery.BigQuerySource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"<p>Get a list of available tables for the project.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Table names are composed of f\"{project_id}.{dataset_id}.{table_id}\".</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb","level":3,"title":"<code>duckdb</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource","level":4,"title":"<code>DuckDBSource</code>","text":"<p>               Bases: <code>BaseSQLSource</code></p> <p>DuckDBSource provides a simple wrapper around the DuckDB SQL connector.</p> <p>To specify tables to be queried provide a list or dictionary of tables. A SQL expression to fetch the data from the table will then be generated using the <code>sql_expr</code>, e.g. if we specify a local table flights.db the default sql_expr <code>SELECT * FROM {table}</code> will expand that to <code>SELECT * FROM flights.db</code>. If you want to specify a full SQL expression as a table you must change the <code>sql_expr</code> to '{table}' ensuring no further templating is applied.</p> <p>Note that certain functionality in DuckDB requires modules to be loaded before making a query. These can be specified using the <code>initializers</code> parameter, providing the ability to define DuckDb statements to be run when initializing the connection.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.connection","level":5,"title":"<code>connection</code>  <code>property</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.dialect","level":5,"title":"<code>dialect = 'duckdb'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.ephemeral","level":5,"title":"<code>ephemeral = param.Boolean(default=False, doc='\\n        Whether the data is ephemeral, i.e. manually inserted into the\\n        DuckDB table or derived from real data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.filter_in_sql","level":5,"title":"<code>filter_in_sql = param.Boolean(default=True, doc='\\n        Whether to apply filters in SQL or in-memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.initializers","level":5,"title":"<code>initializers = param.List(default=[], doc='\\n        SQL statements to run to initialize the connection.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.load_schema","level":5,"title":"<code>load_schema = param.Boolean(default=True, doc='Whether to load the schema')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.mirrors","level":5,"title":"<code>mirrors = param.Dict(default={}, doc='\\n        Mirrors the tables into the DuckDB database. The mirrors\\n        should define a mapping from the table names to the source of\\n        the mirror which may be defined as a Pipeline or a tuple of\\n        the source and the table.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.read_only","level":5,"title":"<code>read_only = param.Boolean(default=None, doc='\\n        Whether to open the DuckDB database in read-only mode.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.source_type","level":5,"title":"<code>source_type = 'duckdb'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.sql_expr","level":5,"title":"<code>sql_expr = param.String(default='SELECT * FROM {table}', doc='\\n        The SQL expression to execute.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.table_params","level":5,"title":"<code>table_params = param.Dict(default={}, doc='\\n        Dictionary mapping table names to lists of SQL parameters.\\n        Parameters are used with placeholders (?) in SQL expressions.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.tables","level":5,"title":"<code>tables = param.ClassSelector(class_=(list, dict), doc='\\n        List or dictionary of tables.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.uri","level":5,"title":"<code>uri = param.String(doc='The URI of the DuckDB database')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.close","level":5,"title":"<code>close()</code>","text":"<p>Close the DuckDB connection, releasing associated resources.</p> <p>This method should be called when the source is no longer needed to prevent connection leaks and properly clean up server-side resources.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.create_sql_expr_source","level":5,"title":"<code>create_sql_expr_source(tables, materialize=True, params=None, **kwargs)</code>","text":"<p>Creates a new SQL Source given a set of table names and corresponding SQL expressions.</p> Arguments <p>tables: dict[str, str]     Mapping from table name to SQL expression. materialize: bool     Whether to materialize new tables params: dict[str, list | dict] | None     Optional mapping from table name to parameters:     - list: Positional parameters for ? placeholders     - dict: Named parameters for $param_name placeholders kwargs: any     Additional keyword arguments.</p> <p>Returns:</p> Name Type Description <code>source</code> <code>DuckDBSource</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.execute","level":5,"title":"<code>execute(sql_query, params=None, *args, **kwargs)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.from_df","level":5,"title":"<code>from_df(tables, **kwargs)</code>  <code>classmethod</code>","text":"<p>Creates an ephemeral, in-memory DuckDBSource containing the supplied dataframe.</p> Arguments <p>tables: dict[str, pandas.DataFrame]     A dictionary mapping from table names to DataFrames kwargs: any     Additional keyword arguments for the source</p> <p>Returns:</p> Name Type Description <code>source</code> <code>DuckDBSource</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.from_spec","level":5,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.normalize_table","level":5,"title":"<code>normalize_table(table)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.duckdb.DuckDBSource.to_spec","level":5,"title":"<code>to_spec(context=None)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake","level":3,"title":"<code>intake</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeBaseSource","level":4,"title":"<code>IntakeBaseSource</code>","text":"<p>               Bases: <code>Source</code></p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeBaseSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeBaseSource.load_schema","level":5,"title":"<code>load_schema = param.Boolean(default=True, doc='\\n        Whether to load the schema')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeBaseSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeBaseSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeBaseSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeSource","level":4,"title":"<code>IntakeSource</code>","text":"<p>               Bases: <code>IntakeBaseSource</code></p> <p>An <code>IntakeSource</code> loads data from an Intake catalog.</p> <p>Intake is a lightweight set of tools for loading and sharing data in data science projects using convenient catalog specifications.</p> <p>The <code>IntakeSource</code> can be given a dictionary <code>catalog</code> specification OR a URI pointing to a catalog.yaml file on disk.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeSource.cat","level":5,"title":"<code>cat = intake.open_catalog(self.uri)</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeSource.catalog","level":5,"title":"<code>catalog = param.Dict(doc='An inlined Catalog specification.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeSource.dask","level":5,"title":"<code>dask = param.Boolean(default=False, doc='\\n        Whether to return a dask DataFrame.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeSource.source_type","level":5,"title":"<code>source_type = 'intake'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake.IntakeSource.uri","level":5,"title":"<code>uri = param.String(doc='URI of the catalog file.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio","level":3,"title":"<code>intake_dremio</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource","level":4,"title":"<code>IntakeBaseDremioSource</code>","text":"<p>               Bases: <code>IntakeBaseSQLSource</code></p> <p>Base class with common parameters for Dremio sources.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.cert","level":5,"title":"<code>cert = param.String(default='Path to certificate file')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.dask","level":5,"title":"<code>dask = param.Boolean(default=False, doc='\\n        Whether to return a dask DataFrame.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.dialect","level":5,"title":"<code>dialect = 'dremio'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.password","level":5,"title":"<code>password = param.String(default=None, doc='Dremio password or token')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.tls","level":5,"title":"<code>tls = param.Boolean(default=False, doc='Enable encryption')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.uri","level":5,"title":"<code>uri = param.String(doc='URI of the Dremio server.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.username","level":5,"title":"<code>username = param.String(default=None, doc='Dremio username')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.create_sql_expr_source","level":5,"title":"<code>create_sql_expr_source(tables, **kwargs)</code>","text":"<p>Creates a new SQL Source given a set of table names and corresponding SQL expressions.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeBaseDremioSource.normalize_table","level":5,"title":"<code>normalize_table(table)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSQLSource","level":4,"title":"<code>IntakeDremioSQLSource</code>","text":"<p>               Bases: <code>IntakeBaseDremioSource</code></p> <p><code>IntakeDremioSQLSource</code> allows querying a subset of Dremio catalog tables and views via custom SQL expressions.</p> <p>When provided with the <code>uri</code> of the Dremio server and credentials to authenticate with the Dremio instance, unlike <code>IntakeDremioSource</code>, only the tables specified in the <code>tables</code> parameter can be used.</p> <p>Requires the intake-dremio package to be installed.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSQLSource.cat","level":5,"title":"<code>cat = {table: (DremioSource(sql_expr=sql_expr, cert=(self.cert), uri=(self.uri), tls=(self.tls), username=(self.username), password=(self.password))) for table, sql_expr in (self.tables.items())}</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSQLSource.source_type","level":5,"title":"<code>source_type = 'intake_dremio_sql'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSQLSource.tables","level":5,"title":"<code>tables = param.Dict(default={}, doc='\\n        Mapping of table names to desired SQL expressions')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSource","level":4,"title":"<code>IntakeDremioSource</code>","text":"<p>               Bases: <code>IntakeBaseDremioSource</code></p> <p><code>IntakeDremioSource</code> allows querying Dremio catalog tables and views.</p> <p>When provided with the <code>uri</code> of the Dremio server and credentials to authenticate with the Dremio instance all available tables can be queried via this <code>Source</code>.</p> <p>Requires the intake-dremio package to be installed.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSource.cat","level":5,"title":"<code>cat = DremioCatalog(self.uri, cert=(self.cert), tls=(self.tls), username=(self.username), password=(self.password))</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_dremio.IntakeDremioSource.source_type","level":5,"title":"<code>source_type = 'intake_dremio'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql","level":3,"title":"<code>intake_sql</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeBaseSQLSource","level":4,"title":"<code>IntakeBaseSQLSource</code>","text":"<p>               Bases: <code>BaseSQLSource</code>, <code>IntakeBaseSource</code></p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeBaseSQLSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=True, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeBaseSQLSource.filter_in_sql","level":5,"title":"<code>filter_in_sql = param.Boolean(default=True, doc='')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeBaseSQLSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"<p>Applies SQL Transforms, creating new temp catalog on the fly and querying the database.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeBaseSQLSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeBaseSQLSource.get_sql_expr","level":5,"title":"<code>get_sql_expr(table)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeSQLSource","level":4,"title":"<code>IntakeSQLSource</code>","text":"<p>               Bases: <code>IntakeBaseSQLSource</code>, <code>IntakeSource</code></p> <p><code>IntakeSQLSource</code> extends the <code>IntakeSource</code> with support for SQL data.</p> <p>In addition to the standard intake support for reading catalogs the <code>IntakeSQLSource</code> computes the schema by querying the database instead of loading all the data into memory and allows for <code>SQLTransform</code> to be applied when querying the SQL database.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.intake_sql.IntakeSQLSource.source_type","level":5,"title":"<code>source_type = 'intake_sql'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus","level":3,"title":"<code>prometheus</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource","level":4,"title":"<code>PrometheusSource</code>","text":"<p>               Bases: <code>Source</code></p> <p><code>PrometheusSource</code> allows querying Prometheus PromQL endpoints.</p> <p>The <code>PrometheusSource</code> is configured to return timeseries about CPU, memory and network usage as well as restarts for a list of Kubernetes pods specified by ID.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.ae5_source","level":5,"title":"<code>ae5_source = param.Parameter(doc='\\n      An AE5Source instance to use for querying.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.cache_per_query","level":5,"title":"<code>cache_per_query = param.Boolean(default=False, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.ids","level":5,"title":"<code>ids = param.List(default=[], doc='\\n      List of pod IDs to query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.metrics","level":5,"title":"<code>metrics = param.List(default=['memory_usage', 'cpu_usage', 'restarts', 'network_receive_bytes', 'network_transmit_bytes'], doc='Names of metric queries to execute')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.panel","level":5,"title":"<code>panel</code>  <code>property</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.period","level":5,"title":"<code>period = param.String(default='3h', doc=\"\\n      Period to query over specified as a string. Supports:\\n\\n        - Week:   '1w'\\n        - Day:    '1d'\\n        - Hour:   '1h'\\n        - Minute: '1m'\\n        - Second: '1s'\\n    \")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.promql_api","level":5,"title":"<code>promql_api = param.String(doc='\\n      Name of the AE5 deployment exposing the Prometheus API')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.samples","level":5,"title":"<code>samples = param.Integer(default=200, doc='\\n      Number of samples in the selected period to query. May be\\n      overridden by explicit step value.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.shared","level":5,"title":"<code>shared = param.Boolean(default=False, readonly=True, doc='\\n      PrometheusSource cannot be shared because it has per-user state.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.source_type","level":5,"title":"<code>source_type = 'prometheus'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.step","level":5,"title":"<code>step = param.String(doc='\\n        Step value to use in PromQL query_range query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.prometheus.PrometheusSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake","level":3,"title":"<code>snowflake</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource","level":4,"title":"<code>SnowflakeSource</code>","text":"<p>               Bases: <code>BaseSQLSource</code></p> <p>SnowflakeSource uses the snowflake-python-connector library to load data from Snowflake.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.account","level":5,"title":"<code>account = param.String(default=None, doc='\\n        The account identifier to connect to.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.authenticator","level":5,"title":"<code>authenticator = param.Selector(default=None, objects=['externalbrowser', 'oauth', 'snowflake', 'username_password_mfa', 'SNOWFLAKE_JWT'], doc='\\n        The authentication approach to use.', allow_None=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.conn_kwargs","level":5,"title":"<code>conn_kwargs = param.Dict(default={}, doc='\\n        Additional connection parameters to pass to the Snowflake connector.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.database","level":5,"title":"<code>database = param.String(default=None, doc='\\n        The database to connect to.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.dialect","level":5,"title":"<code>dialect = 'snowflake'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.excluded_tables","level":5,"title":"<code>excluded_tables = param.List(default=[], doc='\\n        List of table names that should be excluded from the results.\\n        The items can be fully qualified (database.schema.table), partially\\n        qualified (schema.table), simply table names, or wildcards\\n        (e.g. database.schema.*).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.filter_in_sql","level":5,"title":"<code>filter_in_sql = param.Boolean(default=True, doc='\\n        Whether to apply filters in SQL or in-memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.host","level":5,"title":"<code>host = param.String(default=None, doc='\\n        The host to authenticate with.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.paramstyle","level":5,"title":"<code>paramstyle = param.Selector(default='qmark', objects=['qmark', 'numeric', 'format', 'pyformat'], doc='\\n        The paramstyle to use for SQL queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.password","level":5,"title":"<code>password = param.String(default=None, doc='\\n        The password to authenticate with (if authenticator is set to \"snowflake\").')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.private_key","level":5,"title":"<code>private_key = param.ClassSelector(default=None, class_=(str, bytes, Path), doc='\\n        The path or contents of the private key file.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.private_key_password","level":5,"title":"<code>private_key_password = param.String(default=None, doc='\\n        The password to decrypt the private key file.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.schema","level":5,"title":"<code>schema = param.String(default=None, doc='\\n        The database schema to load data from.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.schema_timeout_seconds","level":5,"title":"<code>schema_timeout_seconds = param.Integer(default=600, doc='\\n        Timeout in seconds for schema retrieval. If None, no timeout is applied.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.sql_expr","level":5,"title":"<code>sql_expr = param.String(default='SELECT * FROM {table}', doc='\\n        The SQL expression to execute.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.tables","level":5,"title":"<code>tables = param.ClassSelector(class_=(list, dict), doc='\\n        List or dictionary of tables.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.token","level":5,"title":"<code>token = param.String(default=None, doc='\\n        The OAuth token if authenticator is set to \"oauth\".')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.user","level":5,"title":"<code>user = param.String(default=None, doc='\\n        The user to authenticate as.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.warehouse","level":5,"title":"<code>warehouse = param.String(default=None, doc='\\n        The warehouse to connect to.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.close","level":5,"title":"<code>close()</code>","text":"<p>Close the Snowflake connection and cursor, releasing associated resources.</p> <p>This method should be called when the source is no longer needed to prevent connection leaks and properly clean up server-side resources.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.create_sql_expr_source","level":5,"title":"<code>create_sql_expr_source(tables, params=None, **kwargs)</code>","text":"<p>Creates a new SQL Source given a set of table names and corresponding SQL expressions.</p> Arguments <p>tables: dict[str, str]     Mapping from table name to SQL expression. params: dict[str, list | dict] | None     Optional mapping from table name to parameters:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters (for pyformat/format paramstyle) kwargs: any     Additional keyword arguments.</p> <p>Returns:</p> Name Type Description <code>source</code> <code>SnowflakeSource</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.execute","level":5,"title":"<code>execute(sql_query, params=None, *args, **kwargs)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.execute_async","level":5,"title":"<code>execute_async(sql_query, params=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>Execute a Snowflake SQL query asynchronously and return the result as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>sql_query</code> <code>str</code> <p>The SQL query to execute</p> required <code>params</code> <code>list | dict | None</code> <p>Parameters to use in the SQL query: - list: Positional parameters for placeholder (?) syntax (qmark paramstyle) - dict: Named parameters (for pyformat/format paramstyle) - None: No parameters</p> <code>None</code> <code>*args</code> <code>tuple</code> <p>Additional positional arguments to pass to the query</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the query</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The query result as a pandas DataFrame with supported dtypes</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.get","level":5,"title":"<code>get(table, **query)</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.get_async","level":5,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Retrieve data from a table asynchronously using the same query logic as get().</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>**query</code> <code>dict</code> <p>Query parameters and filters to apply</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The query result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"<p>Returns JSON schema describing the tables returned by the Source.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limits the number of rows considered for the schema calculation</p> <code>None</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle the rows when sampling</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON schema(s) for one or all the tables.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.snowflake.SnowflakeSource.resolve_private_key","level":5,"title":"<code>resolve_private_key()</code>","text":"<p>Converts a PEM encoded private key into a DER binary key.</p> <p>Returns:</p> Type Description <code>bytes or None</code> <p>DER encoded key if private_key has been provided otherwise returns None.</p> <p>Raises:</p> Type Description <code>InvalidPemFormat</code> <p>If private key is not in PEM format.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy","level":3,"title":"<code>sqlalchemy</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.DataFrame","level":4,"title":"<code>DataFrame = pd.DataFrame</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource","level":4,"title":"<code>SQLAlchemySource</code>","text":"<p>               Bases: <code>BaseSQLSource</code></p> <p>SQLAlchemySource uses SQLAlchemy to connect to various SQL databases.</p> <p>Supports both synchronous and asynchronous database drivers through SQLAlchemy's engine system. Can connect to PostgreSQL, MySQL, SQLite, Oracle, MSSQL, and more.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.async_drivers","level":5,"title":"<code>async_drivers = {'postgresql+asyncpg', 'mysql+asyncmy', 'mysql+aiomysql', 'sqlite+aiosqlite', 'oracle+oracledb_async'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.connect_args","level":5,"title":"<code>connect_args = param.Dict(default={}, doc=\"\\n        Additional keyword arguments passed to the DBAPI's connect() method.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.database","level":5,"title":"<code>database = param.String(default=None, doc='\\n        The database name to connect to.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.dialect","level":5,"title":"<code>dialect</code>  <code>property</code>","text":"<p>Detect and return the database dialect name.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.drivername","level":5,"title":"<code>drivername = param.String(default=None, doc=\"\\n        The driver name (e.g., 'postgresql+psycopg2', 'mysql+pymysql', 'sqlite').\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.engine_kwargs","level":5,"title":"<code>engine_kwargs = param.Dict(default={}, doc='\\n        Additional keyword arguments passed to create_engine().')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.excluded_tables","level":5,"title":"<code>excluded_tables = param.List(default=[], doc=\"\\n        List of table name patterns to exclude from the results.\\n        Supports wildcards (e.g., 'schema.table*', 'temp_*').\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.filter_in_sql","level":5,"title":"<code>filter_in_sql = param.Boolean(default=True, doc='\\n        Whether to apply filters in SQL or in-memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.host","level":5,"title":"<code>host = param.String(default=None, doc='\\n        The database host address.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.password","level":5,"title":"<code>password = param.String(default=None, doc='\\n        The password for database authentication.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.port","level":5,"title":"<code>port = param.Integer(default=None, doc='\\n        The database port number.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.query_params","level":5,"title":"<code>query_params = param.Dict(default=None, doc='\\n        Additional query parameters for the connection URL.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.schema","level":5,"title":"<code>schema = param.String(default=None, doc='\\n        The default schema to use for queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.schema_timeout_seconds","level":5,"title":"<code>schema_timeout_seconds = param.Integer(default=600, doc='\\n        Timeout in seconds for schema retrieval operations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.source_type","level":5,"title":"<code>source_type = 'sqlalchemy'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.sql_expr","level":5,"title":"<code>sql_expr = param.String(default='SELECT * FROM {table}', doc='\\n        The SQL expression template to execute.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.tables","level":5,"title":"<code>tables = param.ClassSelector(class_=(list, dict), doc='\\n        List or dictionary of tables to expose.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.url","level":5,"title":"<code>url = param.String(default=None, doc=\"\\n        SQLAlchemy database URL string (e.g., 'postgresql://user:pass@host:port/db').\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.username","level":5,"title":"<code>username = param.String(default=None, doc='\\n        The username for database authentication.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.close","level":5,"title":"<code>close()</code>","text":"<p>Close the database connection and dispose of the engine.</p> <p>This method should be called when the source is no longer needed to prevent connection leaks and properly clean up server-side resources.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.create_sql_expr_source","level":5,"title":"<code>create_sql_expr_source(tables, params=None, **kwargs)</code>","text":"<p>Creates a new SQL Source given a set of table names and corresponding SQL expressions.</p> Arguments <p>tables: dict[str, str]     Mapping from table name to SQL expression. params: dict[str, list | dict] | None     Optional mapping from table name to parameters:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax kwargs: any     Additional keyword arguments.</p> <p>Returns:</p> Name Type Description <code>source</code> <code>SQLAlchemySource</code>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.execute","level":5,"title":"<code>execute(sql_query, params=None, *args, **kwargs)</code>","text":"<p>Executes a SQL query and returns the result as a DataFrame.</p> Arguments <p>sql_query : str     The SQL Query to execute params : list | dict | None     Parameters to use in the SQL query:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax     - None: No parameters args : list     Additional positional arguments to pass to the SQL query *kwargs : dict     Keyword arguments to pass to the SQL query</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.execute_async","level":5,"title":"<code>execute_async(sql_query, params=None, *args, **kwargs)</code>  <code>async</code>","text":"<p>Executes a SQL query asynchronously and returns the result as a DataFrame.</p> <p>This default implementation runs the synchronous execute() method in a thread to avoid blocking the event loop. Subclasses can override this method to provide truly asynchronous implementations.</p> Arguments <p>sql_query : str     The SQL Query to execute params : list | dict | None     Parameters to use in the SQL query:     - list: Positional parameters for placeholder (?) syntax     - dict: Named parameters for :name, %(name)s, etc. syntax     - None: No parameters args : list     Additional positional arguments to pass to the SQL query *kwargs : dict     Keyword arguments to pass to the SQL query</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.get","level":5,"title":"<code>get(table, **query)</code>","text":"<p>Retrieve data from a table with optional filtering.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.get_async","level":5,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Return a table asynchronously; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.get_schema","level":5,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"<p>Returns JSON schema describing the tables returned by the Source.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limits the number of rows considered for the schema calculation</p> <code>None</code> <code>shuffle</code> <code>bool</code> <p>Whether to shuffle rows when sampling</p> <code>False</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON schema(s) for one or all the tables.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/sources/#lumen.sources.sqlalchemy.SQLAlchemySource.get_tables","level":5,"title":"<code>get_tables()</code>","text":"<p>Return the list of available tables.</p>","path":["Reference","API","Sources"],"tags":[]},{"location":"reference/api/transforms/","level":1,"title":"Transforms","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms","level":2,"title":"<code>lumen.transforms</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base","level":3,"title":"<code>base</code>","text":"<p>The Transform components allow transforming tables in arbitrary ways.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DataFrame","level":4,"title":"<code>DataFrame = pd.DataFrame | dDataFrame</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Series","level":4,"title":"<code>Series = pd.Series | dSeries</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.pd_version","level":4,"title":"<code>pd_version = Version(pd.__version__)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate","level":4,"title":"<code>Aggregate</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Aggregate</code> one or more columns or indexes, see <code>pandas.DataFrame.groupby</code>.</p> <p><code>by</code> must be provided.</p> <p><code>df.groupby(&lt;by&gt;)[&lt;columns&gt;].&lt;method&gt;()[.reset_index()]</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.by","level":5,"title":"<code>by = param.ListSelector(doc='\\n        Columns or indexes to group by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.columns","level":5,"title":"<code>columns = param.ListSelector(allow_None=True, doc='\\n        Columns to aggregate.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.kwargs","level":5,"title":"<code>kwargs = param.Dict(default={}, doc='\\n        Keyword arguments to the aggregation method.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.method","level":5,"title":"<code>method = param.String(default='mean', doc='\\n        Name of the pandas aggregation method, e.g. max, min, count.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.transform_type","level":5,"title":"<code>transform_type = 'aggregate'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.with_index","level":5,"title":"<code>with_index = param.Boolean(default=True, doc='\\n        Whether to make the groupby columns indexes.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Aggregate.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Astype","level":4,"title":"<code>Astype</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Astype</code> transforms the type of one or more columns.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Astype.dtypes","level":5,"title":"<code>dtypes = param.Dict(doc='Mapping from column name to new type.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Astype.transform_type","level":5,"title":"<code>transform_type = 'as_type'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Astype.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Columns","level":4,"title":"<code>Columns</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Columns</code> selects a subset of columns.</p> <p><code>df[&lt;columns&gt;]</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Columns.columns","level":5,"title":"<code>columns = param.ListSelector(doc='\\n        The subset of columns to select.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Columns.transform_type","level":5,"title":"<code>transform_type = 'columns'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Columns.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Compute","level":4,"title":"<code>Compute</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Compute</code> turns a <code>dask.dataframe.DataFrame</code> into a <code>pandas.DataFrame</code>.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Compute.transform_type","level":5,"title":"<code>transform_type = 'compute'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Compute.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Corr","level":4,"title":"<code>Corr</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Corr</code> computes pairwise correlation of columns, excluding NA/null values.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Corr.method","level":5,"title":"<code>method = param.Selector(default='pearson', objects=['pearson', 'kendall', 'spearman'], doc='\\n        Method of correlation.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Corr.min_periods","level":5,"title":"<code>min_periods = param.Integer(default=1, doc='\\n        Minimum number of observations required per pair of columns\\n        to have a valid result. Currently only available for Pearson\\n        and Spearman correlation.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Corr.numeric_only","level":5,"title":"<code>numeric_only = param.Boolean(default=False, doc='\\n        Include only `float`, `int` or `boolean` data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Corr.transform_type","level":5,"title":"<code>transform_type = 'corr'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Corr.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Count","level":4,"title":"<code>Count</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Counts non-nan values in each column of the DataFrame and returns a new DataFrame with a single row with a count for each original column, see <code>pandas.DataFrame.count</code>.</p> <p>df.count(axis=, level=, numeric_only=).to_frame().T","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Count.axis","level":5,"title":"<code>axis = param.ClassSelector(default=0, class_=(int, str), doc=\"\\n        The axis to rename. 0 or 'index', 1 or 'columns'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Count.level","level":5,"title":"<code>level = param.ClassSelector(default=None, class_=(int, list, str), doc='\\n        The indexes to stack.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Count.numeric_only","level":5,"title":"<code>numeric_only = param.Boolean(default=False, doc='\\n        Include only float, int or boolean data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Count.transform_type","level":5,"title":"<code>transform_type = 'count'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Count.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA","level":4,"title":"<code>DropNA</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>DropNA</code> drops rows with any missing values.</p> <p><code>df.dropna(axis=&lt;axis&gt;, how=&lt;how&gt;, thresh=&lt;thresh&gt;, subset=&lt;subset&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA.axis","level":5,"title":"<code>axis = param.ClassSelector(default=0, class_=(int, str), doc=\"\\n        The axis to rename. 0 or 'index', 1 or 'columns'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA.how","level":5,"title":"<code>how = param.Selector(default='any', objects=['any', 'all'], doc='\\n        Determine if row or column is removed from DataFrame, when we have\\n        at least one NA or all NA.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA.subset","level":5,"title":"<code>subset = param.ListSelector(default=None, doc='\\n        Labels along other axis to consider, e.g. if you are dropping rows\\n        these would be a list of columns to include.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA.thresh","level":5,"title":"<code>thresh = param.Integer(default=None, doc='\\n        Require that many non-NA values.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA.transform_type","level":5,"title":"<code>transform_type = 'dropna'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.DropNA.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Eval","level":4,"title":"<code>Eval</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Applies an eval assignment expression to a DataFrame. The expression can reference columns on the original table by referencing <code>table.&lt;column&gt;</code> and must assign to a variable that will become a new column in the DataFrame, e.g. to divide a <code>value</code> column by one thousand and assign the result to a new column called <code>kilo_value</code> you can write an <code>expr</code> like:</p> <pre><code>kilo_value = table.value / 1000\n</code></pre> <p>See <code>pandas.eval</code> for more information.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Eval.expr","level":5,"title":"<code>expr = param.String(doc='\\n        The expression to apply to the table.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Eval.transform_type","level":5,"title":"<code>transform_type = 'eval'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Eval.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Filter","level":4,"title":"<code>Filter</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Filter</code> transform implement the filtering behavior of <code>Filter</code> components.</p> <p>The filter <code>conditions</code> must be declared as a list of tuple containing the name of the column to be filtered and one of the following:</p> <ul> <li>scalar: A scalar value will be matched using equality operators</li> <li>tuple:  A tuple value specifies a numeric or date range.</li> <li>list:   A list value specifies a set of categories to match against.</li> <li>list(tuple): A list of tuples specifies a list of ranges.</li> </ul>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Filter.conditions","level":5,"title":"<code>conditions = param.List(doc='\\n      List of filter conditions expressed as tuples of the column\\n      name and the filter value.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Filter.apply","level":5,"title":"<code>apply(df)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.HistoryTransform","level":4,"title":"<code>HistoryTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>HistoryTransform</code> accumulates a history of the queried data.</p> <p>The internal buffer accumulates data up to the supplied <code>length</code> and (optionally) adds a date_column to the data.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.HistoryTransform.date_column","level":5,"title":"<code>date_column = param.Selector(doc='\\n        If defined adds a date column with the supplied name.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.HistoryTransform.length","level":5,"title":"<code>length = param.Integer(default=10, bounds=(1, None), doc='\\n        Accumulates a history of data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.HistoryTransform.transform_type","level":5,"title":"<code>transform_type = 'history'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.HistoryTransform.apply","level":5,"title":"<code>apply(table)</code>","text":"<p>Accumulates a history of the data in a buffer up to the declared <code>length</code> and optionally adds the current datetime to the declared <code>date_column</code>.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> <p>The queried table as a DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the buffered history of the data.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Iloc","level":4,"title":"<code>Iloc</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Iloc</code> allows selecting the data with integer indexing, see <code>pandas.DataFrame.iloc</code>.</p> <p><code>df.iloc[&lt;start&gt;:&lt;end&gt;]</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Iloc.end","level":5,"title":"<code>end = param.Integer(default=None)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Iloc.start","level":5,"title":"<code>start = param.Integer(default=None)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Iloc.transform_type","level":5,"title":"<code>transform_type = 'iloc'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Iloc.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt","level":4,"title":"<code>Melt</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Melt</code> applies the <code>pandas.melt</code> operation given the <code>id_vars</code> and <code>value_vars</code>.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.id_vars","level":5,"title":"<code>id_vars = param.ListSelector(default=[], doc='\\n        Column(s) to use as identifier variables.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.ignore_index","level":5,"title":"<code>ignore_index = param.Boolean(default=True, doc='\\n        If True, original index is ignored. If False, the original\\n        index is retained. Index labels will be repeated as\\n        necessary.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.transform_type","level":5,"title":"<code>transform_type = 'melt'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.value_name","level":5,"title":"<code>value_name = param.String(default='value', doc=\"\\n         Name to use for the 'value' column.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.value_vars","level":5,"title":"<code>value_vars = param.ListSelector(default=None, doc='\\n        Column(s) to unpivot. If not specified, uses all columns that\\n        are not set as `id_vars`.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.var_name","level":5,"title":"<code>var_name = param.String(default=None, doc=\"\\n         Name to use for the 'variable' column. If None it uses\\n         ``frame.columns.name`` or 'variable'.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Melt.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Pivot","level":4,"title":"<code>Pivot</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Pivot</code> applies <code>pandas.DataFrame.pivot</code> given an index, columns, and values.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Pivot.columns","level":5,"title":"<code>columns = param.String(default=None, doc=\"\\n        Column to use to make new frame's columns.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Pivot.index","level":5,"title":"<code>index = param.String(default=None, doc=\"\\n        Column to use to make new frame's index.\\n        If None, uses existing index.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Pivot.transform_type","level":5,"title":"<code>transform_type = 'pivot'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Pivot.values","level":5,"title":"<code>values = param.ListSelector(default=None, doc=\"\\n        Column(s) to use for populating new frame's values.\\n        If not specified, all remaining columns will be used\\n        and the result will have hierarchically indexed columns.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Pivot.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.PivotTable","level":4,"title":"<code>PivotTable</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>PivotTable</code> applies pandas.pivot_table` to the data.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.PivotTable.aggfunc","level":5,"title":"<code>aggfunc = param.String(default='mean', doc=\"\\n        Function, list of functions, dict, default 'mean'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.PivotTable.columns","level":5,"title":"<code>columns = param.ListSelector(default=[], doc='\\n        Column, Grouper, array, or list of the previous\\n        Keys to group by on the pivot table column. If a list is passed,\\n        it can contain any of the other types (except list). If an array is\\n        passed, it must be the same length as the data and will be used in\\n        the same manner as column values.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.PivotTable.index","level":5,"title":"<code>index = param.ListSelector(default=[], doc='\\n        Column, Grouper, array, or list of the previous\\n        Keys to group by on the pivot table index. If a list is passed,\\n        it can contain any of the other types (except list). If an array is\\n        passed, it must be the same length as the data and will be used in\\n        the same manner as column values.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.PivotTable.values","level":5,"title":"<code>values = param.ListSelector(default=[], doc='\\n        Column or columns to aggregate.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.PivotTable.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Query","level":4,"title":"<code>Query</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Query</code> applies the <code>pandas.DataFrame.query</code> method.</p> <p><code>df.query(&lt;query&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Query.query","level":5,"title":"<code>query = param.String(doc='\\n        The query to apply to the table.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Query.transform_type","level":5,"title":"<code>transform_type = 'query'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Query.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename","level":4,"title":"<code>Rename</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Rename</code> renames columns or indexes, see <code>pandas.DataFrame.rename</code>.</p> <p>df.rename(mapper=, columns=, index=,           level=, axis=, copy=)","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.axis","level":5,"title":"<code>axis = param.ClassSelector(default=None, class_=(int, str), doc=\"\\n        The axis to rename. 0 or 'index', 1 or 'columns'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.columns","level":5,"title":"<code>columns = param.Dict(default=None, doc='\\n        Alternative to specifying axis (`mapper, axis=1` is equivalent to\\n        `columns=mapper`).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.copy","level":5,"title":"<code>copy = param.Boolean(default=False, doc='\\n        Also copy underlying data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.index","level":5,"title":"<code>index = param.Dict(default=None, doc='\\n        Alternative to specifying axis (`mapper, axis=0` is equivalent to\\n        `index=mapper`).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.level","level":5,"title":"<code>level = param.ClassSelector(default=None, class_=(int, str), doc='\\n        In case of a MultiIndex, only rename labels in the specified level.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.mapper","level":5,"title":"<code>mapper = param.Dict(default=None, doc=\"\\n        Dict to apply to that axis' values. Use either `mapper` and `axis` to\\n        specify the axis to target with `mapper`, or `index` and `columns`.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.transform_type","level":5,"title":"<code>transform_type = 'rename'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Rename.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis","level":4,"title":"<code>RenameAxis</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Set the name of the axis for the index or columns, see <code>pandas.DataFrame.rename_axis</code>.</p> <p>df.rename_axis(mapper=, columns=, index=,               axis=, copy=)","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.axis","level":5,"title":"<code>axis = param.ClassSelector(default=0, class_=(int, str), doc=\"\\n        The axis to rename. 0 or 'index', 1 or 'columns'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.columns","level":5,"title":"<code>columns = param.ClassSelector(default=None, class_=(str, list, dict), doc=\"\\n        A scalar, list-like, dict-like to apply to that axis' values.\\n        Note that the columns parameter is not allowed if the object\\n        is a Series. This parameter only apply for DataFrame type objects.\\n        Use either mapper and axis to specify the axis to target with\\n        mapper, or index and/or columns.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.copy","level":5,"title":"<code>copy = param.Boolean(default=True, doc='\\n        Also copy underlying data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.index","level":5,"title":"<code>index = param.ClassSelector(default=None, class_=(str, list, dict), doc=\"\\n        A scalar, list-like, dict-like to apply to that axis' values.\\n        Note that the columns parameter is not allowed if the object\\n        is a Series. This parameter only apply for DataFrame type objects.\\n        Use either mapper and axis to specify the axis to target with\\n        mapper, or index and/or columns.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.mapper","level":5,"title":"<code>mapper = param.ClassSelector(default=None, class_=(str, list), doc='\\n        Value to set the axis name attribute.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.transform_type","level":5,"title":"<code>transform_type = 'rename_axis'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.RenameAxis.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex","level":4,"title":"<code>ResetIndex</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>ResetIndex</code> resets DataFrame indexes to columns or drops them, see <code>pandas.DataFrame.reset_index</code></p> <p><code>df.reset_index(drop=&lt;drop&gt;, col_fill=&lt;col_fill&gt;, col_level=&lt;col_level&gt;, level=&lt;level&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex.col_fill","level":5,"title":"<code>col_fill = param.String(default='', doc='\\n        If the columns have multiple levels, determines how the other\\n        levels are named. If None then the index name is repeated.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex.col_level","level":5,"title":"<code>col_level = param.ClassSelector(default=0, class_=(int, str), doc='\\n        If the columns have multiple levels, determines which level the\\n        labels are inserted into. By default it is inserted into the\\n        first level.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex.drop","level":5,"title":"<code>drop = param.Boolean(default=False, doc='\\n        Do not try to insert index into dataframe columns. This resets\\n        the index to the default integer index.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex.level","level":5,"title":"<code>level = param.ClassSelector(default=None, class_=(int, str, list), doc='\\n        Only remove the given levels from the index. Removes all levels\\n        by default.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex.transform_type","level":5,"title":"<code>transform_type = 'reset_index'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.ResetIndex.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sample","level":4,"title":"<code>Sample</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Sample</code> returns a random sample of items.</p> <p><code>df.sample(n=&lt;n&gt;, frac=&lt;frac&gt;, replace=&lt;replace&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sample.frac","level":5,"title":"<code>frac = param.Number(default=None, bounds=(0, 1), doc='\\n        Fraction of axis items to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sample.n","level":5,"title":"<code>n = param.Integer(default=None, doc='\\n        Number of items to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sample.replace","level":5,"title":"<code>replace = param.Boolean(default=False, doc='\\n        Sample with or without replacement.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sample.transform_type","level":5,"title":"<code>transform_type = 'sample'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sample.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex","level":4,"title":"<code>SetIndex</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>SetIndex</code> promotes DataFrame columns to indexes, see <code>pandas.DataFrame.set_index</code>.</p> <p><code>df.set_index(&lt;keys&gt;, drop=&lt;drop&gt;, append=&lt;append&gt;, verify_integrity=&lt;verify_integrity&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex.append","level":5,"title":"<code>append = param.Boolean(default=False, doc='\\n        Whether to append columns to existing index.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex.drop","level":5,"title":"<code>drop = param.Boolean(default=True, doc='\\n        Delete columns to be used as the new index.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex.keys","level":5,"title":"<code>keys = param.ClassSelector(default=None, class_=(str, list), doc='\\n        This parameter can be either a single column key or a list\\n        containing column keys.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex.transform_type","level":5,"title":"<code>transform_type = 'set_index'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex.verify_integrity","level":5,"title":"<code>verify_integrity = param.Boolean(default=False, doc='\\n        Check the new index for duplicates. Otherwise defer the check\\n        until necessary. Setting to False will improve the performance\\n        of this method.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.SetIndex.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sort","level":4,"title":"<code>Sort</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Sort</code> on one or more columns, see <code>pandas.DataFrame.sort_values</code>.</p> <p><code>df.sort_values(&lt;by&gt;, ascending=&lt;ascending&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sort.ascending","level":5,"title":"<code>ascending = param.ClassSelector(default=True, class_=(bool, list), doc='\\n       Sort ascending vs. descending. Specify list for multiple sort\\n       orders. If this is a list of bools, must match the length of\\n       the by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sort.by","level":5,"title":"<code>by = param.ListSelector(default=[], doc='\\n       Columns or indexes to sort by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sort.transform_type","level":5,"title":"<code>transform_type = 'sort'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sort.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Stack","level":4,"title":"<code>Stack</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Stack</code> applies <code>pandas.DataFrame.stack</code> to the declared <code>level</code>.</p> <p><code>df.stack(&lt;level&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Stack.dropna","level":5,"title":"<code>dropna = param.Boolean(default=True, doc='\\n        Whether to drop rows in the resulting Frame/Series with missing values.\\n        Stacking a column level onto the index axis can create combinations of\\n        index and column values that are missing from the original\\n        dataframe.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Stack.level","level":5,"title":"<code>level = param.ClassSelector(default=(-1), class_=(int, list, str), doc='\\n        The indexes to stack.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Stack.transform_type","level":5,"title":"<code>transform_type = 'stack'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Stack.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sum","level":4,"title":"<code>Sum</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Sums numeric values in each column of the DataFrame and returns a new DataFrame with a single row containing the sum for each original column, see <code>pandas.DataFrame.sum</code>.</p> <p>df.count(axis=, level=).to_frame().T","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sum.axis","level":5,"title":"<code>axis = param.ClassSelector(default=0, class_=(int, str), doc=\"\\n        The axis to rename. 0 or 'index', 1 or 'columns'\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sum.level","level":5,"title":"<code>level = param.ClassSelector(default=None, class_=(int, list, str), doc='\\n        The indexes to stack.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sum.transform_type","level":5,"title":"<code>transform_type = 'sum'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Sum.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform","level":4,"title":"<code>Transform</code>","text":"<p>               Bases: <code>MultiTypeComponent</code></p> <p><code>Transform</code> components implement transforms of <code>DataFrame</code> objects.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform.control_panel","level":5,"title":"<code>control_panel</code>  <code>property</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform.controls","level":5,"title":"<code>controls = param.List(default=[], doc='\\n        Parameters that should be exposed as widgets in the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform.transform_type","level":5,"title":"<code>transform_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform.apply","level":5,"title":"<code>apply(table)</code>","text":"<p>Given a table transform it in some way and return it.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> <p>The queried table as a DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the transformed data.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform.apply_to","level":5,"title":"<code>apply_to(table, **kwargs)</code>  <code>classmethod</code>","text":"<p>Calls the apply method based on keyword arguments passed to define transform.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DataFrame</code> required <p>Returns:</p> Type Description <code>A DataFrame with the results of the transformation.</code>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Transform.from_spec","level":5,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"<p>Resolves a Transform specification.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict[str, Any] | str</code> <p>Specification declared as a dictionary of parameter values.</p> required <p>Returns:</p> Type Description <code>The resolved Transform object.</code>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Unstack","level":4,"title":"<code>Unstack</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>Unstack</code> applies <code>pandas.DataFrame.unstack</code> to the declared <code>level</code>.</p> <p><code>df.unstack(&lt;level&gt;)</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Unstack.fill_value","level":5,"title":"<code>fill_value = param.ClassSelector(default=None, class_=(int, str, dict), doc='\\n        Replace NaN with this value if the unstack produces missing values.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Unstack.level","level":5,"title":"<code>level = param.ClassSelector(default=(-1), class_=(int, list, str), doc='\\n        The indexes to unstack.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Unstack.transform_type","level":5,"title":"<code>transform_type = 'unstack'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.Unstack.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.project_lnglat","level":4,"title":"<code>project_lnglat</code>","text":"<p>               Bases: <code>Transform</code></p> <p><code>project_lnglat</code> projects the given longitude/latitude columns to Web Mercator.</p> <p>Converts latitude and longitude values into WGS84 (Web Mercator) coordinates (meters East of Greenwich and meters North of the Equator).</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.project_lnglat.latitude","level":5,"title":"<code>latitude = param.String(default='longitude', doc='Latitude column')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.project_lnglat.longitude","level":5,"title":"<code>longitude = param.String(default='longitude', doc='Longitude column')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.project_lnglat.transform_type","level":5,"title":"<code>transform_type = 'project_lnglat'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.base.project_lnglat.apply","level":5,"title":"<code>apply(table)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql","level":3,"title":"<code>sql</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLColumns","level":4,"title":"<code>SQLColumns</code>","text":"<p>               Bases: <code>SQLTransform</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLColumns.columns","level":5,"title":"<code>columns = param.List(default=[], doc='Columns to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLColumns.transform_type","level":5,"title":"<code>transform_type = 'sql_columns'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLColumns.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLCount","level":4,"title":"<code>SQLCount</code>","text":"<p>               Bases: <code>SQLTransform</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLCount.transform_type","level":5,"title":"<code>transform_type = 'sql_count'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLCount.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLDistinct","level":4,"title":"<code>SQLDistinct</code>","text":"<p>               Bases: <code>SQLTransform</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLDistinct.columns","level":5,"title":"<code>columns = param.List(default=[], doc='Columns to return distinct values for.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLDistinct.transform_type","level":5,"title":"<code>transform_type = 'sql_distinct'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLDistinct.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFilter","level":4,"title":"<code>SQLFilter</code>","text":"<p>               Bases: <code>SQLFilterBase</code></p> <p>Apply WHERE clause filtering to the entire query result.</p> <p>This transform wraps the input query in a subquery and applies filters to the result set.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFilter.conditions","level":5,"title":"<code>conditions = param.List(doc='\\n      List of filter conditions expressed as tuples of the column\\n      name and the filter value.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFilter.transform_type","level":5,"title":"<code>transform_type = 'sql_filter'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFilter.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFilterBase","level":4,"title":"<code>SQLFilterBase</code>","text":"<p>               Bases: <code>SQLTransform</code></p> <p>Base class for SQL filtering transforms that provides common filtering logic.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFormat","level":4,"title":"<code>SQLFormat</code>","text":"<p>               Bases: <code>SQLTransform</code></p> <p>Format SQL expressions with parameterized replacements.</p> <p>This transform allows for replacing placeholders in SQL queries using either Python string format-style placeholders {name} or sqlglot-style placeholders :name.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFormat.parameters","level":5,"title":"<code>parameters = param.Dict(default={}, doc='\\n        Dictionary of parameter names and values to replace in the SQL template.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFormat.transform_type","level":5,"title":"<code>transform_type = 'sql_format'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLFormat.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"<p>Apply the formatting to the input SQL, replacing placeholders with values.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> <p>The input SQL query to format. This is used as a base query that will have the formatted sql_expr applied to it, typically as a subquery.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The formatted SQL query with all placeholders replaced.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLGroupBy","level":4,"title":"<code>SQLGroupBy</code>","text":"<p>               Bases: <code>SQLTransform</code></p> <p>Performs a Group-By and aggregation</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLGroupBy.aggregates","level":5,"title":"<code>aggregates = param.Dict(doc='\\n        Mapping of aggregate functions to use to which column(s) to use them on,\\n        e.g. {\"AVG\": \"col1\", \"SUM\": [\"col1\", \"col2\"]}.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLGroupBy.by","level":5,"title":"<code>by = param.List(doc='Columns to group by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLGroupBy.transform_type","level":5,"title":"<code>transform_type = 'sql_group_by'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLGroupBy.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLLimit","level":4,"title":"<code>SQLLimit</code>","text":"<p>               Bases: <code>SQLTransform</code></p> <p>Performs a LIMIT SQL operation on the query. If the query already has a LIMIT clause, it will only be applied if the existing limit is less than the new limit.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLLimit.limit","level":5,"title":"<code>limit = param.Integer(default=1000, allow_None=True, doc='Limit on the number of rows to return')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLLimit.transform_type","level":5,"title":"<code>transform_type = 'sql_limit'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLLimit.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLMinMax","level":4,"title":"<code>SQLMinMax</code>","text":"<p>               Bases: <code>SQLTransform</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLMinMax.columns","level":5,"title":"<code>columns = param.List(default=[], doc='Columns to return min/max values for.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLMinMax.transform_type","level":5,"title":"<code>transform_type = 'sql_minmax'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLMinMax.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLOverride","level":4,"title":"<code>SQLOverride</code>","text":"<p>               Bases: <code>SQLTransform</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLOverride.override","level":5,"title":"<code>override = param.String()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLOverride.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLPreFilter","level":4,"title":"<code>SQLPreFilter</code>","text":"<p>               Bases: <code>SQLFilterBase</code></p> <p>Apply filtering conditions to source tables before executing the main query.</p> <p>This transform wraps source tables in subqueries with WHERE clauses, allowing filtering to be applied even when the main query doesn't select the filter columns.</p> <p>For example: Input: \"SELECT n_genes FROM obs\" With conditions: [(\"obs\", [(\"obs_id\", [\"cell1\", \"cell2\"])])] Output: \"SELECT n_genes FROM (SELECT * FROM obs WHERE obs_id IN ('cell1', 'cell2'))\"</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLPreFilter.conditions","level":5,"title":"<code>conditions = param.List(doc='\\n        List of filter conditions expressed as tuples of (table_name, filter_conditions)\\n        where filter_conditions is a list of (column_name, filter_value) tuples.\\n        Example: [(\"obs\", [(\"obs_id\", [\"cell1\", \"cell2\"])])]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLPreFilter.transform_type","level":5,"title":"<code>transform_type = 'sql_prefilter'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLPreFilter.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLRemoveSourceSeparator","level":4,"title":"<code>SQLRemoveSourceSeparator</code>","text":"<p>               Bases: <code>SQLTransform</code></p> <p>Class to exclude the source and separator.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLRemoveSourceSeparator.separator","level":5,"title":"<code>separator = param.String(default=SOURCE_TABLE_SEPARATOR, doc='\\n        Separator used to split the source and table name in the SQL query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLRemoveSourceSeparator.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"<p>Exclude the source and separator from the SQL query.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> <p>The initial SQL query to be manipulated.</p> required <p>Returns:</p> Type Description <code>string</code> <p>New SQL query derived from the above query.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample","level":4,"title":"<code>SQLSample</code>","text":"<p>               Bases: <code>SQLTransform</code></p> <p>Samples rows from a SQL query using TABLESAMPLE or similar functionality, depending on the dialect's support.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample.percent","level":5,"title":"<code>percent = param.Number(default=10.0, bounds=(0.0, 100.0), doc='\\n        percent of rows to sample. Must be between 0 and 100.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample.sample_kwargs","level":5,"title":"<code>sample_kwargs = param.Dict(default={}, doc='\\n        Other keyword arguments, like method, bucket_numerator, bucket_denominator, bucket_field.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample.seed","level":5,"title":"<code>seed = param.Integer(default=None, allow_None=True, doc='\\n        Random seed for reproducible sampling.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample.size","level":5,"title":"<code>size = param.Integer(default=None, allow_None=True, doc='\\n        Absolute number of rows to sample. If specified, takes precedence over percent.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample.transform_type","level":5,"title":"<code>transform_type = 'sql_sample'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSample.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSelectFrom","level":4,"title":"<code>SQLSelectFrom</code>","text":"<p>               Bases: <code>SQLFormat</code></p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSelectFrom.sql_expr","level":5,"title":"<code>sql_expr = param.String(default='SELECT * FROM {table}', doc='\\n        The SQL expression to use if the sql_in does NOT\\n        already contain a SELECT statement.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSelectFrom.tables","level":5,"title":"<code>tables = param.ClassSelector(default=None, class_=(list, dict), doc='\\n        Dictionary of tables to replace or use in the SQL expression.\\n        If None, the original table will be used.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSelectFrom.transform_type","level":5,"title":"<code>transform_type = 'sql_select_from'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLSelectFrom.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform","level":4,"title":"<code>SQLTransform</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Base class for SQL transforms using sqlglot.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.comments","level":5,"title":"<code>comments = param.Boolean(default=False, doc='Whether to include comments in the output SQL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.error_level","level":5,"title":"<code>error_level = param.ClassSelector(class_=(sqlglot.ErrorLevel), default=(sqlglot.ErrorLevel.RAISE), doc='Error level for parsing')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.identify","level":5,"title":"<code>identify = param.Boolean(default=False, doc='\\n        Delimit all identifiers, e.g. turn `FROM database.table` into `FROM \"database\".\"table\"`.\\n        This is useful for dialects that don\\'t support unquoted identifiers.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.optimize","level":5,"title":"<code>optimize = param.Boolean(default=False, doc=\"\\n        Whether to optimize the generated SQL query; may produce invalid results, especially with\\n        duckdb's read_* functions.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.pretty","level":5,"title":"<code>pretty = param.Boolean(default=False, doc='Prettify output SQL, i.e. add newlines and indentation')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.read","level":5,"title":"<code>read = param.String(default=None, doc='Source dialect for parsing; if None, automatically detects')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.unsupported_level","level":5,"title":"<code>unsupported_level = param.ClassSelector(class_=(sqlglot.ErrorLevel), default=(sqlglot.ErrorLevel.WARN), doc='When using `to_sql`, how to handle unsupported dialect features.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.write","level":5,"title":"<code>write = param.String(default=None, doc='Target dialect for output; if None, defaults to read dialect')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.apply","level":5,"title":"<code>apply(sql_in)</code>","text":"<p>Given an SQL statement, manipulate it, and return a new SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> <p>The initial SQL query to be manipulated.</p> required <p>Returns:</p> Type Description <code>string</code> <p>New SQL query derived from the above query.</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.apply_to","level":5,"title":"<code>apply_to(sql_in, **kwargs)</code>  <code>classmethod</code>","text":"<p>Calls the apply method based on keyword arguments passed to define transform.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> required <p>Returns:</p> Type Description <code>SQL statement after application of transformation.</code>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.parse_sql","level":5,"title":"<code>parse_sql(sql_in)</code>","text":"<p>Parse SQL string into sqlglot AST.</p> <p>Parameters:</p> Name Type Description Default <code>sql_in</code> <code>str</code> <p>SQL string to parse</p> required <p>Returns:</p> Type Description <code>Expression</code> <p>Parsed SQL expression</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/transforms/#lumen.transforms.sql.SQLTransform.to_sql","level":5,"title":"<code>to_sql(expression)</code>","text":"<p>Convert sqlglot expression back to SQL string.</p> <p>Parameters:</p> Name Type Description Default <code>expression</code> <code>Expression</code> <p>Expression to convert to SQL</p> required <p>Returns:</p> Type Description <code>string</code> <p>SQL string representation</p>","path":["Reference","API","Transforms"],"tags":[]},{"location":"reference/api/views/","level":1,"title":"Views","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views","level":2,"title":"<code>lumen.views</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base","level":3,"title":"<code>base</code>","text":"<p>The View classes render the data returned by a Pipeline as a Panel object.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DOWNLOAD_FORMATS","level":4,"title":"<code>DOWNLOAD_FORMATS = ['csv', 'xlsx', 'json', 'parquet']</code>  <code>module-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView","level":4,"title":"<code>AltairView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>AltairView</code> provides a declarative way to render Altair charts.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.chart","level":5,"title":"<code>chart = param.Dict(default={}, doc='Keyword argument for Chart.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.encode","level":5,"title":"<code>encode = param.Dict(default={}, doc='Keyword arguments for encode.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.mark","level":5,"title":"<code>mark = param.Dict(default={}, doc='Keyword arguments for mark.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.marker","level":5,"title":"<code>marker = param.Selector(default='line', objects=['area', 'bar', 'boxplot', 'circle', 'errorband', 'errorbar', 'geoshape', 'image', 'line', 'point', 'rect', 'rule', 'square', 'text', 'tick', 'trail'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.project","level":5,"title":"<code>project = param.Dict(doc='Keyword arguments for project.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.properties","level":5,"title":"<code>properties = param.Dict(doc='Keyword arguments for properties.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.transform","level":5,"title":"<code>transform = param.Dict(doc=\"\\n        Keyword arguments for transforms, nested by the type of\\n        transform, e.g. {'bin': {'as_': 'binned', 'field': 'x'}}.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.view_type","level":5,"title":"<code>view_type = 'altair'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.x","level":5,"title":"<code>x = param.Selector(doc='The column to render on the x-axis.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.y","level":5,"title":"<code>y = param.Selector(doc='The column to render on the y-axis.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.AltairView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DeckGLView","level":4,"title":"<code>DeckGLView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>DeckGLView</code> renders geographic data as 3D visualizations using deck.gl.</p> <p>Supports various layer types including ScatterplotLayer, HexagonLayer, ArcLayer, and more for visualizing geospatial data with latitude/longitude coordinates.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DeckGLView.spec","level":5,"title":"<code>spec = param.Dict(doc='\\n        The deck.gl JSON specification containing layers, viewState, and mapStyle.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DeckGLView.tooltips","level":5,"title":"<code>tooltips = param.ClassSelector(class_=(bool, dict), default=True, doc='\\n        Whether to enable tooltips on hover. Can be True for auto-generated\\n        tooltips, False to disable, or a dict specifying tooltip configuration.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DeckGLView.view_type","level":5,"title":"<code>view_type = 'deckgl'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DeckGLView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView","level":4,"title":"<code>DownloadView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>DownloadView</code> renders a button that allows downloading data as CSV, Excel, and parquet files.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView.filename","level":5,"title":"<code>filename = param.String(default='data', doc='\\n      Filename of the downloaded file.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView.format","level":5,"title":"<code>format = param.Selector(default=None, objects=DOWNLOAD_FORMATS, doc='\\n      The format to download the data in.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView.icon","level":5,"title":"<code>icon = param.String(default='file-spreadsheet', doc='\\n      Icon to show on the button.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView.kwargs","level":5,"title":"<code>kwargs = param.Dict(default={}, doc='\\n      Keyword arguments passed to the serialization function, e.g.\\n      data.to_csv(file_obj, **kwargs).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView.view_type","level":5,"title":"<code>view_type = 'download'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.DownloadView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker","level":4,"title":"<code>GraphicWalker</code>","text":"<p>               Bases: <code>View</code></p> <p>Renders the data using the GraphicWalker panel extension.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker.ignore_limit","level":5,"title":"<code>ignore_limit = param.Boolean(default=False, doc='\\n        Ignore any SQLLimit transform defined on the input pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker.kernel_computation","level":5,"title":"<code>kernel_computation = param.Boolean(default=False, doc=\"If True the computations will take place on the server or in the Jupyter kernel\\n        instead of the client to scale to larger datasets. Default is False. In Pyodide this will\\n        always be set to False. The 'chart' renderer will only work with client side rendering.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker.renderer","level":5,"title":"<code>renderer = param.Selector(default='profiler', objects=['explorer', 'profiler', 'viewer', 'chart'], doc=\"How to display the data. One of 'explorer' (default), 'profiler,\\n        'viewer' or 'chart'.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker.tab","level":5,"title":"<code>tab = param.Selector(default='data', objects=['data', 'vis'], doc=\"Set the active tab to 'data' or 'vis' (default). Only applicable for the 'explorer' renderer. Not bi-directionally synced with client.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker.view_type","level":5,"title":"<code>view_type = 'graphic_walker'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.GraphicWalker.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews","level":4,"title":"<code>HoloViews</code>","text":"<p>               Bases: <code>View</code></p> <p><code>HoloViews</code> renders the data as a HoloViews plot.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews.object","level":5,"title":"<code>object = param.Parameter()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews.streaming","level":5,"title":"<code>streaming = param.Boolean(default=False, doc='\\n        Whether to stream new data to the plot or rerender the plot.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews.view_type","level":5,"title":"<code>view_type = 'holoviews'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews.from_spec","level":5,"title":"<code>from_spec(spec, source=None, filters=None, pipeline=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.HoloViews.to_spec","level":5,"title":"<code>to_spec(context=None)</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.IndicatorView","level":4,"title":"<code>IndicatorView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>IndicatorView</code> renders the latest field value as a Panel <code>Indicator</code>.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.IndicatorView.indicator","level":5,"title":"<code>indicator = param.Selector(objects=_INDICATORS, doc='\\n        The name of the panel Indicator type.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.IndicatorView.label","level":5,"title":"<code>label = param.String(doc='\\n        A custom label to use for the Indicator.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.IndicatorView.view_type","level":5,"title":"<code>view_type = 'indicator'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.IndicatorView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Panel","level":4,"title":"<code>Panel</code>","text":"<p>               Bases: <code>View</code></p> <p><code>Panel</code> views provide a way to declaratively wrap a Panel component.</p> <p>The <code>Panel</code> View is a very general purpose view that allows expressing arbitrary Panel objects as a specification. The Panel specification may be arbitrarily nested making it possible to specify entire layouts.  Additionally the Panel specification also supports references, including standard source and variable references and a custom <code>$data</code> reference that inserts the current data of the <code>View</code>.</p> <pre><code>type: panel\n  spec:\n   type: panel.layout.Column\n   objects:\n     - type: pn.pane.Markdown\n       object: '# My custom title'\n     - type: pn.pane.DataFrame\n       object: $data\n</code></pre>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Panel.object","level":5,"title":"<code>object = Child()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Panel.view_type","level":5,"title":"<code>view_type = 'panel'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Panel.from_spec","level":5,"title":"<code>from_spec(spec, source=None, filters=None, pipeline=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Panel.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Panel.to_spec","level":5,"title":"<code>to_spec(context=None)</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView","level":4,"title":"<code>PerspectiveView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>PerspectiveView</code> renders data into a Perspective widget.</p> <p>See https://panel.holoviz.org/reference/panes/Perspective.html for more details.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.aggregates","level":5,"title":"<code>aggregates = param.Dict(None, allow_None=True, doc='\\n        How to aggregate. For example {x: \"distinct count\"}')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.column_pivots","level":5,"title":"<code>column_pivots = param.ListSelector(None, allow_None=True, doc='\\n        A list of source columns to pivot by. For example [\"x\", \"y\"]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.columns","level":5,"title":"<code>columns = param.ListSelector(default=None, allow_None=True, doc='\\n        A list of source columns to show as columns. For example [\"x\", \"y\"]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.computed_columns","level":5,"title":"<code>computed_columns = param.ListSelector(default=None, allow_None=True, doc='\\n        A list of computed columns. For example [\"\"x\"+\"index\"\"]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.filters","level":5,"title":"<code>filters = param.List(default=None, allow_None=True, doc='\\n        How to filter. For example [[\"x\", \"&lt;\", 3],[\"y\", \"contains\", \"abc\"]]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.plugin","level":5,"title":"<code>plugin = param.Selector(default=(_PerspectivePlugin.GRID.value), objects=(_PerspectivePlugin.options()), doc='\\n        The name of a plugin to display the data. For example hypergrid or d3_xy_scatter.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.row_pivots","level":5,"title":"<code>row_pivots = param.ListSelector(default=None, allow_None=True, doc='\\n        A list of source columns to group by. For example [\"x\", \"y\"]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.selectable","level":5,"title":"<code>selectable = param.Boolean(default=True, allow_None=True, doc='\\n        Whether items are selectable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.sort","level":5,"title":"<code>sort = param.List(default=None, doc='\\n        How to sort. For example[[\"x\",\"desc\"]]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.theme","level":5,"title":"<code>theme = param.Selector(default='material', objects=_PERSPECTIVE_THEMES, doc='\\n        The style of the PerspectiveViewer. For example material-dark')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.view_type","level":5,"title":"<code>view_type = 'perspective'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.PerspectiveView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.StringView","level":4,"title":"<code>StringView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>StringView</code> renders the latest value of the field as a HTML string.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.StringView.font_size","level":5,"title":"<code>font_size = param.String(default='24pt', doc='\\n        The font size of the rendered field value.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.StringView.view_type","level":5,"title":"<code>view_type = 'string'</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.StringView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Table","level":4,"title":"<code>Table</code>","text":"<p>               Bases: <code>View</code></p> <p><code>Table</code> renders data using the powerful Panel <code>Tabulator</code> component.</p> <p>See https://panel.holoviz.org/reference/widgets/Tabulator.html</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Table.page_size","level":5,"title":"<code>page_size = param.Integer(default=None, doc='\\n        Number of rows to render per page, if pagination is enabled.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Table.view_type","level":5,"title":"<code>view_type = 'table'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.Table.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.VegaLiteView","level":4,"title":"<code>VegaLiteView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>VegaLite</code> provides a declarative way to render vega-lite charts.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.VegaLiteView.spec","level":5,"title":"<code>spec = param.Dict()</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.VegaLiteView.view_type","level":5,"title":"<code>view_type = 'vegalite'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.VegaLiteView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View","level":4,"title":"<code>View</code>","text":"<p>               Bases: <code>MultiTypeComponent</code>, <code>Viewer</code></p> <p><code>View</code> components provide a visual representation for the data returned by a :class:<code>lumen.source.base.Source</code> or :class:<code>lumen.pipeline.Pipeline</code>.</p> <p>The <code>View</code> must return a Panel object or an object that can be rendered by Panel. The base class provides methods which query the the provided :class:<code>lumen.pipeline.Pipeline</code>.</p> <p>Subclasses should use these methods to query the data and return a Viewable Panel object in the <code>get_panel</code> method.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.control_panel","level":5,"title":"<code>control_panel</code>  <code>property</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.controls","level":5,"title":"<code>controls = param.List(default=[], doc='\\n        Parameters that should be exposed as widgets in the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.download","level":5,"title":"<code>download = param.ClassSelector(class_=Download, default=(Download()), doc='\\n        The download objects determines whether and how the source tables\\n        can be downloaded.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.field","level":5,"title":"<code>field = param.Selector(doc='The field being visualized.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.kwargs","level":5,"title":"<code>kwargs = {k: v for k, v in (params.items()) if k not in self.param}</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.limit","level":5,"title":"<code>limit = param.Integer(default=None, bounds=(0, None), doc='\\n        Limits the number of rows that are rendered.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.loading_indicator","level":5,"title":"<code>loading_indicator = param.Boolean(default=True, constant=True, doc='\\n        Whether to display a loading indicator on the View when the\\n        Pipeline is refreshing the data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.panel","level":5,"title":"<code>panel</code>  <code>property</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.pipeline","level":5,"title":"<code>pipeline = param.ClassSelector(class_=Pipeline, doc='\\n        The data pipeline that drives the View.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.rerender","level":5,"title":"<code>rerender = param.Event(default=False, doc='\\n        An event that is triggered whenever the View requests a re-render.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.selection_group","level":5,"title":"<code>selection_group = param.String(default=None, doc='\\n        Declares a selection group the plot is part of. This feature\\n        requires the separate HoloViews library.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.title","level":5,"title":"<code>title = param.String(default=None, doc='\\n        The title of the view.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.view_type","level":5,"title":"<code>view_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.from_spec","level":5,"title":"<code>from_spec(spec, source=None, filters=None, pipeline=None)</code>  <code>classmethod</code>","text":"<p>Resolves a View specification given the schema of the Source it will be filtering on.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict[str, Any] | str</code> <p>Specification declared as a dictionary of parameter values.</p> required <code>source</code> <p>The Source object containing the tables the View renders.</p> <code>None</code> <code>filters</code> <p>A list of Filter objects which provide query values for the Source.</p> <code>None</code> <code>pipeline</code> <p>The Lumen pipeline driving this View. Must not be supplied if the spec contains a pipeline definition or reference.</p> <code>None</code> <p>Returns:</p> Type Description <code>The resolved View object.</code>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.get_data","level":5,"title":"<code>get_data()</code>","text":"<p>Queries the Source for the specified table applying any filters and transformations specified on the View. Unlike <code>get_value</code> this should be used when multiple return values are expected.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The queried table after filtering and transformations are applied.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.get_panel","level":5,"title":"<code>get_panel()</code>","text":"<p>Constructs and returns a Panel object which will represent a view of the queried table.</p> <p>Returns:</p> Type Description <code>Viewable</code> <p>A Panel Viewable object representing a current representation of the queried table.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.get_value","level":5,"title":"<code>get_value(field=None)</code>","text":"<p>Queries the Source for the data associated with a particular field applying any filters and transformations specified on the View. Unlike <code>get_data</code> this method returns a single scalar value associated with the field and should therefore only be used if only a single.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str | None</code> <p>The field from the table to return; if None uses field defined on the View.</p> <code>None</code> <p>Returns:</p> Type Description <code>object</code> <p>A single scalar value representing the current value of the queried field.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.to_spec","level":5,"title":"<code>to_spec(context=None)</code>","text":"<p>Exports the full specification to reconstruct this component.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>dict[str, Any] | None</code> <p>Context contains the specification of all previously serialized components, e.g. to allow resolving of references.</p> <code>None</code> <p>Returns:</p> Type Description <code>Declarative specification of this component.</code>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.View.update","level":5,"title":"<code>update(*events, invalidate_cache=True)</code>","text":"<p>Triggers an update in the View.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <code>Event</code> <p>param events that may trigger an update.</p> <code>()</code> <code>invalidate_cache</code> <code>bool</code> <p>Whether to clear the View's cache.</p> <code>True</code>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.YdataProfilingView","level":4,"title":"<code>YdataProfilingView</code>","text":"<p>               Bases: <code>View</code></p> <p>A View that renders a ydata_profiling ProfileReport.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.YdataProfilingView.view_type","level":5,"title":"<code>view_type = 'ydata_profiling'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.YdataProfilingView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvOverlayView","level":4,"title":"<code>hvOverlayView</code>","text":"<p>               Bases: <code>View</code></p> <p><code>hvOverlayView</code> allows overlaying a list of layers consisting of <code>hvPlotView</code> components.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvOverlayView.layers","level":5,"title":"<code>layers = param.List(item_type=hvPlotView)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvOverlayView.view_type","level":5,"title":"<code>view_type = 'hv_overlay'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvOverlayView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView","level":4,"title":"<code>hvPlotBaseView</code>","text":"<p>               Bases: <code>View</code></p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView.by","level":5,"title":"<code>by = param.ListSelector(doc='The column(s) to facet the plot by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView.geo","level":5,"title":"<code>geo = param.Boolean(default=False, doc='Toggle True if the plot is on a geographic map.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView.groupby","level":5,"title":"<code>groupby = param.ListSelector(doc='The column(s) to group by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView.kind","level":5,"title":"<code>kind = param.Selector(default=None, doc=\"The kind of plot, e.g. 'scatter' or 'line'.\", objects=['area', 'bar', 'barh', 'bivariate', 'box', 'contour', 'contourf', 'errorbars', 'hist', 'image', 'kde', 'labels', 'line', 'scatter', 'heatmap', 'hexbin', 'ohlc', 'points', 'step', 'violin'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView.x","level":5,"title":"<code>x = param.Selector(doc='The column to render on the x-axis.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotBaseView.y","level":5,"title":"<code>y = param.Selector(doc='The column to render on the y-axis.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotUIView","level":4,"title":"<code>hvPlotUIView</code>","text":"<p>               Bases: <code>hvPlotBaseView</code></p> <p><code>hvPlotUIView</code> displays provides a component for exploring datasets interactively.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotUIView.view_type","level":5,"title":"<code>view_type = 'hvplot_ui'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotUIView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView","level":4,"title":"<code>hvPlotView</code>","text":"<p>               Bases: <code>hvPlotBaseView</code></p> <p><code>hvPlotView</code> renders the queried data as a bokeh plot generated with hvPlot.</p> <p>hvPlot allows for a concise but powerful declaration of a plot via its simple API.</p>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.operations","level":5,"title":"<code>operations = param.List(item_type=(param.ParameterizedFunction), doc='\\n        Operations to apply to HoloViews plot.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.opts","level":5,"title":"<code>opts = param.Dict(default={}, doc='HoloViews options to apply on the plot.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.selection_expr","level":5,"title":"<code>selection_expr = param.Parameter(doc='\\n        A selection expression caputirng the current selection applied\\n        on the plot.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.streaming","level":5,"title":"<code>streaming = param.Boolean(default=False, doc='\\n        Whether to stream new data to the plot or rerender the plot.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.view_type","level":5,"title":"<code>view_type = 'hvplot'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.get_panel","level":5,"title":"<code>get_panel()</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.get_plot","level":5,"title":"<code>get_plot(df)</code>","text":"","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/views/#lumen.views.base.hvPlotView.update","level":5,"title":"<code>update(*events, invalidate_cache=True)</code>","text":"<p>Triggers an update in the View.</p> <p>Parameters:</p> Name Type Description Default <code>events</code> <p>param events that may trigger an update.</p> <code>()</code> <code>invalidate_cache</code> <code>bool</code> <p>Whether to clear the View's cache.</p> <code>True</code>","path":["Reference","API","Views"],"tags":[]},{"location":"reference/api/ai/agents/","level":1,"title":"AI Agents","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents","level":2,"title":"<code>lumen.ai.agents</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.__all__","level":3,"title":"<code>__all__ = ['Agent', 'AnalysisAgent', 'BaseCodeAgent', 'ChatAgent', 'DbtslAgent', 'DeckGLAgent', 'DocumentListAgent', 'hvPlotAgent', 'SQLAgent', 'TableListAgent', 'ValidationAgent', 'VegaLiteAgent']</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent","level":3,"title":"<code>Agent</code>","text":"<p>               Bases: <code>Viewer</code>, <code>ToolUser</code>, <code>ContextProvider</code></p> <p>Agents are actors responsible for taking a user query and performing a particular task, either by adding context or generating outputs.</p> <p>Agents have access to an LLM and are given context and can solve tasks by executing a series of prompts or by rendering contents such as forms or widgets to gather user input.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent.agents","level":4,"title":"<code>agents = param.List(doc='\\n        List of agents this agent can invoke.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent.debug","level":4,"title":"<code>debug = param.Boolean(default=False, doc='\\n        Whether to enable verbose error reporting.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent.llm","level":4,"title":"<code>llm = param.ClassSelector(class_=Llm, doc='\\n        The LLM implementation to query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent.user","level":4,"title":"<code>user = param.String(default='Agent', doc='\\n        The name of the user that will be respond to the user query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent.applies","level":4,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Additional checks to determine if the agent should be used.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.Agent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Provides a response to the user query.</p> <p>The type of the response may be a simple string or an object.</p> Arguments <p>messages: list[Message]     The list of messages corresponding to the user query and any other     system messages to be included. context: TContext     A mapping containing context for the agent to perform its task. step_title: str | None     If the Agent response is part of a longer query this describes     the step currently being processed.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent","level":3,"title":"<code>AnalysisAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.analyses","level":4,"title":"<code>analyses = param.List([])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use for custom analysis, advanced analytics, or domain-specific methods', \"Use when the user query matches one of the available analyses' name or description below.\", \"Include the selected analysis' required cols in the instructions\", 'NOT for simple queries or basic visualizations'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.input_schema","level":4,"title":"<code>input_schema = AnalysisInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.output_schema","level":4,"title":"<code>output_schema = AnalysisOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'AnalysisAgent' / 'main.jinja2', 'response_model': make_analysis_model}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.purpose","level":4,"title":"<code>purpose = param.String(default='Perform custom analyses that are reliable and repeatable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.AnalysisAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.BaseCodeAgent","level":3,"title":"<code>BaseCodeAgent</code>","text":"<p>               Bases: <code>BaseViewAgent</code></p> <p>Base class for view agents that can generate and execute code.</p> <p>Subclasses must: - Set <code>_executor_class</code> to the appropriate CodeExecutor subclass - Implement <code>_generate_code_spec()</code> for their specific code generation flow</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.BaseCodeAgent.code_execution","level":4,"title":"<code>code_execution = param.Selector(default='disabled', objects=['disabled', 'prompt', 'llm', 'allow'], doc=\"\\n        Code execution mode for generating visualizations via code:\\n        - disabled: No code execution; generate declarative specs only (safe for production)\\n        - prompt: Generate code, prompt user for permission to execute\\n        - llm: Generate code, validate with LLM safety check, then execute\\n        - allow: Generate and execute code without user confirmation\\n\\n        ‚ö†Ô∏è WARNING: The 'prompt', 'llm', and 'allow' modes execute LLM-generated code and\\n        must NEVER be enabled in production environments with access to secrets, credentials,\\n        or sensitive data.\\n        \", allow_refs=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.BaseCodeAgent.code_execution_enabled","level":4,"title":"<code>code_execution_enabled</code>  <code>property</code>","text":"<p>Whether code execution is enabled (any mode except 'disabled').</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ChatAgent","level":3,"title":"<code>ChatAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>ChatAgent provides general information about available data and other topics to the user. When data is available, it acts as an analyst providing insights and interpretations.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ChatAgent.conditions","level":4,"title":"<code>conditions = param.List(default=[\"Use for general conversation that doesn't require fetching or querying data\", 'Use for technical questions about programming, functions, methods, libraries, or APIs', \"Use when user asks to 'explain', 'interpret', 'analyze', 'summarize', or 'comment on' existing data in context\", \"NOT when user asks to 'show', 'get', 'fetch', 'query', 'filter', 'calculate', 'aggregate', or 'transform' data\", 'NOT for creating new data transformations - only for explaining data that already exists'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ChatAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'ChatAgent' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ChatAgent.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Provides conversational assistance and interprets existing results.\\n        Handles general questions, technical documentation, and programming help.\\n        When data has been retrieved, explains findings in accessible terms.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ChatAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent","level":3,"title":"<code>DbtslAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code>, <code>DbtslMixin</code></p> <p>Responsible for creating and executing queries against a dbt Semantic Layer to answer user questions about business metrics.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Always use this when dbtsl_metaset is available'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.output_schema","level":4,"title":"<code>output_schema = DbtslOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'response_model': DbtslQueryParams, 'template': PROMPTS_DIR / 'DbtslAgent' / 'main.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'BaseLumenAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Responsible for displaying data to answer user queries about\\n        business metrics using dbt Semantic Layers. This agent can compile\\n        and execute metric queries against a dbt Semantic Layer.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.requires","level":4,"title":"<code>requires = param.List(default=['source', 'dbtsl_metaset'], readonly=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.source","level":4,"title":"<code>source = param.ClassSelector(class_=BaseSQLSource, doc='\\n        The source associated with the dbt Semantic Layer.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.user","level":4,"title":"<code>user = param.String(default='DBT')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DbtslAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Responds to user messages by generating and executing a dbt Semantic Layer query.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent","level":3,"title":"<code>DeckGLAgent</code>","text":"<p>               Bases: <code>BaseCodeAgent</code></p> <p>Agent for generating DeckGL 3D map visualizations.</p> <p>Supports two generation modes: - When code_execution is 'disabled': Generate DeckGL JSON specs directly - When code_execution is enabled: Generate PyDeck Python code, execute safely, convert to spec</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use for 3D geographic visualizations, map-based data, or when user requests DeckGL/deck.gl', 'Use for large-scale geospatial data with latitude/longitude coordinates', 'Use for hexbin aggregations, heatmaps, or 3D extruded visualizations on maps'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.default_map_style","level":4,"title":"<code>default_map_style = 'https://basemaps.cartocdn.com/gl/dark-matter-gl-style/style.json'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'response_model': DeckGLSpec, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'main.jinja2'}, 'main_pydeck': {'response_model': PyDeckSpec, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'main_pydeck.jinja2'}, 'code_safety': {'response_model': CodeSafetyCheck, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'code_safety.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.purpose","level":4,"title":"<code>purpose = param.String(default='Generates DeckGL 3D map visualizations from geographic data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.user","level":4,"title":"<code>user = param.String(default='DeckGL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.view_type","level":4,"title":"<code>view_type = DeckGLView</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DeckGLAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Generate a DeckGL visualization.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DocumentListAgent","level":3,"title":"<code>DocumentListAgent</code>","text":"<p>               Bases: <code>BaseListAgent</code></p> <p>The DocumentListAgent lists all available documents provided by the user.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DocumentListAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use when user asks to list or see all available documents', 'NOT when user asks about specific document content'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DocumentListAgent.input_schema","level":4,"title":"<code>input_schema = DocumentListInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DocumentListAgent.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Displays a list of all available documents.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.DocumentListAgent.applies","level":4,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent","level":3,"title":"<code>SQLAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use for querying, filtering, aggregating, or transforming data with SQL', \"Use for calculations that require executing SQL (e.g., 'calculate average', 'sum by category')\", \"Use when user asks to 'show', 'get', 'fetch', 'query', 'find', 'filter', 'calculate', 'aggregate', or 'transform' data\", \"NOT when user asks to 'explain', 'interpret', 'analyze', 'summarize', or 'comment on' existing data\", 'NOT useful if the user is using the same data for plotting'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.exclusions","level":4,"title":"<code>exclusions = param.List(default=['dbtsl_metaset'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.exploration_enabled","level":4,"title":"<code>exploration_enabled = param.Boolean(default=True, allow_refs=True, doc='\\n        Whether to enable SQL exploration mode. When False, only attempts oneshot SQL generation.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.input_schema","level":4,"title":"<code>input_schema = SQLInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.not_with","level":4,"title":"<code>not_with = param.List(default=['DbtslAgent', 'MetadataLookup', 'TableListAgent'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.output_schema","level":4,"title":"<code>output_schema = SQLEditors</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'response_model': make_sql_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'main.jinja2'}, 'select_tables': {'response_model': make_table_selection_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'select_tables.jinja2'}, 'select_discoveries': {'response_model': make_discovery_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'select_discoveries.jinja2'}, 'check_sufficiency': {'response_model': make_discovery_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'check_sufficiency.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'SQLAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Creates and executes SQL queries to retrieve, filter, aggregate, or transform data.\\n        Handles table joins, WHERE clauses, GROUP BY, calculations, and other SQL operations.\\n        Generates new data pipelines from SQL transformations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.user","level":4,"title":"<code>user = param.String(default='SQL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Execute SQL generation with table selection, then one-shot attempt, then exploration if needed.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.SQLAgent.revise","level":4,"title":"<code>revise(feedback, messages, context, view=None, spec=None, language=None, errors=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.TableListAgent","level":3,"title":"<code>TableListAgent</code>","text":"<p>               Bases: <code>BaseListAgent</code></p> <p>The TableListAgent lists all available data and lets the user pick one.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.TableListAgent.conditions","level":4,"title":"<code>conditions = param.List(default=[\"Use when user explicitly asks to 'list data', 'show available data', or 'what data do you have'\", 'NOT for showing actual data contents, querying, or analyzing data', 'NOT for describing data sources or telling what the data is about'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.TableListAgent.input_schema","level":4,"title":"<code>input_schema = TableListInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.TableListAgent.not_with","level":4,"title":"<code>not_with = param.List(default=['DbtslAgent', 'SQLAgent'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.TableListAgent.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Displays a list of all available data &amp; datasets. Not useful for identifying which dataset to use for analysis.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.TableListAgent.applies","level":4,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent","level":3,"title":"<code>ValidationAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>ValidationAgent focuses solely on validating whether the executed plan fully answered the user's original query. It identifies missing elements and suggests next steps when validation fails.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use to validate whether executed plans fully answered user queries', 'Use to identify missing elements from the original user request', 'NOT for data analysis, pattern identification, or technical programming questions'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent.input_schema","level":4,"title":"<code>input_schema = ValidationInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent.output_schema","level":4,"title":"<code>output_schema = ValidationOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'ValidationAgent' / 'main.jinja2', 'response_model': QueryCompletionValidation, 'tools': []}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent.purpose","level":4,"title":"<code>purpose = param.String(default=\"\\n        Validates whether executed plans fully answered the user's original query.\\n        Identifies missing elements, assesses completeness, and suggests next steps\\n        when validation fails. Acts as a quality gate for plan execution.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.ValidationAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent","level":3,"title":"<code>VegaLiteAgent</code>","text":"<p>               Bases: <code>BaseCodeAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use for publication-ready visualizations or when user specifically requests Vega-Lite charts', 'Use for polished charts intended for presentation or sharing'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'response_model': VegaLiteSpec, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'main.jinja2'}, 'main_altair': {'response_model': AltairSpec, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'main_altair.jinja2'}, 'code_safety': {'response_model': CodeSafetyCheck, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'code_safety.jinja2'}, 'interaction_polish': {'response_model': VegaLiteSpecUpdate, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'interaction_polish.jinja2'}, 'annotate_plot': {'response_model': VegaLiteSpecUpdate, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'annotate_plot.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.purpose","level":4,"title":"<code>purpose = param.String(default='Generates a vega-lite plot specification from the input data pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.user","level":4,"title":"<code>user = param.String(default='Vega')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.vector_store_path","level":4,"title":"<code>vector_store_path = param.Path(default=None, check_exists=False, doc='\\n        Path to a custom vector store for storing and retrieving Vega-Lite examples;\\n        if not provided a default store will be used depending on the LLM--\\n        OpenAIEmbeddings for OpenAI LLM or NumpyEmbeddings for all others.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.view_type","level":4,"title":"<code>view_type = VegaLiteView</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.annotate","level":4,"title":"<code>annotate(instruction, messages, context, spec)</code>  <code>async</code>","text":"<p>Apply annotations based on user request.</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>User's description of what to annotate</p> required <code>messages</code> <code>list[Message]</code> <p>Chat history for context</p> required <code>context</code> <code>TContext</code> <p>Session context</p> required <code>spec</code> <code>dict</code> <p>The current VegaLite specification (full dict with 'spec' key)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Updated specification with annotations</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.respond","level":4,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Generates a VegaLite visualization using progressive building approach with real-time updates.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.VegaLiteAgent.revise","level":4,"title":"<code>revise(feedback, messages, context, view=None, spec=None, language=None, errors=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvPlotAgent","level":3,"title":"<code>hvPlotAgent</code>","text":"<p>               Bases: <code>BaseViewAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvPlotAgent.conditions","level":4,"title":"<code>conditions = param.List(default=['Use for exploratory data analysis, interactive plots, and dynamic filtering', 'Use for quick, iterative data visualization during analysis'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvPlotAgent.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'hvPlotAgent' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvPlotAgent.purpose","level":4,"title":"<code>purpose = param.String(default='Generates a plot of the data given a user prompt.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvPlotAgent.view_type","level":4,"title":"<code>view_type = hvPlotUIView</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis","level":3,"title":"<code>analysis</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent","level":4,"title":"<code>AnalysisAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.analyses","level":5,"title":"<code>analyses = param.List([])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use for custom analysis, advanced analytics, or domain-specific methods', \"Use when the user query matches one of the available analyses' name or description below.\", \"Include the selected analysis' required cols in the instructions\", 'NOT for simple queries or basic visualizations'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.input_schema","level":5,"title":"<code>input_schema = AnalysisInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.output_schema","level":5,"title":"<code>output_schema = AnalysisOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'AnalysisAgent' / 'main.jinja2', 'response_model': make_analysis_model}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.purpose","level":5,"title":"<code>purpose = param.String(default='Perform custom analyses that are reliable and repeatable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisInputs","level":4,"title":"<code>AnalysisInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisInputs.data","level":5,"title":"<code>data</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisInputs.pipeline","level":5,"title":"<code>pipeline</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisOutputs","level":4,"title":"<code>AnalysisOutputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisOutputs.analysis","level":5,"title":"<code>analysis</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisOutputs.pipeline","level":5,"title":"<code>pipeline</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.AnalysisOutputs.view","level":5,"title":"<code>view</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.analysis.make_analysis_model","level":4,"title":"<code>make_analysis_model(analyses)</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base","level":3,"title":"<code>base</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent","level":4,"title":"<code>Agent</code>","text":"<p>               Bases: <code>Viewer</code>, <code>ToolUser</code>, <code>ContextProvider</code></p> <p>Agents are actors responsible for taking a user query and performing a particular task, either by adding context or generating outputs.</p> <p>Agents have access to an LLM and are given context and can solve tasks by executing a series of prompts or by rendering contents such as forms or widgets to gather user input.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent.agents","level":5,"title":"<code>agents = param.List(doc='\\n        List of agents this agent can invoke.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent.debug","level":5,"title":"<code>debug = param.Boolean(default=False, doc='\\n        Whether to enable verbose error reporting.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent.llm","level":5,"title":"<code>llm = param.ClassSelector(class_=Llm, doc='\\n        The LLM implementation to query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent.user","level":5,"title":"<code>user = param.String(default='Agent', doc='\\n        The name of the user that will be respond to the user query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent.applies","level":5,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Additional checks to determine if the agent should be used.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base.Agent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Provides a response to the user query.</p> <p>The type of the response may be a simple string or an object.</p> Arguments <p>messages: list[Message]     The list of messages corresponding to the user query and any other     system messages to be included. context: TContext     A mapping containing context for the agent to perform its task. step_title: str | None     If the Agent response is part of a longer query this describes     the step currently being processed.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_code","level":3,"title":"<code>base_code</code>","text":"<p>Base class for agents that execute LLM-generated code.</p> <p>This provides a clean inheritance hierarchy:     BaseViewAgent         ‚îî‚îÄ‚îÄ BaseCodeAgent                 ‚îú‚îÄ‚îÄ VegaLiteAgent                 ‚îî‚îÄ‚îÄ (future code-executing agents)</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_code.BaseCodeAgent","level":4,"title":"<code>BaseCodeAgent</code>","text":"<p>               Bases: <code>BaseViewAgent</code></p> <p>Base class for view agents that can generate and execute code.</p> <p>Subclasses must: - Set <code>_executor_class</code> to the appropriate CodeExecutor subclass - Implement <code>_generate_code_spec()</code> for their specific code generation flow</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_code.BaseCodeAgent.code_execution","level":5,"title":"<code>code_execution = param.Selector(default='disabled', objects=['disabled', 'prompt', 'llm', 'allow'], doc=\"\\n        Code execution mode for generating visualizations via code:\\n        - disabled: No code execution; generate declarative specs only (safe for production)\\n        - prompt: Generate code, prompt user for permission to execute\\n        - llm: Generate code, validate with LLM safety check, then execute\\n        - allow: Generate and execute code without user confirmation\\n\\n        ‚ö†Ô∏è WARNING: The 'prompt', 'llm', and 'allow' modes execute LLM-generated code and\\n        must NEVER be enabled in production environments with access to secrets, credentials,\\n        or sensitive data.\\n        \", allow_refs=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_code.BaseCodeAgent.code_execution_enabled","level":5,"title":"<code>code_execution_enabled</code>  <code>property</code>","text":"<p>Whether code execution is enabled (any mode except 'disabled').</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_list","level":3,"title":"<code>base_list</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_list.BaseListAgent","level":4,"title":"<code>BaseListAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>Abstract base class for agents that display a list of items to the user.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_list.BaseListAgent.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Renders a list of items to the user and lets the user pick one.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_list.BaseListAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_lumen","level":3,"title":"<code>base_lumen</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_lumen.BaseLumenAgent","level":4,"title":"<code>BaseLumenAgent</code>","text":"<p>               Bases: <code>Agent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_lumen.BaseLumenAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'BaseLumenAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_lumen.BaseLumenAgent.user","level":5,"title":"<code>user = param.String(default='Lumen')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_lumen.BaseLumenAgent.revise","level":5,"title":"<code>revise(instruction, messages, context, view=None, spec=None, language=None, errors=None, **kwargs)</code>  <code>async</code>","text":"<p>Retry the output by line, allowing the user to provide instruction on why the output was not satisfactory, or an error.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view","level":3,"title":"<code>base_view</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.BaseViewAgent","level":4,"title":"<code>BaseViewAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.BaseViewAgent.input_schema","level":5,"title":"<code>input_schema = ViewInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.BaseViewAgent.output_schema","level":5,"title":"<code>output_schema = ViewOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.BaseViewAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'BaseViewAgent' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.BaseViewAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Generates a visualization based on user messages and the current data pipeline.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewInputs","level":4,"title":"<code>ViewInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewInputs.data","level":5,"title":"<code>data</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewInputs.metaset","level":5,"title":"<code>metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewInputs.pipeline","level":5,"title":"<code>pipeline</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewInputs.table","level":5,"title":"<code>table</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewOutputs","level":4,"title":"<code>ViewOutputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.base_view.ViewOutputs.view","level":5,"title":"<code>view = Any</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.chat","level":3,"title":"<code>chat</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.chat.ChatAgent","level":4,"title":"<code>ChatAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>ChatAgent provides general information about available data and other topics to the user. When data is available, it acts as an analyst providing insights and interpretations.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.chat.ChatAgent.conditions","level":5,"title":"<code>conditions = param.List(default=[\"Use for general conversation that doesn't require fetching or querying data\", 'Use for technical questions about programming, functions, methods, libraries, or APIs', \"Use when user asks to 'explain', 'interpret', 'analyze', 'summarize', or 'comment on' existing data in context\", \"NOT when user asks to 'show', 'get', 'fetch', 'query', 'filter', 'calculate', 'aggregate', or 'transform' data\", 'NOT for creating new data transformations - only for explaining data that already exists'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.chat.ChatAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'ChatAgent' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.chat.ChatAgent.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Provides conversational assistance and interprets existing results.\\n        Handles general questions, technical documentation, and programming help.\\n        When data has been retrieved, explains findings in accessible terms.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.chat.ChatAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl","level":3,"title":"<code>dbtsl</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent","level":4,"title":"<code>DbtslAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code>, <code>DbtslMixin</code></p> <p>Responsible for creating and executing queries against a dbt Semantic Layer to answer user questions about business metrics.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Always use this when dbtsl_metaset is available'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.output_schema","level":5,"title":"<code>output_schema = DbtslOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'response_model': DbtslQueryParams, 'template': PROMPTS_DIR / 'DbtslAgent' / 'main.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'BaseLumenAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Responsible for displaying data to answer user queries about\\n        business metrics using dbt Semantic Layers. This agent can compile\\n        and execute metric queries against a dbt Semantic Layer.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.requires","level":5,"title":"<code>requires = param.List(default=['source', 'dbtsl_metaset'], readonly=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.source","level":5,"title":"<code>source = param.ClassSelector(class_=BaseSQLSource, doc='\\n        The source associated with the dbt Semantic Layer.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.user","level":5,"title":"<code>user = param.String(default='DBT')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Responds to user messages by generating and executing a dbt Semantic Layer query.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslOutputs","level":4,"title":"<code>DbtslOutputs</code>","text":"<p>               Bases: <code>SQLEditors</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslOutputs.dbtsl_metaset","level":5,"title":"<code>dbtsl_metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams","level":4,"title":"<code>DbtslQueryParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Model for dbtsl.client.query() parameters.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(description=\"You are a world-class dbt Semantic Layer expert. Think step by step about\\n        what metrics are needed, what dimensions to group by, what time granularity\\n        to use, and any filters that should be applied; if filters are applied, include those\\n        filtered dimensions in group_by. If there are errors, mention how you'll address the errors.\\n        \")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.expr_slug","level":5,"title":"<code>expr_slug = Field(description='Give the query a concise, but descriptive, slug that includes the metrics\\n        and dimensions used, e.g. monthly_revenue_by_region. The slug must be unique.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.group_by","level":5,"title":"<code>group_by = Field(default_factory=list, description=\"A list of dimensions to group by, e.g. ['metric_time__month'], must include dimensions from where.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.limit","level":5,"title":"<code>limit = Field(default=None, description='The maximum number of rows to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.metrics","level":5,"title":"<code>metrics = Field(default_factory=list, description=\"A list of metrics to include in the query, e.g. ['revenue']\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.order_by","level":5,"title":"<code>order_by = Field(default_factory=list, description=\"A list of columns or expressions to order the results by, e.g. ['metric_time__month']\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.dbtsl.DbtslQueryParams.where","level":5,"title":"<code>where = Field(default_factory=list, description=\"A list of conditions to filter the results; dimensions referenced here must also be in group_by, e.g. ['metric_time__month &gt;= date_trunc('month', '2024-09-30'::date)']\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl","level":3,"title":"<code>deck_gl</code>","text":"<p>DeckGL Agent for generating 3D map visualizations.</p> <p>This agent generates deck.gl visualizations either: - Directly as JSON specs (when code_execution is disabled) - Via PyDeck Python code execution (when code_execution is enabled)</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent","level":4,"title":"<code>DeckGLAgent</code>","text":"<p>               Bases: <code>BaseCodeAgent</code></p> <p>Agent for generating DeckGL 3D map visualizations.</p> <p>Supports two generation modes: - When code_execution is 'disabled': Generate DeckGL JSON specs directly - When code_execution is enabled: Generate PyDeck Python code, execute safely, convert to spec</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use for 3D geographic visualizations, map-based data, or when user requests DeckGL/deck.gl', 'Use for large-scale geospatial data with latitude/longitude coordinates', 'Use for hexbin aggregations, heatmaps, or 3D extruded visualizations on maps'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.default_map_style","level":5,"title":"<code>default_map_style = 'https://basemaps.cartocdn.com/gl/dark-matter-gl-style/style.json'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'response_model': DeckGLSpec, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'main.jinja2'}, 'main_pydeck': {'response_model': PyDeckSpec, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'main_pydeck.jinja2'}, 'code_safety': {'response_model': CodeSafetyCheck, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'code_safety.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'DeckGLAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.purpose","level":5,"title":"<code>purpose = param.String(default='Generates DeckGL 3D map visualizations from geographic data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.user","level":5,"title":"<code>user = param.String(default='DeckGL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.view_type","level":5,"title":"<code>view_type = DeckGLView</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Generate a DeckGL visualization.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLSpec","level":4,"title":"<code>DeckGLSpec</code>","text":"<p>               Bases: <code>EscapeBaseModel</code></p> <p>Response model for DeckGL JSON spec generation (declarative mode).</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLSpec.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(description='Explain your design choices for the 3D visualization:\\n        - What geographic patterns does this data reveal?\\n        - Which layer type best represents the data (HexagonLayer, ScatterplotLayer, etc.)?\\n        - What visual encodings (elevation, color, radius) highlight key insights?\\n        Keep response to 1-2 sentences.', examples=['The data shows population density clustering around urban centers‚ÄîHexagonLayer with elevation encoding count will create an intuitive 3D cityscape effect.', 'Point locations with varying magnitudes suggest ScatterplotLayer with radius encoding value and color gradient for intensity.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.DeckGLSpec.json_spec","level":5,"title":"<code>json_spec = Field(description='A DeckGL JSON specification. Must include:\\n        - initialViewState with latitude, longitude, zoom, pitch, bearing\\n        - layers array with @@type for each layer\\n        Do NOT include \\'data\\' in layers - it will be injected automatically.\\n        Use @@= syntax for accessors, e.g. \"getPosition\": \"@@=[longitude, latitude]\"\\n        ')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.PyDeckSpec","level":4,"title":"<code>PyDeckSpec</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>Response model for PyDeck code generation.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.PyDeckSpec.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(default='', description='Explain your design choices for the 3D visualization:\\n        - What geographic patterns does this data reveal?\\n        - Which layer type best represents the data?\\n        - What visual encodings highlight key insights?\\n        Keep response to 1-2 sentences.', examples=['The data shows CO2 emissions by plant location‚ÄîHexagonLayer aggregating emissions with elevation shows concentration hotspots.', 'Wind turbine locations with capacity data‚ÄîScatterplotLayer with radius proportional to capacity reveals infrastructure distribution.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.deck_gl.PyDeckSpec.code","level":5,"title":"<code>code = Field(description='Python code that creates a PyDeck visualization.\\n        Requirements:\\n        - Import pydeck as `pdk`\\n        - Data is available as `df` (pandas DataFrame)\\n        - Column names have spaces replaced with underscores and non-alphanumeric chars removed\\n        - Must assign final deck to variable `deck`\\n        - Do NOT call .to_html(), .show(), or any I/O methods\\n        ```\\n        ')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list","level":3,"title":"<code>document_list</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListAgent","level":4,"title":"<code>DocumentListAgent</code>","text":"<p>               Bases: <code>BaseListAgent</code></p> <p>The DocumentListAgent lists all available documents provided by the user.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use when user asks to list or see all available documents', 'NOT when user asks about specific document content'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListAgent.input_schema","level":5,"title":"<code>input_schema = DocumentListInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListAgent.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Displays a list of all available documents.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListAgent.applies","level":5,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListInputs","level":4,"title":"<code>DocumentListInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.document_list.DocumentListInputs.metaset","level":5,"title":"<code>metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvplot","level":3,"title":"<code>hvplot</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvplot.hvPlotAgent","level":4,"title":"<code>hvPlotAgent</code>","text":"<p>               Bases: <code>BaseViewAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvplot.hvPlotAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use for exploratory data analysis, interactive plots, and dynamic filtering', 'Use for quick, iterative data visualization during analysis'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvplot.hvPlotAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'hvPlotAgent' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvplot.hvPlotAgent.purpose","level":5,"title":"<code>purpose = param.String(default='Generates a plot of the data given a user prompt.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.hvplot.hvPlotAgent.view_type","level":5,"title":"<code>view_type = hvPlotUIView</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql","level":3,"title":"<code>sql</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery","level":4,"title":"<code>DistinctQuery</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>Universal column analysis with optional pattern matching - handles join keys, categories, date ranges.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.column","level":5,"title":"<code>column = Field(description='Column to analyze unique values')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.offset","level":5,"title":"<code>offset = Field(default=0, description='Number of distinct values to skip (0 for initial, 10 for follow-up)')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.pattern","level":5,"title":"<code>pattern = Field(default='', description=\"Optional pattern to search for (e.g., 'chin' for China/Chinese variations). Leave empty for all distinct values.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.query","level":5,"title":"<code>query = Field(default=\"SELECT DISTINCT {column} FROM {slug[table]} WHERE {column} ILIKE '%{pattern}%' LIMIT 10 OFFSET {offset}\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.format_result","level":5,"title":"<code>format_result(df)</code>","text":"<p>Format query results for display.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.generate_sql","level":5,"title":"<code>generate_sql(source)</code>","text":"<p>Generate SQL for this query type.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.get_description","level":5,"title":"<code>get_description()</code>","text":"<p>Get query description for logging.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.DistinctQuery.model_post_init","level":5,"title":"<code>model_post_init(__context)</code>","text":"<p>Adjust query template based on whether pattern is provided.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent","level":4,"title":"<code>SQLAgent</code>","text":"<p>               Bases: <code>BaseLumenAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use for querying, filtering, aggregating, or transforming data with SQL', \"Use for calculations that require executing SQL (e.g., 'calculate average', 'sum by category')\", \"Use when user asks to 'show', 'get', 'fetch', 'query', 'find', 'filter', 'calculate', 'aggregate', or 'transform' data\", \"NOT when user asks to 'explain', 'interpret', 'analyze', 'summarize', or 'comment on' existing data\", 'NOT useful if the user is using the same data for plotting'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.exclusions","level":5,"title":"<code>exclusions = param.List(default=['dbtsl_metaset'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.exploration_enabled","level":5,"title":"<code>exploration_enabled = param.Boolean(default=True, allow_refs=True, doc='\\n        Whether to enable SQL exploration mode. When False, only attempts oneshot SQL generation.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.input_schema","level":5,"title":"<code>input_schema = SQLInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.not_with","level":5,"title":"<code>not_with = param.List(default=['DbtslAgent', 'MetadataLookup', 'TableListAgent'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.output_schema","level":5,"title":"<code>output_schema = SQLEditors</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'response_model': make_sql_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'main.jinja2'}, 'select_tables': {'response_model': make_table_selection_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'select_tables.jinja2'}, 'select_discoveries': {'response_model': make_discovery_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'select_discoveries.jinja2'}, 'check_sufficiency': {'response_model': make_discovery_model, 'template': PROMPTS_DIR / 'SQLAgent' / 'check_sufficiency.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'SQLAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Creates and executes SQL queries to retrieve, filter, aggregate, or transform data.\\n        Handles table joins, WHERE clauses, GROUP BY, calculations, and other SQL operations.\\n        Generates new data pipelines from SQL transformations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.user","level":5,"title":"<code>user = param.String(default='SQL')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Execute SQL generation with table selection, then one-shot attempt, then exploration if needed.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLAgent.revise","level":5,"title":"<code>revise(feedback, messages, context, view=None, spec=None, language=None, errors=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLEditors","level":4,"title":"<code>SQLEditors</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLEditors.data","level":5,"title":"<code>data</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLEditors.pipeline","level":5,"title":"<code>pipeline</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLEditors.sql","level":5,"title":"<code>sql</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLEditors.table","level":5,"title":"<code>table</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs","level":4,"title":"<code>SQLInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs.data","level":5,"title":"<code>data</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs.metaset","level":5,"title":"<code>metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs.source","level":5,"title":"<code>source</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs.sources","level":5,"title":"<code>sources</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs.sql","level":5,"title":"<code>sql</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLInputs.visible_slugs","level":5,"title":"<code>visible_slugs</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLQuery","level":4,"title":"<code>SQLQuery</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>A single SQL query with its associated metadata.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLQuery.query","level":5,"title":"<code>query = Field(description=\"\\n        One, correct, valid SQL query that answers the user's question;\\n        should only be one query and do NOT add extraneous comments; no multiple semicolons.\\n        No limits unless explicitly requested.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SQLQuery.table_slug","level":5,"title":"<code>table_slug = Field(description='\\n        Provide a unique, descriptive table slug for the SQL expression that clearly indicates the key transformations and source tables involved.\\n        Include 1 or 2 elements of data lineage in the slug, such as the main transformation and original table names,\\n        e.g. top_5_athletes_in_2020 or distinct_years_from_wx_table.\\n        Ensure the slug does not duplicate any existing table names or slugs.\\n        ')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SampleQuery","level":4,"title":"<code>SampleQuery</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>See actual data content - reveals format issues and patterns.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SampleQuery.query","level":5,"title":"<code>query = Field(default='SELECT * FROM {slug[table]} LIMIT 5')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SampleQuery.format_result","level":5,"title":"<code>format_result(df)</code>","text":"<p>Format query results for display.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SampleQuery.generate_sql","level":5,"title":"<code>generate_sql(source)</code>","text":"<p>Generate SQL for this query type.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.SampleQuery.get_description","level":5,"title":"<code>get_description()</code>","text":"<p>Get query description for logging.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableQuery","level":4,"title":"<code>TableQuery</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>Wildcard search using native source metadata to discover tables and columns by pattern.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableQuery.pattern","level":5,"title":"<code>pattern = Field(description=\"Search pattern (e.g., 'revenue', 'customer')\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableQuery.scope","level":5,"title":"<code>scope = Field(default='both', description=\"Search scope: 'columns' for column names, 'tables' for table names, 'both' for either\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableQuery.format_result","level":5,"title":"<code>format_result(matches)</code>","text":"<p>Format search results for display.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableQuery.get_description","level":5,"title":"<code>get_description()</code>","text":"<p>Get query description for logging.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableQuery.search_metadata","level":5,"title":"<code>search_metadata(source)</code>","text":"<p>Search tables and columns using native source metadata with fuzzy matching.</p> <p>Returns:     List of (table_name, column_name) tuples sorted by match quality.     column_name is None for table matches.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableSelection","level":4,"title":"<code>TableSelection</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>Select tables relevant to answering the user's query.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableSelection.reasoning","level":5,"title":"<code>reasoning = Field(description='Brief explanation of why these tables are needed to answer the query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.TableSelection.tables","level":5,"title":"<code>tables = Field(description='List of table slugs needed to answer the query. Select only tables that are directly relevant.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.make_discovery_model","level":4,"title":"<code>make_discovery_model(sources)</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.make_source_table_model","level":4,"title":"<code>make_source_table_model(sources)</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.make_sql_model","level":4,"title":"<code>make_sql_model(sources)</code>","text":"<p>Create a SQL query model with source/table validation.</p> <p>Parameters:</p> Name Type Description Default <code>sources</code> <code>list[tuple[str, str]]</code> <p>List of (source_name, table_name) tuples for tables with full schemas.</p> required","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.make_table_model","level":4,"title":"<code>make_table_model(sources)</code>","text":"<p>Create a table model with constrained table choices.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.sql.make_table_selection_model","level":4,"title":"<code>make_table_selection_model(available_tables)</code>","text":"<p>Create a table selection model with constrained table choices.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list","level":3,"title":"<code>table_list</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListAgent","level":4,"title":"<code>TableListAgent</code>","text":"<p>               Bases: <code>BaseListAgent</code></p> <p>The TableListAgent lists all available data and lets the user pick one.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListAgent.conditions","level":5,"title":"<code>conditions = param.List(default=[\"Use when user explicitly asks to 'list data', 'show available data', or 'what data do you have'\", 'NOT for showing actual data contents, querying, or analyzing data', 'NOT for describing data sources or telling what the data is about'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListAgent.input_schema","level":5,"title":"<code>input_schema = TableListInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListAgent.not_with","level":5,"title":"<code>not_with = param.List(default=['DbtslAgent', 'SQLAgent'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListAgent.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Displays a list of all available data &amp; datasets. Not useful for identifying which dataset to use for analysis.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListAgent.applies","level":5,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListInputs","level":4,"title":"<code>TableListInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListInputs.metaset","level":5,"title":"<code>metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListInputs.source","level":5,"title":"<code>source</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.table_list.TableListInputs.visible_slugs","level":5,"title":"<code>visible_slugs</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation","level":3,"title":"<code>validation</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.QueryCompletionValidation","level":4,"title":"<code>QueryCompletionValidation</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>Validation of whether the executed plan answered the user's query</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.QueryCompletionValidation.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(description='Restate intent and results succinctly; then explain your reasoning as to why you will be answering yes or no.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.QueryCompletionValidation.correct","level":5,"title":"<code>correct = Field(description='True if query correctly solves user request, otherwise False.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.QueryCompletionValidation.missing_elements","level":5,"title":"<code>missing_elements = Field(default_factory=list, description=\"List of specific elements from the user's query that weren't addressed\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.QueryCompletionValidation.suggestions","level":5,"title":"<code>suggestions = Field(default_factory=list, description='Suggestions for additional steps that could complete the query if not fully answered')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent","level":4,"title":"<code>ValidationAgent</code>","text":"<p>               Bases: <code>Agent</code></p> <p>ValidationAgent focuses solely on validating whether the executed plan fully answered the user's original query. It identifies missing elements and suggests next steps when validation fails.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use to validate whether executed plans fully answered user queries', 'Use to identify missing elements from the original user request', 'NOT for data analysis, pattern identification, or technical programming questions'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent.input_schema","level":5,"title":"<code>input_schema = ValidationInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent.output_schema","level":5,"title":"<code>output_schema = ValidationOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'ValidationAgent' / 'main.jinja2', 'response_model': QueryCompletionValidation, 'tools': []}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent.purpose","level":5,"title":"<code>purpose = param.String(default=\"\\n        Validates whether executed plans fully answered the user's original query.\\n        Identifies missing elements, assesses completeness, and suggests next steps\\n        when validation fails. Acts as a quality gate for plan execution.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationInputs","level":4,"title":"<code>ValidationInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationInputs.data","level":5,"title":"<code>data</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationInputs.sql","level":5,"title":"<code>sql</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationInputs.view","level":5,"title":"<code>view</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationOutputs","level":4,"title":"<code>ValidationOutputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.validation.ValidationOutputs.validation_result","level":5,"title":"<code>validation_result</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite","level":3,"title":"<code>vega_lite</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.AltairSpec","level":4,"title":"<code>AltairSpec</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p> <p>Response model for Altair code generation.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.AltairSpec.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(default='', description=\"Explain your design choices based on visualization theory:\\n        - What story does this data tell?\\n        - What's the most compelling insight or trend (for the title)?\\n        - Which visual encodings (position, color, size) best reveal patterns?\\n        Keep response to 1-2 sentences.\", examples=['The data reveals US dominance in Winter Olympic hosting‚Äîa horizontal bar chart sorted descending makes comparison immediate, with the leader highlighted in a distinct color.', 'This time series shows a 40% revenue spike in Q3 2024‚Äîa line chart with point markers reveals the trend clearly.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.AltairSpec.code","level":5,"title":"<code>code = Field(description=\"Python code that creates an Altair chart.\\n        Requirements:\\n        - Import altair as `alt`\\n        - Data is available as `df` (pandas DataFrame)\\n        - Must assign final chart to variable `chart`\\n        - Do NOT call .to_dict(), .save(), .display() or any I/O methods\\n        - Use 'container' for width to make charts responsive\\n        \")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent","level":4,"title":"<code>VegaLiteAgent</code>","text":"<p>               Bases: <code>BaseCodeAgent</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.conditions","level":5,"title":"<code>conditions = param.List(default=['Use for publication-ready visualizations or when user specifically requests Vega-Lite charts', 'Use for polished charts intended for presentation or sharing'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'response_model': VegaLiteSpec, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'main.jinja2'}, 'main_altair': {'response_model': AltairSpec, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'main_altair.jinja2'}, 'code_safety': {'response_model': CodeSafetyCheck, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'code_safety.jinja2'}, 'interaction_polish': {'response_model': VegaLiteSpecUpdate, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'interaction_polish.jinja2'}, 'annotate_plot': {'response_model': VegaLiteSpecUpdate, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'annotate_plot.jinja2'}, 'revise_output': {'response_model': RetrySpec, 'template': PROMPTS_DIR / 'VegaLiteAgent' / 'revise_output.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.purpose","level":5,"title":"<code>purpose = param.String(default='Generates a vega-lite plot specification from the input data pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.user","level":5,"title":"<code>user = param.String(default='Vega')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.vector_store_path","level":5,"title":"<code>vector_store_path = param.Path(default=None, check_exists=False, doc='\\n        Path to a custom vector store for storing and retrieving Vega-Lite examples;\\n        if not provided a default store will be used depending on the LLM--\\n        OpenAIEmbeddings for OpenAI LLM or NumpyEmbeddings for all others.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.view_type","level":5,"title":"<code>view_type = VegaLiteView</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.annotate","level":5,"title":"<code>annotate(instruction, messages, context, spec)</code>  <code>async</code>","text":"<p>Apply annotations based on user request.</p> <p>Parameters:</p> Name Type Description Default <code>instruction</code> <code>str</code> <p>User's description of what to annotate</p> required <code>messages</code> <code>list[Message]</code> <p>Chat history for context</p> required <code>context</code> <code>TContext</code> <p>Session context</p> required <code>spec</code> <code>dict</code> <p>The current VegaLite specification (full dict with 'spec' key)</p> required <p>Returns:</p> Type Description <code>str</code> <p>Updated specification with annotations</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.respond","level":5,"title":"<code>respond(messages, context, step_title=None)</code>  <code>async</code>","text":"<p>Generates a VegaLite visualization using progressive building approach with real-time updates.</p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteAgent.revise","level":5,"title":"<code>revise(feedback, messages, context, view=None, spec=None, language=None, errors=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteSpec","level":4,"title":"<code>VegaLiteSpec</code>","text":"<p>               Bases: <code>EscapeBaseModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteSpec.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(description=\"Explain your design choices based on visualization theory:\\n        - What story does this data tell?\\n        - What's the most compelling insight or trend (for the title)?\\n        - What additional context adds value without repeating the title (for the subtitle)?\\n        - Which visual encodings (position, color, size) best reveal patterns?\\n        - Should color highlight specific insights or remain neutral?\\n        - What makes this plot engaging and useful for the user?\\n        Keep response to 1-2 sentences.\", examples=[\"The data reveals US dominance in Winter Olympic hosting (4 times vs France's 3)‚Äîtitle should emphasize this leadership. Position encoding via horizontal bars sorted descending makes comparison immediate, neutral blue keeps focus on counts rather than categories, and the subtitle can note the 23-country spread to add context without redundancy.\", \"This time series shows a 40% revenue spike in Q3 2024‚Äîthe key trend for the title. A line chart with position encoding (time‚Üíx, revenue‚Üíy) reveals the pattern, endpoint labels eliminate need for constant grid reference making it cleaner, and color remains neutral since there's one series; the subtitle should explain what drove the spike (e.g., 'Three offshore projects') to add insight.\"])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteSpec.yaml_spec","level":5,"title":"<code>yaml_spec = Field(description='A basic vega-lite YAML specification with core plot elements only (mark, basic x/y encoding). Skip $schema and data fields.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteSpecUpdate","level":4,"title":"<code>VegaLiteSpecUpdate</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteSpecUpdate.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(description=\"Explain what changes you're making to the Vega-Lite spec and why. Keep to 1-2 sentences.\", examples=['Adding tooltips to show exact values on hover for better interactivity.', 'Swapping x and y axes to create horizontal bars as requested.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/agents/#lumen.ai.agents.vega_lite.VegaLiteSpecUpdate.yaml_update","level":5,"title":"<code>yaml_update = Field(description=\"Partial YAML with ONLY modified properties (unchanged values omitted).\\n        Respect your step's scope; don't override previous steps.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Agents"],"tags":[]},{"location":"reference/api/ai/coordinator/","level":1,"title":"AI Coordinator","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator","level":2,"title":"<code>lumen.ai.coordinator</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.__all__","level":3,"title":"<code>__all__ = ['Coordinator', 'Plan', 'DependencyResolver', 'Planner']</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator","level":3,"title":"<code>Coordinator</code>","text":"<p>               Bases: <code>Viewer</code>, <code>VectorLookupToolUser</code></p> <p>A Coordinator is responsible for coordinating the actions of a number of agents towards the user defined query by computing an execution graph and then executing each step along the graph.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.agents","level":4,"title":"<code>agents = param.List(default=[ChatAgent], doc='\\n        List of agents to coordinate.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.context","level":4,"title":"<code>context = param.Dict(default={})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.history","level":4,"title":"<code>history = param.Integer(default=3, doc='\\n        Number of previous user-assistant interactions to include in the chat history.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'Coordinator' / 'main.jinja2'}, 'tool_relevance': {'template': PROMPTS_DIR / 'Coordinator' / 'tool_relevance.jinja2', 'response_model': ThinkingYesNo}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.validation_enabled","level":4,"title":"<code>validation_enabled = param.Boolean(default=False, allow_refs=True, doc='\\n        Whether to enable the ValidationAgent in the planning process.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.verbose","level":4,"title":"<code>verbose = param.Boolean(default=False, allow_refs=True, doc='\\n        Whether to show verbose output.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.within_ui","level":4,"title":"<code>within_ui = param.Boolean(default=False, constant=True, doc='\\n        Whether this coordinator is being used within the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.respond","level":4,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Coordinator.sync","level":4,"title":"<code>sync(context)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.DependencyResolver","level":3,"title":"<code>DependencyResolver</code>","text":"<p>               Bases: <code>Coordinator</code></p> <p>DependencyResolver is a type of Coordinator that chooses the agent to answer the query and then recursively resolves all the information required for that agent until the answer is available.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.DependencyResolver.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'DependencyResolver' / 'main.jinja2', 'response_model': make_agent_model}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan","level":3,"title":"<code>Plan</code>","text":"<p>               Bases: <code>Section</code></p> <p>A Plan is a Task that is a collection of other Tasks.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.abort_on_error","level":4,"title":"<code>abort_on_error = param.Boolean(default=True, doc='\\n        If True, the report will abort if an error occurs.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.agents","level":4,"title":"<code>agents = param.List(item_type=Actor, default=[])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.coordinator","level":4,"title":"<code>coordinator = param.ClassSelector(class_=(param.Parameterized))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.interface","level":4,"title":"<code>interface = param.ClassSelector(class_=ChatFeed)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.is_followup","level":4,"title":"<code>is_followup = param.Boolean(default=False)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.execute","level":4,"title":"<code>execute(context=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Plan.render_task_history","level":4,"title":"<code>render_task_history(i=None, failed=False)</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Planner","level":3,"title":"<code>Planner</code>","text":"<p>               Bases: <code>Coordinator</code></p> <p>The Planner develops a plan to solve the user query step-by-step and then executes it.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Planner.planner_tools","level":4,"title":"<code>planner_tools = param.List(default=[MetadataLookup], doc='\\n        List of tools to use to provide context for the planner prior\\n        to making a plan.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Planner.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'Planner' / 'main.jinja2', 'response_model': make_plan_model}, 'follow_up': {'template': PROMPTS_DIR / 'Planner' / 'follow_up.jinja2', 'response_model': ThinkingYesNo}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.Planner.sync","level":4,"title":"<code>sync(context)</code>  <code>async</code>","text":"<p>Sync both main tools and planner tools.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base","level":3,"title":"<code>base</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator","level":4,"title":"<code>Coordinator</code>","text":"<p>               Bases: <code>Viewer</code>, <code>VectorLookupToolUser</code></p> <p>A Coordinator is responsible for coordinating the actions of a number of agents towards the user defined query by computing an execution graph and then executing each step along the graph.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.agents","level":5,"title":"<code>agents = param.List(default=[ChatAgent], doc='\\n        List of agents to coordinate.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.context","level":5,"title":"<code>context = param.Dict(default={})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.history","level":5,"title":"<code>history = param.Integer(default=3, doc='\\n        Number of previous user-assistant interactions to include in the chat history.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'Coordinator' / 'main.jinja2'}, 'tool_relevance': {'template': PROMPTS_DIR / 'Coordinator' / 'tool_relevance.jinja2', 'response_model': ThinkingYesNo}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.validation_enabled","level":5,"title":"<code>validation_enabled = param.Boolean(default=False, allow_refs=True, doc='\\n        Whether to enable the ValidationAgent in the planning process.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.verbose","level":5,"title":"<code>verbose = param.Boolean(default=False, allow_refs=True, doc='\\n        Whether to show verbose output.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.within_ui","level":5,"title":"<code>within_ui = param.Boolean(default=False, constant=True, doc='\\n        Whether this coordinator is being used within the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.respond","level":5,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Coordinator.sync","level":5,"title":"<code>sync(context)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan","level":4,"title":"<code>Plan</code>","text":"<p>               Bases: <code>Section</code></p> <p>A Plan is a Task that is a collection of other Tasks.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.abort_on_error","level":5,"title":"<code>abort_on_error = param.Boolean(default=True, doc='\\n        If True, the report will abort if an error occurs.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.agents","level":5,"title":"<code>agents = param.List(item_type=Actor, default=[])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.coordinator","level":5,"title":"<code>coordinator = param.ClassSelector(class_=(param.Parameterized))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.interface","level":5,"title":"<code>interface = param.ClassSelector(class_=ChatFeed)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.is_followup","level":5,"title":"<code>is_followup = param.Boolean(default=False)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.execute","level":5,"title":"<code>execute(context=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.base.Plan.render_task_history","level":5,"title":"<code>render_task_history(i=None, failed=False)</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.dependency","level":3,"title":"<code>dependency</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.dependency.DependencyResolver","level":4,"title":"<code>DependencyResolver</code>","text":"<p>               Bases: <code>Coordinator</code></p> <p>DependencyResolver is a type of Coordinator that chooses the agent to answer the query and then recursively resolves all the information required for that agent until the answer is available.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.dependency.DependencyResolver.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'DependencyResolver' / 'main.jinja2', 'response_model': make_agent_model}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.dependency.make_agent_model","level":4,"title":"<code>make_agent_model(agent_names, primary=False)</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner","level":3,"title":"<code>planner</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.Planner","level":4,"title":"<code>Planner</code>","text":"<p>               Bases: <code>Coordinator</code></p> <p>The Planner develops a plan to solve the user query step-by-step and then executes it.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.Planner.planner_tools","level":5,"title":"<code>planner_tools = param.List(default=[MetadataLookup], doc='\\n        List of tools to use to provide context for the planner prior\\n        to making a plan.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.Planner.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'Planner' / 'main.jinja2', 'response_model': make_plan_model}, 'follow_up': {'template': PROMPTS_DIR / 'Planner' / 'follow_up.jinja2', 'response_model': ThinkingYesNo}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.Planner.sync","level":5,"title":"<code>sync(context)</code>  <code>async</code>","text":"<p>Sync both main tools and planner tools.</p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawPlan","level":4,"title":"<code>RawPlan</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawPlan.steps","level":5,"title":"<code>steps = Field(description=\"\\n        The sequence of steps to resolve the user's query.\\n        Ensure no two consecutive steps use the same actor.\\n\\n        Adhere to separation of concerns:\\n        - Each step's instruction should be limited to that actor's task.\\n        - Do not include downstream objectives in upstream instructions.\\n        \")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawPlan.title","level":5,"title":"<code>title = Field(description='A title that describes this plan, up to three words.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawStep","level":4,"title":"<code>RawStep</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawStep.actor","level":5,"title":"<code>actor</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawStep.instruction","level":5,"title":"<code>instruction = Field(description='\\n        Concise instruction capturing user intent at the right altitude.\\n\\n        - ‚ùå Too low: implementation details (SQL syntax, chart specs)\\n        - ‚ùå Too high: vague (\"handle this\", \"process data\")\\n        - ‚ùå Leaking: mentioning downstream purpose (\"for plotting\", \"for the chart\", \"for analysis\")\\n        - ‚úÖ Just right: what THIS actor should do, nothing about why\\n        ', examples=['Query top 5 countries by sales', 'Get wind, temperature, dewpoint, and precipitation data for Seattle on Jan 1, 2020', 'Plot a line chart of sales over time.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.RawStep.title","level":5,"title":"<code>title</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.Reasoning","level":4,"title":"<code>Reasoning</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p>","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.Reasoning.chain_of_thought","level":5,"title":"<code>chain_of_thought = Field(description=\"\\n        Briefly summarize the user's goal and categorize the question type:\\n        high-level, data-focused, or other. Identify the most relevant and compatible actors,\\n        explaining their requirements, and what you already have satisfied. If there were previous failures, discuss them.\\n        IMPORTANT: Ensure no consecutive steps use the same actor in your planned sequence.\\n        For multi-metric queries (multiple charts or metrics), plan a single SQL step with JOINs.\\n        Keep response to 1-2 sentences.\\n        \", examples=['Find which country hosted the most Winter Olympics‚Äîa data-focused query requiring aggregation. SQLAgent can handle this (requires source/metaset, both available) by filtering to Winter and counting by location, with no consecutive actor conflicts.', 'A horizontal bar chart of existing data. VegaLiteAgent is ready (requires pipeline/data/table, all satisfied from previous SQLAgent step) and will create the chart without consecutive actor issues.', 'SQLAgent should JOIN both tables on country/year in one query, then VegaLiteAgent creates the compound chart. Single SQL step avoids redundant queries.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/coordinator/#lumen.ai.coordinator.planner.make_plan_model","level":4,"title":"<code>make_plan_model(agents, tools)</code>","text":"","path":["Reference","API","AI","AI Coordinator"],"tags":[]},{"location":"reference/api/ai/core/","level":1,"title":"AI Core Components","text":"<p>Core AI functionality including LLM interfaces, context management, and utilities.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm","level":2,"title":"<code>lumen.ai.llm</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.BASE_MODES","level":3,"title":"<code>BASE_MODES = list(Mode)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LLM_PROVIDERS","level":3,"title":"<code>LLM_PROVIDERS = {'openai': 'OpenAI', 'google': 'Google', 'anthropic': 'Anthropic', 'anthropic_bedrock': 'AnthropicBedrock', 'bedrock': 'Bedrock', 'mistral': 'MistralAI', 'azure-openai': 'AzureOpenAI', 'azure-mistral': 'AzureMistralAI', 'ai-navigator': 'AINavigator', 'ollama': 'Ollama', 'llama-cpp': 'LlamaCpp', 'litellm': 'LiteLLM'}</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.PROVIDER_ENV_VARS","level":3,"title":"<code>PROVIDER_ENV_VARS = {'openai': 'OPENAI_API_KEY', 'anthropic': 'ANTHROPIC_API_KEY', 'bedrock': 'AWS_ACCESS_KEY_ID', 'anthropic_bedrock': 'AWS_ACCESS_KEY_ID', 'mistral': 'MISTRAL_API_KEY', 'azure-mistral': 'AZUREAI_ENDPOINT_KEY', 'azure-openai': 'AZUREAI_ENDPOINT_KEY', 'google': 'GEMINI_API_KEY'}</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AINavigator","level":3,"title":"<code>AINavigator</code>","text":"<p>               Bases: <code>OpenAI</code></p> <p>A LLM implementation that calls the Anaconda AI Navigator API.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AINavigator.display_name","level":4,"title":"<code>display_name = param.String(default='AI Navigator', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AINavigator.endpoint","level":4,"title":"<code>endpoint = param.String(default='http://localhost:8080/v1', doc='\\n            The API endpoint; should include the full address, including the port.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AINavigator.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.JSON_SCHEMA))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AINavigator.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'server-model'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AINavigator.select_models","level":4,"title":"<code>select_models = param.List(default=['server-model'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic","level":3,"title":"<code>Anthropic</code>","text":"<p>               Bases: <code>Llm</code></p> <p>A LLM implementation that calls Anthropic models such as Claude.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('ANTHROPIC_API_KEY')), doc='The Anthropic API key.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.display_name","level":4,"title":"<code>display_name = param.String(default='Anthropic', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.ANTHROPIC_TOOLS), objects=[Mode.ANTHROPIC_JSON, Mode.ANTHROPIC_TOOLS])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'claude-haiku-4-5'}, 'edit': {'model': 'claude-sonnet-4-5'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.select_models","level":4,"title":"<code>select_models = param.List(default=['claude-sonnet-4-5', 'claude-haiku-4-5', 'claude-opus-4-5'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.temperature","level":4,"title":"<code>temperature = param.Number(default=0.7, bounds=(0, 1), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for Anthropic API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Anthropic.run_client","level":4,"title":"<code>run_client(model_spec, messages, **kwargs)</code>  <code>async</code>","text":"<p>Override to handle Anthropic-specific message format.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AnthropicBedrock","level":3,"title":"<code>AnthropicBedrock</code>","text":"<p>               Bases: <code>BedrockMixin</code>, <code>Anthropic</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AnthropicBedrock.display_name","level":4,"title":"<code>display_name = param.String(default='Anthropic on AWS Bedrock', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AnthropicBedrock.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'us.anthropic.claude-sonnet-4-5-20250929-v1:0'}, 'ui': {'model': 'us.anthropic.claude-sonnet-4-5-20250929-v1:0'}, 'edit': {'model': 'us.anthropic.claude-opus-4-5-20251101-v1:0'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI","level":3,"title":"<code>AzureMistralAI</code>","text":"<p>               Bases: <code>MistralAI</code></p> <p>A LLM implementation that calls Mistral AI models on Azure.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('AZUREAI_ENDPOINT_KEY')), doc='The Azure API key')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI.display_name","level":4,"title":"<code>display_name = param.String(default='Azure Mistral AI', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI.endpoint","level":4,"title":"<code>endpoint = param.String(default=(os.getenv('AZUREAI_ENDPOINT_URL')), doc='The Azure API endpoint to invoke.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'azureai'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI.select_models","level":4,"title":"<code>select_models = param.List(default=['azureai', 'mistral-large', 'mistral-small'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureMistralAI.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for Mistral AI API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI","level":3,"title":"<code>AzureOpenAI</code>","text":"<p>               Bases: <code>Llm</code>, <code>AzureOpenAIMixin</code></p> <p>A LLM implementation that uses the Azure OpenAI integration. Inherits from AzureOpenAIMixin which extends OpenAIMixin, so it has access to all OpenAI functionality plus Azure-specific configuration.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.display_name","level":4,"title":"<code>display_name = param.String(default='Azure OpenAI', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.TOOLS))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'gpt-4o-mini'}, 'edit': {'model': 'gpt-4o'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.select_models","level":4,"title":"<code>select_models = param.List(default=['gpt-35-turbo', 'gpt-4-turbo', 'gpt-4o', 'gpt-4o-mini'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.temperature","level":4,"title":"<code>temperature = param.Number(default=1, bounds=(0, None), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for Azure OpenAI API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAI.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAIMixin","level":3,"title":"<code>AzureOpenAIMixin</code>","text":"<p>               Bases: <code>OpenAIMixin</code></p> <p>Mixin class for Azure OpenAI functionality that extends OpenAI functionality with Azure-specific configuration.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAIMixin.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('AZUREAI_ENDPOINT_KEY')), doc='\\n        The Azure API key.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAIMixin.api_version","level":4,"title":"<code>api_version = param.String(default='2024-10-21', doc='\\n        The Azure AI Studio API version.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.AzureOpenAIMixin.endpoint","level":4,"title":"<code>endpoint = param.String(default=(os.getenv('AZUREAI_ENDPOINT_URL')), doc='\\n        The Azure AI Studio endpoint.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock","level":3,"title":"<code>Bedrock</code>","text":"<p>               Bases: <code>Llm</code>, <code>BedrockMixin</code></p> <p>A LLM implementation that calls AWS Bedrock models using the Converse API.</p> <p>Uses boto3 bedrock-runtime client with the Converse API for a unified interface across different foundation models. Supports standard AWS credential resolution including environment variables, ~/.aws/credentials, and AWS SSO.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.display_name","level":4,"title":"<code>display_name = param.String(default='AWS Bedrock', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.BEDROCK_TOOLS), objects=[Mode.BEDROCK_JSON, Mode.BEDROCK_TOOLS])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'us.anthropic.claude-sonnet-4-5-20250929-v1:0'}, 'ui': {'model': 'us.anthropic.claude-sonnet-4-5-20250929-v1:0'}, 'edit': {'model': 'us.anthropic.claude-opus-4-5-20251101-v1:0'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.select_models","level":4,"title":"<code>select_models = param.List(default=['us.anthropic.claude-sonnet-4-5-20250929-v1:0', 'us.anthropic.claude-haiku-4-5-20251001-v1:0', 'us.anthropic.claude-opus-4-5-20251101-v1:0', 'us.anthropic.claude-opus-4-1-20250805-v1:0', 'us.anthropic.claude-sonnet-4-20250514-v1:0', 'us.anthropic.claude-3-5-haiku-20241022-v1:0', 'us.anthropic.claude-3-5-sonnet-20241022-v2:0', 'anthropic.claude-3-haiku-20240307-v1:0', 'anthropic.claude-3-sonnet-20240229-v1:0'], constant=True, doc='Available Claude models on Bedrock')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.temperature","level":4,"title":"<code>temperature = param.Number(default=0.7, bounds=(0, 1), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for Bedrock API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Bedrock.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.BedrockMixin","level":3,"title":"<code>BedrockMixin</code>","text":"<p>               Bases: <code>Parameterized</code></p> <p>Mixin class for AWS Bedrock functionality that can be shared between LLM implementations and embedding classes.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.BedrockMixin.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('AWS_SECRET_ACCESS_KEY')), doc='AWS secret access key. If not provided, boto3 will use default credentials (including SSO).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.BedrockMixin.aws_access_key_id","level":4,"title":"<code>aws_access_key_id = param.String(default=(os.getenv('AWS_ACCESS_KEY_ID')), doc='AWS access key ID. If not provided, boto3 will use default credentials (including SSO).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.BedrockMixin.aws_session_token","level":4,"title":"<code>aws_session_token = param.String(default=(os.getenv('AWS_SESSION_TOKEN')), doc='AWS session token for temporary credentials (optional).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.BedrockMixin.region_name","level":4,"title":"<code>region_name = param.String(default='us-east-1', doc='The AWS region name for Bedrock API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Choice","level":3,"title":"<code>Choice</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Choice.delta","level":4,"title":"<code>delta</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Choice.finish_reason","level":4,"title":"<code>finish_reason</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Choice.message","level":4,"title":"<code>message</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google","level":3,"title":"<code>Google</code>","text":"<p>               Bases: <code>Llm</code></p> <p>A LLM implementation that calls Google's Gemini models.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('GEMINI_API_KEY')), doc='The Google API key.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.display_name","level":4,"title":"<code>display_name = param.String(default='Google AI', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.GENAI_TOOLS), objects=[Mode.GENAI_TOOLS, Mode.GENAI_STRUCTURED_OUTPUTS])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'gemini-3-flash-preview'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.select_models","level":4,"title":"<code>select_models = param.List(default=['gemini-3-flash-preview', 'gemini-3-pro-preview', 'gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.5-flash-lite', 'gemini-2.0-flash', 'gemini-2.0-flash-lite', 'gemini-1.5-flash', 'gemini-1.5-pro'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.temperature","level":4,"title":"<code>temperature = param.Number(default=1, bounds=(0, 1), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for Google AI API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Google.run_client","level":4,"title":"<code>run_client(model_spec, messages, **kwargs)</code>  <code>async</code>","text":"<p>Override to handle Gemini-specific message format conversion.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.ImageResponse","level":3,"title":"<code>ImageResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.ImageResponse.output","level":4,"title":"<code>output</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor","level":3,"title":"<code>Interceptor</code>","text":"<p>               Bases: <code>Parameterized</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.conn","level":4,"title":"<code>conn = self._create_connection()</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.db_path","level":4,"title":"<code>db_path = param.String(default='messages.db', doc='Path to the SQLite database file')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.session_id","level":4,"title":"<code>session_id = self._generate_session_id()</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.delete_session","level":4,"title":"<code>delete_session(session_id=None)</code>","text":"<p>Delete the last session from the database.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.get_all_sessions","level":4,"title":"<code>get_all_sessions()</code>","text":"<p>Retrieve the invocations of messages from all sessions.</p> <p>Returns:     A dictionary containing session_id as keys and the corresponding         Session object for each session.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.get_session","level":4,"title":"<code>get_session(session_id=None)</code>","text":"<p>Retrieve the session invocations of inputs from the last session, or a specific session if provided.</p> <p>Args:     session_id: The session ID to retrieve invocations from. If not provided, the last session is used.</p> <p>Returns:     A Session object containing invocations for the session.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.get_session_ids","level":4,"title":"<code>get_session_ids()</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.init_db","level":4,"title":"<code>init_db()</code>","text":"<p>Initialize the database by creating necessary tables if they don't exist.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.patch_client","level":4,"title":"<code>patch_client(client)</code>  <code>abstractmethod</code>","text":"<p>Patch the LLM client's create method to store messages and arguments in the database.</p> <p>Args:     client: The LLM client instance to patch.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.reset_db","level":4,"title":"<code>reset_db()</code>","text":"<p>Reset the database by deleting all tables.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.store_invocation","level":4,"title":"<code>store_invocation(messages, **kwargs)</code>","text":"<p>Store messages and keyword arguments in the database for the current session.</p> <p>Args:     messages: List of message dictionaries to store.     kwargs: The keyword arguments passed to the create method.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.store_response","level":4,"title":"<code>store_response(content)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Interceptor.unpatch","level":4,"title":"<code>unpatch()</code>","text":"<p>Close the database connection and revert the client create.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM","level":3,"title":"<code>LiteLLM</code>","text":"<p>               Bases: <code>Llm</code></p> <p>A LLM implementation using LiteLLM that supports multiple providers through a unified interface.</p> <p>LiteLLM allows you to call 100+ LLMs using the same OpenAI-compatible input/output format, including providers like OpenAI, Anthropic, Cohere, Hugging Face, Azure, Vertex AI, and more.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.display_name","level":4,"title":"<code>display_name = param.String(default='LiteLLM', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.enable_caching","level":4,"title":"<code>enable_caching = param.Boolean(default=False, doc=\"\\n        Enable LiteLLM's built-in caching for repeated queries.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.fallback_models","level":4,"title":"<code>fallback_models = param.List(default=[], doc='\\n        List of fallback models to try if the primary model fails.\\n        Example: [\"gpt-4o-mini\", \"claude-3-haiku\", \"gemini/gemini-1.5-flash\"]')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.litellm_params","level":4,"title":"<code>litellm_params = param.Dict(default={}, doc='\\n        Additional parameters to pass to litellm.acompletion().\\n        Examples: custom_llm_provider, api_base, api_version, etc.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.TOOLS), objects=BASE_MODES)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'gpt-4.1-mini'}, 'edit': {'model': 'anthropic/claude-sonnet-4-5'}, 'sql': {'model': 'gpt-4.1-mini'}}, doc='\\n        Model configurations by type. LiteLLM supports model strings like:\\n        - OpenAI: \"gpt-4.1-mini\", \"gpt-4.1-nano\", \"gpt-5-mini\"\\n        - Anthropic: \"anthropic/claude-sonnet-4-5\", \"anthropic/claude-haiku-4-5\"\\n        - Google: \"gemini/gemini-2.0-flash\", \"gemini/gemini-2.5-flash\"\\n        - Mistral: \"mistral/mistral-medium-latest\", \"mistral/mistral-small-latest\"\\n        - And many more with format: \"provider/model\" or just \"model\" for defaults\\n    ')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.router_settings","level":4,"title":"<code>router_settings = param.Dict(default={}, doc='\\n        Settings for LiteLLM Router for load balancing across multiple models.\\n        Example: {\"routing_strategy\": \"least-busy\", \"num_retries\": 3}')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.select_models","level":4,"title":"<code>select_models = param.List(default=['gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-5-mini', 'anthropic/claude-sonnet-4-5', 'anthropic/claude-haiku-4-5', 'anthropic/claude-opus-4-1', 'gemini/gemini-2.0-flash', 'gemini/gemini-2.5-flash', 'mistral/mistral-medium-latest', 'mistral/mistral-small-latest', 'mistral/codestral-latest'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.temperature","level":4,"title":"<code>temperature = param.Number(default=0.7, bounds=(0, 2), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for LiteLLM API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LiteLLM.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp","level":3,"title":"<code>LlamaCpp</code>","text":"<p>               Bases: <code>Llm</code>, <code>LlamaCppMixin</code></p> <p>A LLM implementation using Llama.cpp Python wrapper together with huggingface_hub to fetch the models.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.chat_format","level":4,"title":"<code>chat_format = param.String(constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.display_name","level":4,"title":"<code>display_name = param.String(default='Llama.cpp', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.JSON_SCHEMA), objects=BASE_MODES)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'repo_id': 'unsloth/Qwen3-32B-GGUF', 'filename': 'Qwen3-32B-Q5_K_M.gguf', 'chat_format': 'qwen'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.select_models","level":4,"title":"<code>select_models = param.List(default=['unsloth/Qwen3-32B-GGUF', 'unsloth/Qwen3-Coder-32B-A3B-Instruct-GGUF', 'unsloth/Qwen2.5-Coder-32B-Instruct-GGUF', 'meta-llama/Llama-3.3-70B-Instruct-GGUF', 'nvidia/Nemotron-3-Nano-30B-GGUF'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.temperature","level":4,"title":"<code>temperature = param.Number(default=0.4, bounds=(0, None), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.run_client","level":4,"title":"<code>run_client(model_spec, messages, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCpp.warmup","level":4,"title":"<code>warmup(model_kwargs)</code>  <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin","level":3,"title":"<code>LlamaCppMixin</code>","text":"<p>               Bases: <code>ServiceMixin</code></p> <p>Mixin class for llama-cpp-python functionality that can be shared between LLM implementations and embedding classes.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.n_batch","level":4,"title":"<code>n_batch = param.Integer(default=512, doc='\\n        Batch size for processing.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.n_ctx","level":4,"title":"<code>n_ctx = param.Integer(default=2048, doc='\\n        Context length for the model.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.n_gpu_layers","level":4,"title":"<code>n_gpu_layers = param.Integer(default=(-1), doc='\\n        Number of layers to offload to GPU. -1 for all layers.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.seed","level":4,"title":"<code>seed = param.Integer(default=128, doc='\\n        Random seed for reproducible outputs.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.use_mlock","level":4,"title":"<code>use_mlock = param.Boolean(default=True, doc='\\n        Force system to keep model in RAM rather than swapping.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.verbose","level":4,"title":"<code>verbose = param.Boolean(default=False, doc='\\n        Enable verbose output from llama.cpp.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.LlamaCppMixin.resolve_model_spec","level":4,"title":"<code>resolve_model_spec(model_spec, base_model_kwargs)</code>","text":"<p>Resolve a model specification string into model kwargs with repo_id/filename. Handles formats like \"repo/model:chat_format\" or \"repo/model\".</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm","level":3,"title":"<code>Llm</code>","text":"<p>               Bases: <code>Parameterized</code></p> <p>Base class for LLM implementations with standardized client caching.</p> <p>Subclasses MUST implement _create_base_client(). Subclasses MAY set _instructor_wrapper (default: \"openai\"). Subclasses MAY override _create_instructor_client() or _get_completion_method().</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.create_kwargs","level":4,"title":"<code>create_kwargs = param.Dict(default={'max_retries': 1}, doc='\\n        Additional keyword arguments to pass to the LLM provider\\n        when calling chat.completions.create. Defaults to no instructor retries\\n        since agents handle retries themselves.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.interceptor","level":4,"title":"<code>interceptor = param.ClassSelector(default=None, class_=Interceptor, doc='\\n        Intercepter instance to intercept LLM calls, e.g. for logging.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.logfire_tags","level":4,"title":"<code>logfire_tags = param.List(default=None, doc='\\n        Whether to log LLM calls and responses to logfire.\\n        If a list of tags is provided, those tags will be used for logging.\\n        Suppresses streaming responses if enabled since\\n        logfire does not track token usage on stream.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.JSON_SCHEMA), objects=BASE_MODES, doc='\\n        The calling mode used by instructor to guide the LLM towards generating\\n        outputs matching the schema.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={}, doc=\"\\n        LLM model definitions indexed by type. Supported types include\\n        'default', 'reasoning' and 'sql'. Agents may pick which model to\\n        invoke for different reasons.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.initialize","level":4,"title":"<code>initialize(log_level)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.invoke","level":4,"title":"<code>invoke(messages, system='', response_model=None, allow_partial=False, model_spec='default', **input_kwargs)</code>  <code>async</code>","text":"<p>Invokes the LLM and returns its response.</p> Arguments <p>messages: list[Message]     A list of messages to feed to the LLM. system: str     A system message to provide to the LLM. response_model: BaseModel | None     A Pydantic model that the LLM should materialize. allow_partial: bool     Whether to allow the LLM to only partially fill     the provided response_model. model: Literal['default' | 'reasoning' | 'sql']     The model as listed in the model_kwargs parameter     to invoke to answer the query.</p> <p>Returns:</p> Type Description <code>The completed response_model.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.run_client","level":4,"title":"<code>run_client(model_spec, messages, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.stream","level":4,"title":"<code>stream(messages, system='', response_model=None, field=None, model_spec='default', **kwargs)</code>  <code>async</code>","text":"<p>Invokes the LLM and streams its response.</p> Arguments <p>messages: list[Message]     A list of messages to feed to the LLM. system: str     A system message to provide to the LLM. response_model: BaseModel | None     A Pydantic model that the LLM should materialize. field: str     The field in the response_model to stream. model: Literal['default' | 'reasoning' | 'sql']     The model as listed in the model_kwargs parameter     to invoke to answer the query.</p> <p>Yields:</p> Type Description <code>The string or response_model field.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Llm.warmup","level":4,"title":"<code>warmup(model_kwargs)</code>  <code>classmethod</code>","text":"<p>Allows LLM provider to perform actions that ensure that the model(s) are ready to run, e.g. downloading the model files.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Message","level":3,"title":"<code>Message</code>","text":"<p>               Bases: <code>TypedDict</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Message.content","level":4,"title":"<code>content</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Message.name","level":4,"title":"<code>name</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Message.role","level":4,"title":"<code>role</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MessageModel","level":3,"title":"<code>MessageModel</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MessageModel.content","level":4,"title":"<code>content</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MessageModel.name","level":4,"title":"<code>name</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MessageModel.role","level":4,"title":"<code>role</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI","level":3,"title":"<code>MistralAI</code>","text":"<p>               Bases: <code>Llm</code></p> <p>A LLM implementation that calls Mistral AI.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('MISTRAL_API_KEY')), doc='The Mistral AI API key.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.display_name","level":4,"title":"<code>display_name = param.String(default='Mistral AI', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.MISTRAL_TOOLS), objects=[Mode.JSON_SCHEMA, Mode.MISTRAL_TOOLS])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'mistral-small-latest'}, 'edit': {'model': 'mistral-medium-latest'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.select_models","level":4,"title":"<code>select_models = param.List(default=['mistral-medium-latest', 'magistral-medium-latest', 'mistral-large-latest', 'magistral-small-latest', 'mistral-small-latest', 'codestral-latest', 'ministral-8b-latest', 'ministral-3b-latest', 'devstral-small-latest'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.temperature","level":4,"title":"<code>temperature = param.Number(default=0.7, bounds=(0, 1), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for Mistral AI API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.MistralAI.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama","level":3,"title":"<code>Ollama</code>","text":"<p>               Bases: <code>OpenAI</code></p> <p>An LLM implementation using the Ollama cloud.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.api_key","level":4,"title":"<code>api_key = param.String(default='ollama', doc='The Ollama API key; required but unused.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.display_name","level":4,"title":"<code>display_name = param.String(default='Ollama', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.endpoint","level":4,"title":"<code>endpoint = param.String(default='http://localhost:11434/v1', doc='The Ollama API endpoint.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.JSON))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'qwen3:32b'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.select_models","level":4,"title":"<code>select_models = param.List(default=['qwen3:32b', 'qwen3-coder:32b', 'nemotron-3-nano:30b', 'mistral-small3.2:24b'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Ollama.temperature","level":4,"title":"<code>temperature = param.Number(default=0.25, bounds=(0, None), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI","level":3,"title":"<code>OpenAI</code>","text":"<p>               Bases: <code>Llm</code>, <code>OpenAIMixin</code></p> <p>An LLM implementation using the OpenAI cloud.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.display_name","level":4,"title":"<code>display_name = param.String(default='OpenAI', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.mode","level":4,"title":"<code>mode = param.Selector(default=(Mode.TOOLS))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'model': 'gpt-4.1-mini'}, 'ui': {'model': 'gpt-4.1-nano'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.select_models","level":4,"title":"<code>select_models = param.List(default=['gpt-5.2', 'gpt-5-mini', 'gpt-5-nano', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano'], constant=True, doc='Available models for selection dropdowns.\\n        Warning: Reasoning models (gpt-5, o4-mini) are much slower and not suitable for dialog interfaces.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.temperature","level":4,"title":"<code>temperature = param.Number(default=0.25, bounds=(0, None), constant=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.timeout","level":4,"title":"<code>timeout = param.Number(default=120, bounds=(1, None), constant=True, doc='\\n        The timeout in seconds for OpenAI API calls.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAI.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAIMixin","level":3,"title":"<code>OpenAIMixin</code>","text":"<p>               Bases: <code>ServiceMixin</code></p> <p>Mixin class for OpenAI functionality that can be shared between LLM implementations and embedding classes.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAIMixin.api_key","level":4,"title":"<code>api_key = param.String(default=None, doc='\\n        The OpenAI API key. If not provided, will use OPENAI_API_KEY env var.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAIMixin.endpoint","level":4,"title":"<code>endpoint = param.String(default=None, doc='\\n        The OpenAI API endpoint. If not provided, uses default OpenAI endpoint.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.OpenAIMixin.organization","level":4,"title":"<code>organization = param.String(default=None, doc='\\n        The OpenAI organization to charge.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Response","level":3,"title":"<code>Response</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.Response.choices","level":4,"title":"<code>choices</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM","level":3,"title":"<code>WebLLM</code>","text":"<p>               Bases: <code>Llm</code></p> <p>WebLLM implementation using panel_web_llm. Uses patch(create=...) like LlamaCpp.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.display_name","level":4,"title":"<code>display_name = param.String(default='WebLLM', constant=True, doc='Display name for UI')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.mode","level":4,"title":"<code>mode = param.Parameter(default=(Mode.JSON_SCHEMA))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict({'default': {'model_slug': 'Qwen2.5-7B-Instruct-q4f16_1-MLC'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.select_models","level":4,"title":"<code>select_models = param.List(default=['Llama-3.2-3B-Instruct-q4f16_1-MLC', 'Phi-3.5-mini-instruct-q4f16_1-MLC', 'Qwen2.5-7B-Instruct-q4f16_1-MLC'], constant=True, doc='Available models for selection dropdowns')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.temperature","level":4,"title":"<code>temperature = param.Number(default=0.4, bounds=(0, None))</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.get_client","level":4,"title":"<code>get_client(model_spec, response_model=None, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.initialize","level":4,"title":"<code>initialize(log_level)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.WebLLM.status","level":4,"title":"<code>status()</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.format_exception","level":3,"title":"<code>format_exception(exc, limit=0)</code>","text":"<p>Format and return a string representation of an exception.</p> <p>Parameters:</p> Name Type Description Default <code>exc</code> <code>Exception</code> <p>The exception to be formatted.</p> required <code>limit</code> <code>int</code> <p>The maximum number of layers of traceback to include in the output. Default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted string describing the exception and its traceback.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.get_available_llm","level":3,"title":"<code>get_available_llm()</code>","text":"<p>Detect and instantiate an available LLM provider by checking environment variables and attempting to instantiate each provider in order.</p> <p>Returns:</p> Type Description <code>type[Llm] | None</code> <p>The LLM class if successful, or None if no provider is available.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.log_debug","level":3,"title":"<code>log_debug(msg, offset=24, prefix='', suffix='', show_sep=None, show_length=False)</code>","text":"<p>Log a debug message with a separator line above and below.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.llm.truncate_string","level":3,"title":"<code>truncate_string(s, max_length=30, ellipsis='...')</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings","level":2,"title":"<code>lumen.ai.embeddings</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.STOP_WORDS","level":3,"title":"<code>STOP_WORDS = (Path(__file__).parent / 'embeddings_stop_words.txt').read_text().splitlines()</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.STOP_WORDS_RE","level":3,"title":"<code>STOP_WORDS_RE = re.compile('\\\\b(?:{})\\\\b'.format('|'.join(STOP_WORDS)), re.IGNORECASE)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIEmbeddings","level":3,"title":"<code>AzureOpenAIEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code>, <code>AzureOpenAIMixin</code></p> <p>AzureOpenAIEmbeddings is an embeddings class that uses the Azure OpenAI API to generate embeddings. Inherits from AzureOpenAIMixin which extends OpenAIMixin, so it has access to all OpenAI functionality plus Azure-specific configuration.</p> <p>:Example:</p> <p>embeddings = AzureOpenAIEmbeddings() await embeddings.embed([\"Hello, world!\", \"Goodbye, world!\"])</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIEmbeddings.client","level":4,"title":"<code>client = self._instantiate_client(async_client=True)</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIEmbeddings.model","level":4,"title":"<code>model = param.String(default='text-embedding-3-large', doc='The OpenAI model to use.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIEmbeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIMixin","level":3,"title":"<code>AzureOpenAIMixin</code>","text":"<p>               Bases: <code>OpenAIMixin</code></p> <p>Mixin class for Azure OpenAI functionality that extends OpenAI functionality with Azure-specific configuration.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIMixin.api_key","level":4,"title":"<code>api_key = param.String(default=(os.getenv('AZUREAI_ENDPOINT_KEY')), doc='\\n        The Azure API key.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIMixin.api_version","level":4,"title":"<code>api_version = param.String(default='2024-10-21', doc='\\n        The Azure AI Studio API version.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.AzureOpenAIMixin.endpoint","level":4,"title":"<code>endpoint = param.String(default=(os.getenv('AZUREAI_ENDPOINT_URL')), doc='\\n        The Azure AI Studio endpoint.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.Embeddings","level":3,"title":"<code>Embeddings</code>","text":"<p>               Bases: <code>Parameterized</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.Embeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Generate embeddings for a list of texts.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.HuggingFaceEmbeddings","level":3,"title":"<code>HuggingFaceEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code></p> <p>HuggingFaceEmbeddings is an embeddings class that uses sentence-transformers to generate embeddings from Hugging Face models.</p> <p>:Example:</p> <p>embeddings = HuggingFaceEmbeddings() await embeddings.embed([\"Hello, world!\", \"Goodbye, world!\"])</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.HuggingFaceEmbeddings.device","level":4,"title":"<code>device = param.String(default='cpu', doc=\"Device to run the model on (e.g., 'cpu' or 'cuda').\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.HuggingFaceEmbeddings.embedding_dim","level":4,"title":"<code>embedding_dim = self._model.get_sentence_embedding_dimension()</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.HuggingFaceEmbeddings.model","level":4,"title":"<code>model = param.String(default='ibm-granite/granite-embedding-107m-multilingual', doc='\\n        The Hugging Face model to use.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.HuggingFaceEmbeddings.prompt_name","level":4,"title":"<code>prompt_name = param.String(default=None, doc='\\n        The prompt name to use for encoding queries. If None, no prompt is used.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.HuggingFaceEmbeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppEmbeddings","level":3,"title":"<code>LlamaCppEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code>, <code>LlamaCppMixin</code></p> <p>LlamaCppEmbeddings is an embeddings class that uses the llama-cpp-python library to generate embeddings from GGUF models.</p> <p>:Example:</p> <p>embeddings = LlamaCppEmbeddings( ...     model_kwargs={ ...         \"repo_id\": \"Qwen/Qwen3-Embedding-4B-GGUF\", ...         \"filename\": \"Qwen3-Embedding-4B-Q4_K_M.gguf\", ...         \"n_ctx\": 512, ...         \"n_batch\": 64 ...     } ... ) await embeddings.embed([\"Hello, world!\", \"Goodbye, world!\"])</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppEmbeddings.llm","level":4,"title":"<code>llm = self._instantiate_client(embedding=True)</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppEmbeddings.model_kwargs","level":4,"title":"<code>model_kwargs = param.Dict(default={'default': {'repo_id': 'Qwen/Qwen3-Embedding-4B-GGUF', 'filename': 'Qwen3-Embedding-4B-Q4_K_M.gguf'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppEmbeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin","level":3,"title":"<code>LlamaCppMixin</code>","text":"<p>               Bases: <code>ServiceMixin</code></p> <p>Mixin class for llama-cpp-python functionality that can be shared between LLM implementations and embedding classes.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.n_batch","level":4,"title":"<code>n_batch = param.Integer(default=512, doc='\\n        Batch size for processing.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.n_ctx","level":4,"title":"<code>n_ctx = param.Integer(default=2048, doc='\\n        Context length for the model.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.n_gpu_layers","level":4,"title":"<code>n_gpu_layers = param.Integer(default=(-1), doc='\\n        Number of layers to offload to GPU. -1 for all layers.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.seed","level":4,"title":"<code>seed = param.Integer(default=128, doc='\\n        Random seed for reproducible outputs.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.use_mlock","level":4,"title":"<code>use_mlock = param.Boolean(default=True, doc='\\n        Force system to keep model in RAM rather than swapping.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.verbose","level":4,"title":"<code>verbose = param.Boolean(default=False, doc='\\n        Enable verbose output from llama.cpp.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.LlamaCppMixin.resolve_model_spec","level":4,"title":"<code>resolve_model_spec(model_spec, base_model_kwargs)</code>","text":"<p>Resolve a model specification string into model kwargs with repo_id/filename. Handles formats like \"repo/model:chat_format\" or \"repo/model\".</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings","level":3,"title":"<code>NumpyEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code></p> <p>NumpyEmbeddings is a simple embeddings class that uses a hash function to map n-grams to the vocabulary.</p> <p>The default hash function uses MD5 for deterministic, stable hashing across Python sessions. You can override with a custom hash function if needed, e.g. using murmurhash from the <code>mmh3</code> package.</p> <p>:Example:</p> <p>embeddings = NumpyEmbeddings() await embeddings.embed([\"Hello, world!\", \"Goodbye, world!\"])</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings.embedding_dim","level":4,"title":"<code>embedding_dim = param.Integer(default=256, doc='The size of the embedding vector')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings.hash_func","level":4,"title":"<code>hash_func = param.Callable(default=_deterministic_hash, doc='\\n        The hashing function to use to map n-grams to the vocabulary.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings.seed","level":4,"title":"<code>seed = param.Integer(default=42, doc='The seed for the random number generator.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings.vocab_size","level":4,"title":"<code>vocab_size = param.Integer(default=5000, doc='The size of the vocabulary.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.NumpyEmbeddings.get_char_ngrams","level":4,"title":"<code>get_char_ngrams(text, n=3)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIEmbeddings","level":3,"title":"<code>OpenAIEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code>, <code>OpenAIMixin</code></p> <p>OpenAIEmbeddings is an embeddings class that uses the OpenAI API to generate embeddings.</p> <p>:Example:</p> <p>embeddings = OpenAIEmbeddings() await embeddings.embed([\"Hello, world!\", \"Goodbye, world!\"])</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIEmbeddings.client","level":4,"title":"<code>client = self._instantiate_client(async_client=True)</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIEmbeddings.model","level":4,"title":"<code>model = param.String(default='text-embedding-3-small', doc='The OpenAI model to use.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIEmbeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIMixin","level":3,"title":"<code>OpenAIMixin</code>","text":"<p>               Bases: <code>ServiceMixin</code></p> <p>Mixin class for OpenAI functionality that can be shared between LLM implementations and embedding classes.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIMixin.api_key","level":4,"title":"<code>api_key = param.String(default=None, doc='\\n        The OpenAI API key. If not provided, will use OPENAI_API_KEY env var.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIMixin.endpoint","level":4,"title":"<code>endpoint = param.String(default=None, doc='\\n        The OpenAI API endpoint. If not provided, uses default OpenAI endpoint.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings.OpenAIMixin.organization","level":4,"title":"<code>organization = param.String(default=None, doc='\\n        The OpenAI organization to charge.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.embeddings._deterministic_hash","level":3,"title":"<code>_deterministic_hash(text)</code>","text":"<p>Deterministic hash function using MD5. Returns a stable integer hash that is consistent across Python sessions.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store","level":2,"title":"<code>lumen.ai.vector_store</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.PROMPTS_DIR","level":3,"title":"<code>PROMPTS_DIR = THIS_DIR / 'prompts'</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore","level":3,"title":"<code>DuckDBVectorStore</code>","text":"<p>               Bases: <code>VectorStore</code></p> <p>Vector store implementation using DuckDB for persistent storage.</p> <p>:Example:</p> <p>.. code-block:: python</p> <pre><code>from lumen.ai.vector_store import DuckDBStore\n\nvector_store = DuckDBStore(uri=':memory:)\nvector_store.add_file('https://lumen.holoviz.org')\nvector_store.query('LLM', threshold=0.1)\n</code></pre> <p>Use upsert to avoid adding duplicate content:</p> <p>.. code-block:: python</p> <pre><code>from lumen.ai.vector_store import DuckDBStore\n\nvector_store = DuckDBStore(uri=':memory:)\nvector_store.upsert([{'text': 'Hello!', 'metadata': {'source': 'greeting'}}])\n# Won't add duplicate if content is similar and metadata matches\nvector_store.upsert([{'text': 'Hello!', 'metadata': {'source': 'greeting'}}])\n</code></pre>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.connection","level":4,"title":"<code>connection = connection</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.embeddings","level":4,"title":"<code>embeddings = param.ClassSelector(class_=Embeddings, default=None, allow_None=True, doc='Embeddings object for text processing. If None and a URI is provided, loads from the database; else NumpyEmbeddings.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.max_concurrent","level":4,"title":"<code>max_concurrent = param.Integer(default=1, bounds=(1, None), doc='\\n        Maximum number of files to process concurrently in add_directory.\\n        Default is 1 for DuckDB due to VSS extension limitations with concurrent writes.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.read_only","level":4,"title":"<code>read_only = param.Boolean(default=False, doc='Whether to open the database in read-only mode')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.uri","level":4,"title":"<code>uri = param.String(default=':memory:', doc='The URI of the DuckDB database')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.clear","level":4,"title":"<code>clear()</code>","text":"<p>Clear all entries and reset sequence.</p> <p>Drops the documents table and sequence, then sets up the database again.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.close","level":4,"title":"<code>close()</code>","text":"<p>Close the DuckDB connection.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.delete","level":4,"title":"<code>delete(ids)</code>","text":"<p>Delete items from the vector store by their IDs.</p> <p>Parameters     ids: List of IDs to delete.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.filter_by","level":4,"title":"<code>filter_by(filters, limit=None, offset=0)</code>","text":"<p>Filter items by metadata without using embeddings similarity.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>Dictionary of metadata key-value pairs to filter by.</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of results to return. If None, returns all matches.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Number of results to skip (for pagination).</p> <code>0</code> <p>Returns:</p> Type Description <code>List of results with 'id', 'text', and 'metadata'.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.query","level":4,"title":"<code>query(text, top_k=5, filters=None, threshold=-1.0)</code>  <code>async</code>","text":"<p>Query the vector store for similar items.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The query text.</p> required <code>top_k</code> <code>int</code> <p>Number of top results to return.</p> <code>5</code> <code>filters</code> <code>dict | None</code> <p>Optional metadata filters.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score required for a result to be included.</p> <code>-1.0</code> <p>Returns:</p> Type Description <code>List of results with 'id', 'text', 'metadata', and 'similarity' score.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.DuckDBVectorStore.upsert","level":4,"title":"<code>upsert(items, situate=None)</code>  <code>async</code>","text":"<p>Add items to the vector store if similar items don't exist, update them if they do.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict]</code> <p>List of dictionaries containing 'text' and optional 'metadata'.</p> required <code>situate</code> <code>bool | None</code> <p>Whether to insert a <code>llm_context</code> key in the metadata containing contextual about the chunks. If None, uses the class default.</p> <code>None</code> <p>Returns:</p> Type Description <code>List of assigned IDs for the added or updated items.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.Embeddings","level":3,"title":"<code>Embeddings</code>","text":"<p>               Bases: <code>Parameterized</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.Embeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Generate embeddings for a list of texts.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.LLMUser","level":3,"title":"<code>LLMUser</code>","text":"<p>               Bases: <code>Parameterized</code></p> <p>Mixin for classes that use prompts with LLMs. Provides parameters and methods for prompt templating and LLM interactions.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.LLMUser.llm","level":4,"title":"<code>llm = param.ClassSelector(class_=Llm, doc='\\n        The LLM implementation to query.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.LLMUser.llm_spec_key","level":4,"title":"<code>llm_spec_key</code>  <code>property</code>","text":"<p>Converts class name to a snake_case model identifier. Used for looking up model configurations in model_kwargs.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.LLMUser.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'Actor' / 'main.jinja2'}}, doc=\"\\n        A dictionary of prompts, indexed by prompt name.\\n        Each prompt should be defined as a dictionary containing a template\\n        'template' and optionally a 'model' and 'tools'.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.LLMUser.steps_layout","level":4,"title":"<code>steps_layout = param.ClassSelector(default=None, class_=(ListLike, NamedListLike), allow_None=True, doc='\\n        The layout progress updates will be streamed to.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.LLMUser.template_overrides","level":4,"title":"<code>template_overrides = param.Dict(default={}, doc=\"\\n        Overrides the template's blocks (instructions, context, tools, examples).\\n        Is a nested dictionary with the prompt name (e.g. main) as the key\\n        and the block names as the inner keys with the new content as the\\n        values.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings","level":3,"title":"<code>NumpyEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code></p> <p>NumpyEmbeddings is a simple embeddings class that uses a hash function to map n-grams to the vocabulary.</p> <p>The default hash function uses MD5 for deterministic, stable hashing across Python sessions. You can override with a custom hash function if needed, e.g. using murmurhash from the <code>mmh3</code> package.</p> <p>:Example:</p> <p>embeddings = NumpyEmbeddings() await embeddings.embed([\"Hello, world!\", \"Goodbye, world!\"])</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings.embedding_dim","level":4,"title":"<code>embedding_dim = param.Integer(default=256, doc='The size of the embedding vector')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings.hash_func","level":4,"title":"<code>hash_func = param.Callable(default=_deterministic_hash, doc='\\n        The hashing function to use to map n-grams to the vocabulary.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings.seed","level":4,"title":"<code>seed = param.Integer(default=42, doc='The seed for the random number generator.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings.vocab_size","level":4,"title":"<code>vocab_size = param.Integer(default=5000, doc='The size of the vocabulary.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings.embed","level":4,"title":"<code>embed(texts)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyEmbeddings.get_char_ngrams","level":4,"title":"<code>get_char_ngrams(text, n=3)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore","level":3,"title":"<code>NumpyVectorStore</code>","text":"<p>               Bases: <code>VectorStore</code></p> <p>Vector store implementation using NumPy for in-memory storage.</p> <p>:Example:</p> <p>.. code-block:: python</p> <pre><code>from lumen.ai.vector_store import NumpyVectorStore\n\nvector_store = NumpyVectorStore()\nvector_store.add_file('https://lumen.holoviz.org')\nvector_store.query('LLM', threshold=0.1)\n</code></pre> <p>Use upsert to avoid adding duplicate content:</p> <p>.. code-block:: python</p> <pre><code>from lumen.ai.vector_store import NumpyVectorStore\n\nvector_store = NumpyVectorStore()\nvector_store.upsert([{'text': 'Hello!', 'metadata': {'source': 'greeting'}}])\n# Won't add duplicate if content is similar and metadata matches\nvector_store.upsert([{'text': 'Hello!', 'metadata': {'source': 'greeting'}}])\n</code></pre>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.ids","level":4,"title":"<code>ids = []</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.metadata","level":4,"title":"<code>metadata = []</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.texts","level":4,"title":"<code>texts = []</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.vectors","level":4,"title":"<code>vectors = None</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.clear","level":4,"title":"<code>clear()</code>","text":"<p>Clear all items from the vector store.</p> <p>Resets the vectors, texts, metadata, and IDs to their initial empty states.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.close","level":4,"title":"<code>close()</code>","text":"<p>Close the vector store and release any resources.</p> <p>For NumpyVectorStore, this clears vectors to free memory.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.delete","level":4,"title":"<code>delete(ids)</code>","text":"<p>Delete items from the vector store by their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[int]</code> <p>List of IDs to delete.</p> required","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.filter_by","level":4,"title":"<code>filter_by(filters, limit=None, offset=0)</code>","text":"<p>Filter items by metadata without using embeddings similarity.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>Dictionary of metadata key-value pairs to filter by.</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of results to return. If None, returns all matches.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Number of results to skip (for pagination).</p> <code>0</code> <p>Returns:</p> Type Description <code>List of results with 'id', 'text', and 'metadata'.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.query","level":4,"title":"<code>query(text, top_k=5, filters=None, threshold=-1.0)</code>  <code>async</code>","text":"<p>Query the vector store for similar items.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The query text.</p> required <code>top_k</code> <code>int</code> <p>Number of top results to return.</p> <code>5</code> <code>filters</code> <code>dict | None</code> <p>Optional metadata filters.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score required for a result to be included.</p> <code>-1.0</code> <p>Returns:</p> Type Description <code>List of results with 'id', 'text', 'metadata', and 'similarity' score.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.NumpyVectorStore.upsert","level":4,"title":"<code>upsert(items, situate=None)</code>  <code>async</code>","text":"<p>Add items to the vector store if similar items don't exist, update them if they do.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict]</code> <p>List of dictionaries containing 'text' and optional 'metadata'.</p> required <code>situate</code> <code>bool | None</code> <p>Whether to insert a <code>llm_context</code> key in the metadata containing contextual about the chunks. If None, uses the class default.</p> <code>None</code> <p>Returns:</p> Type Description <code>List of assigned IDs for the added or updated items.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore","level":3,"title":"<code>VectorStore</code>","text":"<p>               Bases: <code>LLMUser</code></p> <p>Abstract base class for a vector store.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.chunk_func","level":4,"title":"<code>chunk_func = param.Callable(default=None, doc='\\n        The function used to split documents into chunks.\\n        Must accept `text`. If None, defaults to semchunk.chunkerify\\n        with the chunk_size.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.chunk_func_kwargs","level":4,"title":"<code>chunk_func_kwargs = param.Dict(default={}, doc='\\n        Additional keyword arguments to pass to the chunking function.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.chunk_size","level":4,"title":"<code>chunk_size = param.Integer(default=512, doc='Maximum size of text chunks to split documents into.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.chunk_tokenizer","level":4,"title":"<code>chunk_tokenizer = param.String(default='gpt-4o-mini', doc='\\n        If using the default chunk_func, the tokenizer used to split documents into chunks.\\n        Must be a valid tokenizer name from the transformers or tiktoken library.\\n        Otherwise, please pass in a custom chunk_func.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.embeddings","level":4,"title":"<code>embeddings = param.ClassSelector(class_=Embeddings, default=(NumpyEmbeddings()), allow_None=True, doc='Embeddings object for text processing.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.excluded_metadata","level":4,"title":"<code>excluded_metadata = param.List(default=['llm_context'], doc='List of metadata keys to exclude when creating the embeddings.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.max_concurrent","level":4,"title":"<code>max_concurrent = param.Integer(default=5, bounds=(1, None), doc=\"\\n        Maximum number of files to process concurrently in add_directory.\\n        Set to 1 for backends that don't support concurrent writes.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'VectorStore' / 'main.jinja2'}, 'should_situate': {'template': PROMPTS_DIR / 'VectorStore' / 'should_situate.jinja2', 'response_model': YesNo}}, doc=\"\\n        A dictionary of prompts used by the vector store, indexed by prompt name.\\n        Each prompt should be defined as a dictionary containing a template\\n        'template' and optionally a 'model' and 'tools'.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.situate","level":4,"title":"<code>situate = param.Boolean(default=False, doc='\\n        Whether to insert a `llm_context` key in the metadata containing\\n        contextual about the chunks.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.add","level":4,"title":"<code>add(items, force_ids=None, situate=None)</code>  <code>async</code>","text":"<p>Add items to the vector store.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict]</code> <p>List of dictionaries containing 'text' and optional 'metadata'.</p> required <code>force_ids</code> <code>list[int] | None</code> <p>Optional list of IDs to use instead of generating new ones.</p> <code>None</code> <code>situate</code> <code>bool | None</code> <p>Whether to insert a <code>llm_context</code> key in the metadata containing contextual about the chunks. If None, uses the class default.</p> <code>None</code> <p>Returns:</p> Type Description <code>List of assigned IDs for the added items.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.add_directory","level":4,"title":"<code>add_directory(directory, pattern='*', exclude_patterns=None, metadata=None, situate=None, upsert=False, raise_on_error=False, max_concurrent=None)</code>  <code>async</code>","text":"<p>Recursively add files from a directory that match the pattern and don't match exclude patterns.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Union[str, PathLike]</code> <p>The path to the directory to search for files.</p> required <code>pattern</code> <code>str</code> <p>Glob pattern to match files against (e.g., \".txt\", \".py\"). Default is \"*\".</p> <code>'*'</code> <code>exclude_patterns</code> <code>Optional[List[str]]</code> <p>List of patterns to exclude. Files matching any of these patterns will be skipped.</p> <code>None</code> <code>metadata</code> <code>Optional[dict[str, Any]]</code> <p>Base metadata to apply to all files. Will be extended with filename-specific metadata.</p> <code>None</code> <code>situate</code> <code>Optional[bool]</code> <p>Whether to insert a <code>llm_context</code> key in the metadata. If None, uses the class default.</p> <code>None</code> <code>upsert</code> <code>bool</code> <p>If True, will update existing items if similar content is found. Default is False.</p> <code>False</code> <code>raise_on_error</code> <p>If True, will raise an error if any file fails to process. Default is False.</p> <code>False</code> <code>max_concurrent</code> <code>int | None</code> <p>Maximum number of files to process concurrently. If None, uses self.max_concurrent.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[int]</code> <p>Combined list of IDs for all added files.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.add_file","level":4,"title":"<code>add_file(filename, ext=None, metadata=None, situate=None, upsert=False)</code>  <code>async</code>","text":"<p>Adds a file or a URL to the collection.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | IO | Any | PathLike</code> <p>The path to the file, a file-like object or a URL to be added.</p> required <code>ext</code> <code>str | None</code> <p>The file extension to associate with the added file. If not provided, it will be determined from the file or URL.</p> <code>None</code> <code>metadata</code> <code>dict | None</code> <p>A dictionary containing metadata related to the file (e.g., title, author, description). Defaults to None.</p> <code>None</code> <code>situate</code> <code>bool | None</code> <p>Whether to insert a <code>llm_context</code> key in the metadata containing contextual about the chunks. If None, uses the class default.</p> <code>None</code> <code>upsert</code> <code>bool</code> <p>If True, will update existing items if similar content is found. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>List of assigned IDs for the added items.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.clear","level":4,"title":"<code>clear()</code>  <code>abstractmethod</code>","text":"<p>Clear all items from the vector store.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.close","level":4,"title":"<code>close()</code>  <code>abstractmethod</code>","text":"<p>Close the vector store and release any resources.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.delete","level":4,"title":"<code>delete(ids)</code>  <code>abstractmethod</code>","text":"<p>Delete items from the vector store by their IDs.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[int]</code> <p>List of IDs to delete.</p> required","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.filter_by","level":4,"title":"<code>filter_by(filters, limit=None, offset=0)</code>  <code>abstractmethod</code>","text":"<p>Filter items by metadata without using embeddings similarity.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict</code> <p>Dictionary of metadata key-value pairs to filter by.</p> required <code>limit</code> <code>int | None</code> <p>Maximum number of results to return. If None, returns all matches.</p> <code>None</code> <code>offset</code> <code>int</code> <p>Number of results to skip (for pagination).</p> <code>0</code> <p>Returns:</p> Type Description <code>List of results with 'id', 'text', and 'metadata'.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.query","level":4,"title":"<code>query(text, top_k=5, filters=None, threshold=-1.0)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Query the vector store for similar items.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The query text.</p> required <code>top_k</code> <code>int</code> <p>Number of top results to return.</p> <code>5</code> <code>filters</code> <code>dict | None</code> <p>Optional metadata filters.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Minimum similarity score required for a result to be included.</p> <code>-1.0</code> <p>Returns:</p> Type Description <code>List of results with 'id', 'text', 'metadata', and 'similarity' score.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.should_situate_chunk","level":4,"title":"<code>should_situate_chunk(chunk)</code>  <code>async</code>","text":"<p>Determine whether a chunk should be situated based on its content.</p> <p>Parameters:</p> Name Type Description Default <code>chunk</code> <code>str</code> <p>The chunk text to evaluate</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the chunk should be situated</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.VectorStore.upsert","level":4,"title":"<code>upsert(items, situate=None)</code>  <code>async</code>","text":"<p>Add items to the vector store if similar items don't exist, update them if they do.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>list[dict]</code> <p>List of dictionaries containing 'text' and optional 'metadata'.</p> required <code>situate</code> <code>bool | None</code> <p>Whether to insert a <code>llm_context</code> key in the metadata containing contextual about the chunks. If None, uses the class default.</p> <code>None</code> <p>Returns:</p> Type Description <code>List of assigned IDs for the added or updated items.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.YesNo","level":3,"title":"<code>YesNo</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.YesNo.yes","level":4,"title":"<code>yes = Field(description='True if yes, otherwise False.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.vector_store.log_debug","level":3,"title":"<code>log_debug(msg, offset=24, prefix='', suffix='', show_sep=None, show_length=False)</code>","text":"<p>Log a debug message with a separator line above and below.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils","level":2,"title":"<code>lumen.ai.utils</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.LineEdit","level":3,"title":"<code>LineEdit = Annotated[InsertLine | ReplaceLine | DeleteLine, Field(discriminator='op')]</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.PROMPTS_DIR","level":3,"title":"<code>PROMPTS_DIR = THIS_DIR / 'prompts'</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.SOURCE_TABLE_SEPARATOR","level":3,"title":"<code>SOURCE_TABLE_SEPARATOR = ' ‚¶ô '</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.UNRECOVERABLE_ERRORS","level":3,"title":"<code>UNRECOVERABLE_ERRORS = (ImportError, LlmSetupError, RecursionError, MissingContextError, asyncio.CancelledError, UserCancelledError)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils._BLOCK_RE","level":3,"title":"<code>_BLOCK_RE = re.compile('{%-?\\\\s*block\\\\s+(?P&lt;name&gt;\\\\w+)\\\\s*-?%}(?P&lt;body&gt;.*?){%-?\\\\s*endblock(?:\\\\s+(?P=name))?\\\\s*-?%}', re.DOTALL)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.log","level":3,"title":"<code>log = getLogger(__name__)</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.BlockNameCollector","level":3,"title":"<code>BlockNameCollector</code>","text":"<p>               Bases: <code>NodeVisitor</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.BlockNameCollector.blocks","level":4,"title":"<code>blocks = []</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.BlockNameCollector.visit_Block","level":4,"title":"<code>visit_Block(node)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.DeleteLine","level":3,"title":"<code>DeleteLine</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.DeleteLine.line_no","level":4,"title":"<code>line_no = Field(ge=1, description='The 1-based line number to delete.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.DeleteLine.op","level":4,"title":"<code>op = 'delete'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Details","level":3,"title":"<code>Details</code>","text":"<p>               Bases: <code>JSComponent</code></p> <p>A component wrapper for the HTML details element with proper content rendering.</p> <p>This component provides an expandable details/summary element that can be used to hide/show content. It supports any Panel component as content, including Markdown panes for rendering markdown content.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Details.collapsed","level":4,"title":"<code>collapsed = param.Boolean(default=True, doc='\\n        Whether the details element is collapsed by default.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Details.object","level":4,"title":"<code>object = Child(doc='\\n        The content to display within the details element. Can be any Panel component,\\n        including a Markdown pane for rendering markdown content.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Details.title","level":4,"title":"<code>title = param.String(default='Details', doc='\\n        The text to display in the summary element (the clickable header).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.InsertLine","level":3,"title":"<code>InsertLine</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.InsertLine.line","level":4,"title":"<code>line = Field(min_length=1, description='Content for the new line (must be non-empty).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.InsertLine.line_no","level":4,"title":"<code>line_no = Field(ge=1, description='Insert BEFORE this 1-based line number. Use line_no == len(lines) to append at the end.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.InsertLine.op","level":4,"title":"<code>op = 'insert'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.MissingContextError","level":3,"title":"<code>MissingContextError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raise to indicate missing context for a query.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline","level":3,"title":"<code>Pipeline</code>","text":"<p>               Bases: <code>Viewer</code>, <code>Component</code></p> <p><code>Pipeline</code> encapsulates filters and transformations applied to a :class:<code>lumen.sources.base.Source</code> table.</p> <p>A <code>Pipeline</code> ingests data from a :class:<code>lumen.sources.base.Source</code> table or another <code>Pipeline</code> applying the declared :class:<code>lumen.filters.base.Filter</code>, :class:<code>lumen.transforms.base.Transform</code> and :class:<code>lumen.transforms.sql.SQLTransform</code> definitions. It can be used to drive one or more visual outputs or leveraged as a standalone component to encapsulate multiple data processing steps.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.auto_update","level":4,"title":"<code>auto_update = param.Boolean(default=True, constant=True, doc='\\n        Whether changes in filters, transforms and references automatically\\n        trigger updates in the data or whether an update has to be triggered\\n        manually using the update event or the update button in the UI.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.control_panel","level":4,"title":"<code>control_panel</code>  <code>property</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.data","level":4,"title":"<code>data = DataFrame(doc='The current data on this source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.filters","level":4,"title":"<code>filters = param.List(item_type=Filter, doc='\\n        A list of Filters to apply to the source data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.pipeline","level":4,"title":"<code>pipeline = param.ClassSelector(class_=None, doc='\\n        Optionally a pipeline may be chained to another pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.refs","level":4,"title":"<code>refs</code>  <code>property</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.schema","level":4,"title":"<code>schema = param.Dict(doc='The schema of the input data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.source","level":4,"title":"<code>source = param.ClassSelector(class_=Source, doc='\\n        The Source this pipeline is fed by.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.sql_transforms","level":4,"title":"<code>sql_transforms = param.List(item_type=SQLTransform, doc='\\n        A list of SQLTransforms to apply to the source data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.table","level":4,"title":"<code>table = param.String(doc='\\n        The name of the table driving this pipeline.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.transforms","level":4,"title":"<code>transforms = param.List(item_type=Transform, doc='\\n        A list of Transforms to apply to the source data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.update","level":4,"title":"<code>update = param.Event(label='Apply update', doc='\\n        Update event trigger (if manual update is set).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.add_filter","level":4,"title":"<code>add_filter(filt, field=None, **kwargs)</code>","text":"<p>Add a filter to the pipeline.</p> Arguments <p>filt: Filter | Type[Filter]    The filter instance or filter type to add. field: str | None    The field to filter on (required to instantiate Filter type).</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.add_transform","level":4,"title":"<code>add_transform(transform, **kwargs)</code>","text":"<p>Add a (SQL)Transform to the pipeline.</p> Arguments <p>filt: Transform    The Transform instance to add.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.chain","level":4,"title":"<code>chain(filters=None, transforms=None, sql_transforms=None, **kwargs)</code>","text":"<p>Chains additional filtering, transform and sql_transform operations on an existing pipeline. Note that if one or more sql_transforms are provided the existing table will be mirrored into a DuckDB database.</p> Arguments <p>filters: List[Filter] | None   Additional filters to apply on top of existing pipeline. transforms: List[Transform] | None   Additional transforms to apply on top of existing pipeline. sql_transforms: List[SQLTransform] | None   Additional filters to apply on top of existing pipeline.</p> <p>Returns:</p> Type Description <code>Pipeline</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.clone","level":4,"title":"<code>clone(**params)</code>","text":"<p>Create a new instance of the pipeline with optionally overridden parameter values.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.from_spec","level":4,"title":"<code>from_spec(spec, source=None, source_filters=None)</code>  <code>classmethod</code>","text":"<p>Creates a Pipeline from a specification.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict or str</code> <p>Specification declared as a dictionary of parameter values or a string referencing a source in the sources dictionary.</p> required <p>Returns:</p> Type Description <code>Resolved and instantiated Pipeline object</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.get_schema","level":4,"title":"<code>get_schema()</code>","text":"<p>Generates a JSON schema for the current data held by the Pipeline.</p> <p>Returns:</p> Name Type Description <code>schema</code> <code>dict[str, any]</code> <p>JSON schema for each column in the current data.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.precache","level":4,"title":"<code>precache(queries)</code>","text":"<p>Populates the cache of the :class:<code>lumen.sources.base.Source</code> with the provided queries.</p> <p>Queries can be provided in two formats:</p> <ul> <li> <p>A dictionary containing 'filters' and 'variables'     dictionaries each containing lists of values to compute     a cross-product for, e.g.</p> <p>{     'filters': {       ': ['a', 'b', 'c', ...],       ...     },     'variables': {       : [0, 2, 4, ...],       ...     }   }   - A list containing dictionaries of explicit values for each filter and variables. <p>[{      'filters': {: 'a'},      'variables': {: 0}    },    {      'filters': {: 'a'},      'variables': {: 1}    },    ...   ]","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.to_spec","level":4,"title":"<code>to_spec(context=None)</code>","text":"<p>Exports the full specification to reconstruct this component.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>dict[str, Any] | None</code> <p>Context contains the specification of all previously serialized components, e.g. to allow resolving of references.</p> <code>None</code> <p>Returns:</p> Type Description <code>Declarative specification of this component.</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.traverse","level":4,"title":"<code>traverse(type)</code>","text":"<p>Returns all Filter or Transform objects in a potentially chained pipeline.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Pipeline.validate","level":4,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.ReplaceLine","level":3,"title":"<code>ReplaceLine</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.ReplaceLine.line","level":4,"title":"<code>line = Field(description='The new content for the line (empty string is allowed).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.ReplaceLine.line_no","level":4,"title":"<code>line_no = Field(ge=1, description='The 1-based line number to replace.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.ReplaceLine.op","level":4,"title":"<code>op = 'replace'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.RetriesExceededError","level":3,"title":"<code>RetriesExceededError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when the maximum number of retries is exceeded.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source","level":3,"title":"<code>Source</code>","text":"<p>               Bases: <code>MultiTypeComponent</code></p> <p><code>Source</code> components provide allow querying all kinds of data.</p> <p>A <code>Source</code> can return one or more tables queried using the <code>.get_tables</code> method, a description of the data returned by each table in the form of a JSON schema accessible via the <code>.get_schema</code> method and lastly a <code>.get</code> method that allows filtering the data.</p> <p>The Source base class also implements both in-memory and disk caching which can be enabled if a <code>cache_dir</code> is provided. Data cached to disk is stored as parquet files.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.cache_data","level":4,"title":"<code>cache_data = param.Boolean(default=True, doc='\\n        Whether to cache actual data.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.cache_dir","level":4,"title":"<code>cache_dir = param.String(default=None, doc='\\n        Whether to enable local cache and write file to disk.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.cache_metadata","level":4,"title":"<code>cache_metadata = param.Boolean(default=True, doc='\\n        Whether to cache metadata.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.cache_per_query","level":4,"title":"<code>cache_per_query = param.Boolean(default=True, doc='\\n        Whether to query the whole dataset or individual queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.cache_schema","level":4,"title":"<code>cache_schema = param.Boolean(default=True, doc='\\n        Whether to cache table schemas.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.cache_with_dask","level":4,"title":"<code>cache_with_dask = param.Boolean(default=True, doc='\\n        Whether to read and write cache files with dask if available.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.metadata","level":4,"title":"<code>metadata = param.Dict(default={}, doc='\\n        Optional metadata about the source tables. Should follow the format:\\n        {\"table_name\": {\"description\": ..., \"columns\": {\"column_name\": \"...\"}}}')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.metadata_func","level":4,"title":"<code>metadata_func = param.Callable(default=None, doc='\\n        Function to implement custom metadata lookup for tables.\\n        Given a list of tables it should return a dictionary of the form:\\n\\n        {\\n            &lt;table&gt;: {\"description\": ..., \"columns\": {\"column_name\": \"...\"}}\\n        }\\n\\n        May be used to override the default _get_table_metadata\\n        implementation of the Source.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.panel","level":4,"title":"<code>panel</code>  <code>property</code>","text":"<p>A Source can return a Panel object which displays information about the Source or controls how the Source queries data.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.root","level":4,"title":"<code>root = param.ClassSelector(class_=Path, precedence=(-1), doc='\\n        Root folder of the cache_dir, default is config.root')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.shared","level":4,"title":"<code>shared = param.Boolean(default=False, doc='\\n        Whether the Source can be shared across all instances of the\\n        dashboard. If set to `True` the Source will be loaded on\\n        initial server load.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.source_type","level":4,"title":"<code>source_type = None</code>  <code>class-attribute</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.clear_cache","level":4,"title":"<code>clear_cache(*events)</code>","text":"<p>Clears any cached data.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.from_spec","level":4,"title":"<code>from_spec(spec)</code>  <code>classmethod</code>","text":"<p>Creates a Source object from a specification. If a Source specification references other sources these may be supplied in the sources dictionary and be referenced by name.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict or str</code> <p>Specification declared as a dictionary of parameter values or a string referencing a source in the sources dictionary.</p> required <p>Returns:</p> Type Description <code>Resolved and instantiated Source object</code>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.get","level":4,"title":"<code>get(table, **query)</code>","text":"<p>Return a table; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.get_async","level":4,"title":"<code>get_async(table, **query)</code>  <code>async</code>","text":"<p>Return a table asynchronously; optionally filtered by the given query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table to query</p> required <code>query</code> <code>dict</code> <p>A dictionary containing all the query parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the queried table.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.get_metadata","level":4,"title":"<code>get_metadata(table)</code>","text":"<p>Returns metadata for one, multiple or all tables provided by the source.</p> <p>The metadata for a table is structured as:</p> <p>{     \"description\": ...,     \"columns\": {         : {            \"description\": ...,            \"data_type\": ...,         }     },     **other_metadata } <p>If a list of tables or no table is provided the metadata is nested one additional level:</p> <p>{     \"table_name\": {         {             \"description\": ...,             \"columns\": {                 : {                 \"description\": ...,                 \"data_type\": ...,                 }             },             **other_metadata         }     } } <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | list[str] | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> required <p>Returns:</p> Name Type Description <code>metadata</code> <code>dict</code> <p>Dictionary of metadata indexed by table (if no table was was provided or individual table metdata.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.get_schema","level":4,"title":"<code>get_schema(table=None, limit=None, shuffle=False)</code>","text":"<p>Returns JSON schema describing the tables returned by the Source.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str | None</code> <p>The name of the table to return the schema for. If None returns schema for all available tables.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limits the number of rows considered for the schema calculation</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>JSON schema(s) for one or all the tables.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.get_tables","level":4,"title":"<code>get_tables()</code>","text":"<p>Returns the list of tables available on this source.</p> <p>Returns:</p> Type Description <code>list</code> <p>The list of available tables on this source.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.Source.validate","level":4,"title":"<code>validate(spec, context=None)</code>  <code>classmethod</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.apply_changes","level":3,"title":"<code>apply_changes(lines, edits)</code>","text":"<p>Apply a Patch to a list of lines (no trailing newline characters in elements). Indices in the Patch refer to the ORIGINAL <code>lines</code>.</p> <p>Strategy:   - To keep indices stable, apply all non-insert edits in DESCENDING order of line_no.   - Apply inserts in ASCENDING order of line_no (grouped), inserting BEFORE that index.     Inserts at the same index are applied in the order they appear in <code>patch.edits</code>.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.cast_value","level":3,"title":"<code>cast_value(value)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.class_name_to_llm_spec_key","level":3,"title":"<code>class_name_to_llm_spec_key(class_name)</code>","text":"<p>Convert class name to llm_spec_key using the same logic as Actor.llm_spec_key. Removes \"Agent\" suffix and converts to snake_case.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.clean_sql","level":3,"title":"<code>clean_sql(sql_expr, dialect=None, prettify=False)</code>","text":"<p>Cleans up a SQL expression generated by an LLM by removing backticks, fencing and extraneous space and semi-colons.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.describe_data","level":3,"title":"<code>describe_data(df, enum_limit=3, reduce_enums=True)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.extract_block_source","level":3,"title":"<code>extract_block_source(template_path, block_name, relative_to=PROMPTS_DIR)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.format_exception","level":3,"title":"<code>format_exception(exc, limit=0)</code>","text":"<p>Format and return a string representation of an exception.</p> <p>Parameters:</p> Name Type Description Default <code>exc</code> <code>Exception</code> <p>The exception to be formatted.</p> required <code>limit</code> <code>int</code> <p>The maximum number of layers of traceback to include in the output. Default is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>A formatted string describing the exception and its traceback.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.format_float","level":3,"title":"<code>format_float(num)</code>","text":"<p>Process a float value, returning numeric types instead of strings. For very large/small numbers, returns a float that will display in scientific notation.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.fuse_messages","level":3,"title":"<code>fuse_messages(messages, max_user_messages=2)</code>","text":"<p>Fuses the chat history into a single system message, followed by the last user message. This function is reusable across different components that need to combine multiple messages into a simplified format for LLM processing.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[dict]</code> <p>List of message dictionaries with 'role' and 'content' keys</p> required <code>max_user_messages</code> <code>int</code> <p>Maximum number of user messages to include in the history</p> <code>2</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>Processed messages with the chat history as a system message</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.generate_diff","level":3,"title":"<code>generate_diff(old_text, new_text, filename='spec')</code>","text":"<p>Generate a unified diff between old and new text.</p> <p>Parameters:</p> Name Type Description Default <code>old_text</code> <code>str</code> <p>The original text</p> required <code>new_text</code> <code>str</code> <p>The modified text</p> required <code>filename</code> <code>str</code> <p>The filename to use in the diff header</p> <code>'spec'</code> <p>Returns:</p> Type Description <code>str</code> <p>A unified diff string showing the changes</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.get_block_names","level":3,"title":"<code>get_block_names(template_path, relative_to=PROMPTS_DIR)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.get_data","level":3,"title":"<code>get_data(pipeline)</code>  <code>async</code>","text":"<p>A wrapper be able to use asyncio.to_thread and not block the main thread when calling pipeline.data</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.get_pipeline","level":3,"title":"<code>get_pipeline(**kwargs)</code>  <code>async</code>","text":"<p>A wrapper be able to use asyncio.to_thread and not block the main thread when calling Pipeline</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.get_root_exception","level":3,"title":"<code>get_root_exception(e, depth=5, exceptions=None)</code>","text":"<p>Recursively get the root cause of an exception up to a specified depth.</p> <p>Parameters:</p> Name Type Description Default <code>e</code> <code>Exception</code> <p>The exception to analyze</p> required <code>depth</code> <code>int</code> <p>Maximum recursion depth to avoid infinite loops</p> <code>5</code> <code>exceptions</code> <code>list[Exception]</code> <p>List of exception types to consider as root causes. If None, all exceptions are considered.</p> <code>None</code> <p>Returns:</p> Type Description <code>Exception | None</code> <p>The root cause exception if found, otherwise None</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.get_schema","level":3,"title":"<code>get_schema(source, table=None, include_type=True, include_min_max=True, include_enum=True, include_count=False, include_empty_fields=False, include_nans=False, reduce_enums=True, shuffle=True, **get_kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.get_template_loader","level":3,"title":"<code>get_template_loader(template_path, relative_to=PROMPTS_DIR)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.json_to_yaml","level":3,"title":"<code>json_to_yaml(data)</code>","text":"<p>Convert JSON string or Python dict/list to YAML format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | dict | list</code> <p>JSON string or Python data structure to convert to YAML</p> required <p>Returns:</p> Type Description <code>str</code> <p>YAML formatted string, or original data if conversion fails</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.load_json","level":3,"title":"<code>load_json(json_spec)</code>","text":"<p>Load a JSON string, handling unicode escape sequences.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.log_debug","level":3,"title":"<code>log_debug(msg, offset=24, prefix='', suffix='', show_sep=None, show_length=False)</code>","text":"<p>Log a debug message with a separator line above and below.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.mutate_user_message","level":3,"title":"<code>mutate_user_message(content, messages, suffix=True, wrap=False, inplace=True)</code>","text":"<p>Helper to mutate the last user message in a list of messages. Suffixes the content by default, else prefixes.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.normalized_name","level":3,"title":"<code>normalized_name(inst)</code>","text":"<p>Returns the name of a Parameterized instance, stripping the auto-generated object count.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.parse_huggingface_url","level":3,"title":"<code>parse_huggingface_url(url)</code>","text":"<p>Parse a HuggingFace URL to extract repo, model file, and model_kwargs.</p> <p>Args:     url: HuggingFace URL in format https://huggingface.co/org/repo/blob/main/file.gguf?param1=value1&amp;param2=value2</p> <p>Returns:     tuple: (repo, model_file, model_kwargs)</p> <p>Raises:     ValueError: If URL format is invalid</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.parse_table_slug","level":3,"title":"<code>parse_table_slug(table, sources, normalize=True)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.process_enums","level":3,"title":"<code>process_enums(spec, num_cols, limit=None, include_enum=True, reduce_enums=True, include_empty_fields=False)</code>","text":"<p>Process enum values in a schema field specification.</p> <p>Parameters:</p> Name Type Description Default <code>spec</code> <code>dict</code> <p>The specification dictionary for this field</p> required <code>num_cols</code> <code>int</code> <p>The total number of columns in the schema (used for enum reduction calculation)</p> required <code>limit</code> <code>int</code> <p>The limit used in schema generation</p> <code>None</code> <code>include_enum</code> <code>bool</code> <p>Whether to include enum values</p> <code>True</code> <code>reduce_enums</code> <code>bool</code> <p>Whether to reduce the number of enum values for readability</p> <code>True</code> <code>include_empty_fields</code> <code>bool</code> <p>Whether to include fields that are empty</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[dict, bool]</code> <p>The updated spec dictionary and a boolean indicating if this field is empty</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.render_template","level":3,"title":"<code>render_template(template_path, overrides=None, relative_to=PROMPTS_DIR, **context)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.report_error","level":3,"title":"<code>report_error(exc, step, language='python', context='', status='failed')</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.retry_llm_output","level":3,"title":"<code>retry_llm_output(retries=3, sleep=1)</code>","text":"<p>Retry a function that returns a response from the LLM API. If the function raises an exception, retry it up to <code>retries</code> times. If <code>sleep</code> is provided, wait that many seconds between retries. If an error occurs, pass the error message into kwargs for the function to manually handle by including it.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.sanitize_column_names","level":3,"title":"<code>sanitize_column_names(df)</code>","text":"<p>Sanitize DataFrame column names for use in code execution.</p> <p>Replaces spaces with underscores and removes non-alphanumeric characters (except underscores) from column names.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame whose columns should be sanitized</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A copy of the DataFrame with sanitized column names</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.set_nested","level":3,"title":"<code>set_nested(data, keys, value)</code>","text":"<p>Set nested dictionary value</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.stream_details","level":3,"title":"<code>stream_details(content, step, title='Expand for details', auto=True, **stream_kwargs)</code>","text":"<p>Process content to place code blocks inside collapsible details elements</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content to format</p> required <code>step</code> <code>Any</code> <p>The chat step to stream the formatted content to, or NullStep if interface is None</p> required <code>title</code> <code>str</code> <p>The title of the details component</p> <code>'Expand for details'</code> <code>auto</code> <code>bool</code> <p>Whether to automatically determine what to put in details or all. If False, all of content will be placed in details components.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>The formatted content with code blocks in details components</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.truncate_iterable","level":3,"title":"<code>truncate_iterable(iterable, max_length=150)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.truncate_string","level":3,"title":"<code>truncate_string(s, max_length=30, ellipsis='...')</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.warn_on_unused_variables","level":3,"title":"<code>warn_on_unused_variables(string, kwargs, prompt_label)</code>","text":"","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.with_timeout","level":3,"title":"<code>with_timeout(coro, timeout_seconds=10, default_value=None, error_message=None)</code>  <code>async</code>","text":"<p>Executes a coroutine with a timeout.</p> <p>Parameters:</p> Name Type Description Default <code>coro</code> <code>coroutine</code> <p>The coroutine to execute with a timeout</p> required <code>timeout_seconds</code> <code>float</code> <p>Maximum number of seconds to wait before timing out</p> <code>10</code> <code>default_value</code> <code>Any</code> <p>Value to return if timeout occurs</p> <code>None</code> <code>error_message</code> <code>str</code> <p>Custom error message to log on timeout</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>Result of the coroutine if it completes in time, otherwise default_value</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.wrap_logfire","level":3,"title":"<code>wrap_logfire(span_name=None, extract_args=True, **instrument_kwargs)</code>","text":"<p>Decorator to instrument a function with logfire if llm.logfire_tags is provided. Expects the decorated function to have an 'llm' attribute (on self) or be passed via instrument_kwargs.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/core/#lumen.ai.utils.wrap_logfire_on_method","level":3,"title":"<code>wrap_logfire_on_method(cls, method_name)</code>","text":"<p>Automatically adds logfire wrapping to a method.</p>","path":["Reference","API","AI","AI Core Components"],"tags":[]},{"location":"reference/api/ai/models/","level":1,"title":"AI Models","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models","level":2,"title":"<code>lumen.ai.models</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.LineEdit","level":3,"title":"<code>LineEdit = Annotated[InsertLine | ReplaceLine | DeleteLine, Field(discriminator='op')]</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.DeleteLine","level":3,"title":"<code>DeleteLine</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.DeleteLine.line_no","level":4,"title":"<code>line_no = Field(ge=1, description='The 1-based line number to delete.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.DeleteLine.op","level":4,"title":"<code>op = 'delete'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ErrorDescription","level":3,"title":"<code>ErrorDescription</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a user-facing error explanation.</p> <p>Style rules: - Do not use first-person pronouns (‚ÄúI‚Äù, ‚Äúwe‚Äù). - All outputs must be written in neutral, system-level language.</p> <p>Guidance: - If you think it's an internal error, indicate that the user should rerun. - Otherwise, ask the user to either replan OR clarify their questions. - You are given the error type, message, the user query, and the plan the planning agent came up with.</p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ErrorDescription.explanation","level":4,"title":"<code>explanation = Field(description='A brief description of the error suitable for a non-technical user.', max_length=300)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.EscapeBaseModel","level":3,"title":"<code>EscapeBaseModel</code>","text":"<p>               Bases: <code>PartialBaseModel</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.EscapeBaseModel.insufficient_context","level":4,"title":"<code>insufficient_context = Field(description='True if lacking context, else False. If True, leave other fields empty.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.EscapeBaseModel.insufficient_context_reason","level":4,"title":"<code>insufficient_context_reason = Field(description=\"If lacking sufficient context, explain why; else use ''. Do not base off the user query; only from the data context provided.\", examples=['A timeseries is requested but SQL only provides customer and order data; please include a time dimension', 'The previous result is one aggregated value; try a different aggregation or more dimensions', ''])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.EscapeBaseModel.model_post_init","level":4,"title":"<code>model_post_init(__context)</code>","text":"<p>After model initialization, check if insufficient_context. If it is, raise a MissingContextError with the provided explanation to stop further processing.</p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.InsertLine","level":3,"title":"<code>InsertLine</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.InsertLine.line","level":4,"title":"<code>line = Field(min_length=1, description='Content for the new line (must be non-empty).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.InsertLine.line_no","level":4,"title":"<code>line_no = Field(ge=1, description='Insert BEFORE this 1-based line number. Use line_no == len(lines) to append at the end.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.InsertLine.op","level":4,"title":"<code>op = 'insert'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.MissingContextError","level":3,"title":"<code>MissingContextError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raise to indicate missing context for a query.</p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.PartialBaseModel","level":3,"title":"<code>PartialBaseModel</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>PartialLiteralMixin</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ReplaceLine","level":3,"title":"<code>ReplaceLine</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ReplaceLine.line","level":4,"title":"<code>line = Field(description='The new content for the line (empty string is allowed).')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ReplaceLine.line_no","level":4,"title":"<code>line_no = Field(ge=1, description='The 1-based line number to replace.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ReplaceLine.op","level":4,"title":"<code>op = 'replace'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.RetrySpec","level":3,"title":"<code>RetrySpec</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a revision of text with its content and changes.</p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.RetrySpec.chain_of_thought","level":4,"title":"<code>chain_of_thought = Field(description='In 1-2 sentences, explain the plan to revise the text based on the feedback provided.', examples=['The SQL query failed due to missing quotes around the column name. Will add double quotes to fix the syntax error.', 'The chart needs horizontal bars instead of vertical. Will swap x and y encodings.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.RetrySpec.edits","level":4,"title":"<code>edits = Field(description='A list of line edits based on the chain_of_thought.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.RetrySpec.validate_indices_nonconflicting","level":4,"title":"<code>validate_indices_nonconflicting()</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ThinkingYesNo","level":3,"title":"<code>ThinkingYesNo</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ThinkingYesNo.chain_of_thought","level":4,"title":"<code>chain_of_thought = Field(description='In 1-2 sentences, explain your reasoning for yes or no.', examples=['The query asks for top 10 hosts which requires extending the existing aggregation from LIMIT 1 to LIMIT 10.', 'The data contains location and count columns needed for a bar chart visualization.'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.ThinkingYesNo.yes","level":4,"title":"<code>yes = Field(description='True if yes, otherwise False.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.YesNo","level":3,"title":"<code>YesNo</code>","text":"<p>               Bases: <code>BaseModel</code></p>","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/models/#lumen.ai.models.YesNo.yes","level":4,"title":"<code>yes = Field(description='True if yes, otherwise False.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Models"],"tags":[]},{"location":"reference/api/ai/tools/","level":1,"title":"AI Tools","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools","level":2,"title":"<code>lumen.ai.tools</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.__all__","level":3,"title":"<code>__all__ = ['Tool', 'FunctionTool', 'ToolUser', 'define_tool', 'VectorLookupTool', 'VectorLookupToolUser', 'MetadataLookup', 'DbtslLookup']</code>  <code>module-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup","level":3,"title":"<code>DbtslLookup</code>","text":"<p>               Bases: <code>VectorLookupTool</code>, <code>DbtslMixin</code></p> <p>DbtslLookup tool that creates a vector store of all available dbt semantic layers and responds with relevant metrics for user queries.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.dimension_fetch_timeout","level":4,"title":"<code>dimension_fetch_timeout = param.Number(default=15, doc='\\n        Maximum time in seconds to wait for a dimension values fetch operation.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.max_concurrent","level":4,"title":"<code>max_concurrent = param.Integer(default=5, doc='\\n        Maximum number of concurrent metadata fetch operations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.min_similarity","level":4,"title":"<code>min_similarity = param.Number(default=0.1, doc='\\n        The minimum similarity to include a document.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.n","level":4,"title":"<code>n = param.Integer(default=4, bounds=(1, None), doc='\\n        The number of document results to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.output_schema","level":4,"title":"<code>output_schema = DbtslLookupOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.prompts","level":4,"title":"<code>prompts = param.Dict(default={'refine_query': {'template': PROMPTS_DIR / 'VectorLookupTool' / 'refine_query.jinja2', 'response_model': make_refined_query_model}, 'main': {'template': PROMPTS_DIR / 'DbtslLookup' / 'main.jinja2', 'response_model': ThinkingYesNo}}, doc='Dictionary of available prompts for the tool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Looks up additional context by querying dbt semantic layers based on the user query with a vector store.\\n        Useful for quickly gathering information about dbt semantic layers and their metrics to plan the steps.\\n        Not useful for looking up what datasets are available. Likely useful for all queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.DbtslLookup.respond","level":4,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"<p>Fetches metrics based on the user query, populates the DbtslMetaset, and returns formatted context.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool","level":3,"title":"<code>FunctionTool</code>","text":"<p>               Bases: <code>Tool</code></p> <p>FunctionTool wraps arbitrary functions and makes them available as a tool for an LLM to call. It inspects the arguments of the function and generates a pydantic Model that the LLM will populate.</p> <p>The function may also consume information in memory, e.g. the current table or pipeline by declaring the requires parameter.</p> <p>The function may also return context to add to the current working memory by returning a dictionary and declaring the <code>provides</code> parameter. Any keys listed in the provides parameter will be copied into working memory.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.formatter","level":4,"title":"<code>formatter = param.Parameter(default='{function}({arguments}) returned: {output}', doc=\"\\n        Formats the return value for inclusion in the global context.\\n        Accepts the 'function', 'arguments' and 'output' as formatting variables.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.function","level":4,"title":"<code>function = param.Callable(default=None, allow_refs=False, doc='\\n        The function to call.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.inputs","level":4,"title":"<code>inputs</code>  <code>property</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.prompts","level":4,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'FunctionTool' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.provides","level":4,"title":"<code>provides = param.List(default=[], readonly=False, constant=True, doc='\\n        List of context values it provides to current working memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.render_output","level":4,"title":"<code>render_output = param.Boolean(default=False, doc='\\n        Whether to render the tool output directly, even if it is not already a Lumen View or Panel Viewable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.requires","level":4,"title":"<code>requires = param.List(default=[], readonly=False, constant=True, doc='\\n        List of context values it requires to be in memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.FunctionTool.respond","level":4,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup","level":3,"title":"<code>MetadataLookup</code>","text":"<p>               Bases: <code>VectorLookupTool</code></p> <p>MetadataLookup tool that creates a vector store of all available tables and responds with relevant tables for user queries.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.always_use","level":4,"title":"<code>always_use = param.Boolean(default=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.conditions","level":4,"title":"<code>conditions = param.List(default=['Best paired with ChatAgent for general conversation about data', 'Avoid if table discovery already performed for same request', 'Not useful for data related queries'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.exclusions","level":4,"title":"<code>exclusions = param.List(default=['dbtsl_metaset'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.include_columns","level":4,"title":"<code>include_columns = param.Boolean(default=True, doc='\\n        Whether to include column names and descriptions in the embeddings.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.include_metadata","level":4,"title":"<code>include_metadata = param.Boolean(default=True, doc='\\n        Whether to include table descriptions in the embeddings and responses.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.include_misc","level":4,"title":"<code>include_misc = param.Boolean(default=False, doc='\\n        Whether to include miscellaneous metadata in the embeddings,\\n        besides table and column descriptions.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.input_schema","level":4,"title":"<code>input_schema = MetadataLookupInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.max_concurrent","level":4,"title":"<code>max_concurrent = param.Integer(default=1, doc='\\n        Maximum number of concurrent metadata fetch operations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.min_similarity","level":4,"title":"<code>min_similarity = param.Number(default=0, doc='\\n        The minimum similarity to include a document.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.n","level":4,"title":"<code>n = param.Integer(default=20, bounds=(1, None), doc='\\n        The number of document results to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.n_documents","level":4,"title":"<code>n_documents = param.Integer(default=4, bounds=(1, None), doc='\\n        The number of document chunks to retrieve per table.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.not_with","level":4,"title":"<code>not_with = param.List(default=[])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.output_schema","level":4,"title":"<code>output_schema = MetadataLookupOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.prompts","level":4,"title":"<code>prompts = param.Dict(default={'refine_query': {'template': PROMPTS_DIR / 'VectorLookupTool' / 'refine_query.jinja2', 'response_model': make_refined_query_model}}, doc='Dictionary of available prompts for the tool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.purpose","level":4,"title":"<code>purpose = param.String(default='\\n        Discovers relevant tables using vector search, providing context for other agents.\\n        Not to be used for finding tables for further analysis (e.g. SQL), because it does\\n        not provide a schema.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.respond","level":4,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"<p>Fetches tables based on the user query and returns formatted context.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.MetadataLookup.sync","level":4,"title":"<code>sync(context)</code>  <code>async</code>","text":"<p>Sync the vector store with updated context. Only processes new sources that haven't been added yet.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.Tool","level":3,"title":"<code>Tool</code>","text":"<p>               Bases: <code>Actor</code>, <code>ContextProvider</code></p> <p>A Tool can be invoked by another Actor to provide additional context or respond to a question. Unlike an Agent they never interact with or on behalf of a user directly.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.Tool.always_use","level":4,"title":"<code>always_use = param.Boolean(default=False, doc='\\n        Whether to always use this tool, even if it is not explicitly\\n        required by the current context.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.Tool.conditions","level":4,"title":"<code>conditions = param.List(default=['Always requires a supporting agent to interpret results'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.Tool.applies","level":4,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Additional checks to determine if the tool should be used.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.Tool.prepare","level":4,"title":"<code>prepare(context)</code>  <code>async</code>","text":"<p>Prepare the tool with the initial context. Called once when the tool is first initialized.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.Tool.sync","level":4,"title":"<code>sync(context)</code>  <code>async</code>","text":"<p>Allows the tool to update when the provided context changes. Subclasses should override this to handle context updates.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.ToolUser","level":3,"title":"<code>ToolUser</code>","text":"<p>               Bases: <code>Actor</code></p> <p>ToolUser is a mixin class for actors that use tools.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.ToolUser.tools","level":4,"title":"<code>tools = param.List(default=[], doc='\\n        List of tools to use.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool","level":3,"title":"<code>VectorLookupTool</code>","text":"<p>               Bases: <code>Tool</code></p> <p>Baseclass for tools that search a vector database for relevant chunks.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.document_vector_store","level":4,"title":"<code>document_vector_store = param.ClassSelector(class_=VectorStore, default=None, constant=True, doc='\\n        Separate vector store for documents. If None, uses the same vector store as tables.\\n        This allows for different embedding strategies or storage backends for documents vs tables.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.enable_query_refinement","level":4,"title":"<code>enable_query_refinement = param.Boolean(default=True, doc='\\n        Whether to enable query refinement for improving search results.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.max_refinement_iterations","level":4,"title":"<code>max_refinement_iterations = param.Integer(default=3, bounds=(1, 10), doc='\\n        Maximum number of refinement iterations to perform.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.min_refinement_improvement","level":4,"title":"<code>min_refinement_improvement = param.Number(default=0.05, bounds=(0, 1), doc='\\n        Minimum improvement in similarity score required to keep refining.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.min_similarity","level":4,"title":"<code>min_similarity = param.Number(default=0.3, doc='\\n        The minimum similarity to include a document.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.n","level":4,"title":"<code>n = param.Integer(default=5, bounds=(1, None), doc='\\n        The number of document results to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.output_schema","level":4,"title":"<code>output_schema = VectorLookupOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.prompts","level":4,"title":"<code>prompts = param.Dict(default={'refine_query': {'template': PROMPTS_DIR / 'VectorLookupTool' / 'refine_query.jinja2', 'response_model': make_refined_query_model}}, doc='Dictionary of available prompts for the tool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.refinement_similarity_threshold","level":4,"title":"<code>refinement_similarity_threshold = param.Number(default=0.05, bounds=(0, 1), doc='\\n        Similarity threshold below which query refinement is triggered.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.vector_store","level":4,"title":"<code>vector_store = param.ClassSelector(class_=VectorStore, constant=True, doc='\\n        Vector store object which is queried to provide additional context\\n        before responding.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.prepare","level":4,"title":"<code>prepare(context)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupTool.respond","level":4,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"<p>Respond to a user query using the vector store.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[Message]</code> <p>The user query and any additional context</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the response</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The response from the vector store</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupToolUser","level":3,"title":"<code>VectorLookupToolUser</code>","text":"<p>               Bases: <code>ToolUser</code></p> <p>VectorLookupToolUser is a mixin class for actors that use vector lookup tools.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupToolUser.document_vector_store","level":4,"title":"<code>document_vector_store = param.ClassSelector(class_=VectorStore, default=None, doc='\\n        The vector store to use for document tools. If not provided, a new one will be created\\n        or inferred from the tools provided.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.VectorLookupToolUser.vector_store","level":4,"title":"<code>vector_store = param.ClassSelector(class_=VectorStore, default=None, doc='\\n        The vector store to use for the tools. If not provided, a new one will be created\\n        or inferred from the tools provided.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.define_tool","level":3,"title":"<code>define_tool(*, requires=None, provides=None, purpose=None, render_output=None)</code>","text":"<p>Annotate a function so FunctionTool can read tool metadata.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base","level":3,"title":"<code>base</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool","level":4,"title":"<code>FunctionTool</code>","text":"<p>               Bases: <code>Tool</code></p> <p>FunctionTool wraps arbitrary functions and makes them available as a tool for an LLM to call. It inspects the arguments of the function and generates a pydantic Model that the LLM will populate.</p> <p>The function may also consume information in memory, e.g. the current table or pipeline by declaring the requires parameter.</p> <p>The function may also return context to add to the current working memory by returning a dictionary and declaring the <code>provides</code> parameter. Any keys listed in the provides parameter will be copied into working memory.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.formatter","level":5,"title":"<code>formatter = param.Parameter(default='{function}({arguments}) returned: {output}', doc=\"\\n        Formats the return value for inclusion in the global context.\\n        Accepts the 'function', 'arguments' and 'output' as formatting variables.\")</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.function","level":5,"title":"<code>function = param.Callable(default=None, allow_refs=False, doc='\\n        The function to call.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.inputs","level":5,"title":"<code>inputs</code>  <code>property</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.prompts","level":5,"title":"<code>prompts = param.Dict(default={'main': {'template': PROMPTS_DIR / 'FunctionTool' / 'main.jinja2'}})</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.provides","level":5,"title":"<code>provides = param.List(default=[], readonly=False, constant=True, doc='\\n        List of context values it provides to current working memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.render_output","level":5,"title":"<code>render_output = param.Boolean(default=False, doc='\\n        Whether to render the tool output directly, even if it is not already a Lumen View or Panel Viewable.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.requires","level":5,"title":"<code>requires = param.List(default=[], readonly=False, constant=True, doc='\\n        List of context values it requires to be in memory.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.FunctionTool.respond","level":5,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.Tool","level":4,"title":"<code>Tool</code>","text":"<p>               Bases: <code>Actor</code>, <code>ContextProvider</code></p> <p>A Tool can be invoked by another Actor to provide additional context or respond to a question. Unlike an Agent they never interact with or on behalf of a user directly.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.Tool.always_use","level":5,"title":"<code>always_use = param.Boolean(default=False, doc='\\n        Whether to always use this tool, even if it is not explicitly\\n        required by the current context.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.Tool.conditions","level":5,"title":"<code>conditions = param.List(default=['Always requires a supporting agent to interpret results'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.Tool.applies","level":5,"title":"<code>applies(context)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Additional checks to determine if the tool should be used.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.Tool.prepare","level":5,"title":"<code>prepare(context)</code>  <code>async</code>","text":"<p>Prepare the tool with the initial context. Called once when the tool is first initialized.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.Tool.sync","level":5,"title":"<code>sync(context)</code>  <code>async</code>","text":"<p>Allows the tool to update when the provided context changes. Subclasses should override this to handle context updates.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.ToolUser","level":4,"title":"<code>ToolUser</code>","text":"<p>               Bases: <code>Actor</code></p> <p>ToolUser is a mixin class for actors that use tools.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.ToolUser.tools","level":5,"title":"<code>tools = param.List(default=[], doc='\\n        List of tools to use.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.base.define_tool","level":4,"title":"<code>define_tool(*, requires=None, provides=None, purpose=None, render_output=None)</code>","text":"<p>Annotate a function so FunctionTool can read tool metadata.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup","level":3,"title":"<code>dbtsl_lookup</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup","level":4,"title":"<code>DbtslLookup</code>","text":"<p>               Bases: <code>VectorLookupTool</code>, <code>DbtslMixin</code></p> <p>DbtslLookup tool that creates a vector store of all available dbt semantic layers and responds with relevant metrics for user queries.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.dimension_fetch_timeout","level":5,"title":"<code>dimension_fetch_timeout = param.Number(default=15, doc='\\n        Maximum time in seconds to wait for a dimension values fetch operation.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.max_concurrent","level":5,"title":"<code>max_concurrent = param.Integer(default=5, doc='\\n        Maximum number of concurrent metadata fetch operations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.min_similarity","level":5,"title":"<code>min_similarity = param.Number(default=0.1, doc='\\n        The minimum similarity to include a document.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.n","level":5,"title":"<code>n = param.Integer(default=4, bounds=(1, None), doc='\\n        The number of document results to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.output_schema","level":5,"title":"<code>output_schema = DbtslLookupOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.prompts","level":5,"title":"<code>prompts = param.Dict(default={'refine_query': {'template': PROMPTS_DIR / 'VectorLookupTool' / 'refine_query.jinja2', 'response_model': make_refined_query_model}, 'main': {'template': PROMPTS_DIR / 'DbtslLookup' / 'main.jinja2', 'response_model': ThinkingYesNo}}, doc='Dictionary of available prompts for the tool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Looks up additional context by querying dbt semantic layers based on the user query with a vector store.\\n        Useful for quickly gathering information about dbt semantic layers and their metrics to plan the steps.\\n        Not useful for looking up what datasets are available. Likely useful for all queries.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookup.respond","level":5,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"<p>Fetches metrics based on the user query, populates the DbtslMetaset, and returns formatted context.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookupOutputs","level":4,"title":"<code>DbtslLookupOutputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.dbtsl_lookup.DbtslLookupOutputs.dbtsl_metaset","level":5,"title":"<code>dbtsl_metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup","level":3,"title":"<code>metadata_lookup</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup","level":4,"title":"<code>MetadataLookup</code>","text":"<p>               Bases: <code>VectorLookupTool</code></p> <p>MetadataLookup tool that creates a vector store of all available tables and responds with relevant tables for user queries.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.always_use","level":5,"title":"<code>always_use = param.Boolean(default=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.conditions","level":5,"title":"<code>conditions = param.List(default=['Best paired with ChatAgent for general conversation about data', 'Avoid if table discovery already performed for same request', 'Not useful for data related queries'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.exclusions","level":5,"title":"<code>exclusions = param.List(default=['dbtsl_metaset'])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.include_columns","level":5,"title":"<code>include_columns = param.Boolean(default=True, doc='\\n        Whether to include column names and descriptions in the embeddings.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.include_metadata","level":5,"title":"<code>include_metadata = param.Boolean(default=True, doc='\\n        Whether to include table descriptions in the embeddings and responses.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.include_misc","level":5,"title":"<code>include_misc = param.Boolean(default=False, doc='\\n        Whether to include miscellaneous metadata in the embeddings,\\n        besides table and column descriptions.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.input_schema","level":5,"title":"<code>input_schema = MetadataLookupInputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.max_concurrent","level":5,"title":"<code>max_concurrent = param.Integer(default=1, doc='\\n        Maximum number of concurrent metadata fetch operations.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.min_similarity","level":5,"title":"<code>min_similarity = param.Number(default=0, doc='\\n        The minimum similarity to include a document.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.n","level":5,"title":"<code>n = param.Integer(default=20, bounds=(1, None), doc='\\n        The number of document results to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.n_documents","level":5,"title":"<code>n_documents = param.Integer(default=4, bounds=(1, None), doc='\\n        The number of document chunks to retrieve per table.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.not_with","level":5,"title":"<code>not_with = param.List(default=[])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.output_schema","level":5,"title":"<code>output_schema = MetadataLookupOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.prompts","level":5,"title":"<code>prompts = param.Dict(default={'refine_query': {'template': PROMPTS_DIR / 'VectorLookupTool' / 'refine_query.jinja2', 'response_model': make_refined_query_model}}, doc='Dictionary of available prompts for the tool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.purpose","level":5,"title":"<code>purpose = param.String(default='\\n        Discovers relevant tables using vector search, providing context for other agents.\\n        Not to be used for finding tables for further analysis (e.g. SQL), because it does\\n        not provide a schema.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.respond","level":5,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"<p>Fetches tables based on the user query and returns formatted context.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookup.sync","level":5,"title":"<code>sync(context)</code>  <code>async</code>","text":"<p>Sync the vector store with updated context. Only processes new sources that haven't been added yet.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookupInputs","level":4,"title":"<code>MetadataLookupInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookupInputs.sources","level":5,"title":"<code>sources</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookupOutputs","level":4,"title":"<code>MetadataLookupOutputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.metadata_lookup.MetadataLookupOutputs.metaset","level":5,"title":"<code>metaset</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup","level":3,"title":"<code>vector_lookup</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupInputs","level":4,"title":"<code>VectorLookupInputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupInputs.document_sources","level":5,"title":"<code>document_sources</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupOutputs","level":4,"title":"<code>VectorLookupOutputs</code>","text":"<p>               Bases: <code>ContextModel</code></p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupOutputs.document_chunks","level":5,"title":"<code>document_chunks</code>  <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool","level":4,"title":"<code>VectorLookupTool</code>","text":"<p>               Bases: <code>Tool</code></p> <p>Baseclass for tools that search a vector database for relevant chunks.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.document_vector_store","level":5,"title":"<code>document_vector_store = param.ClassSelector(class_=VectorStore, default=None, constant=True, doc='\\n        Separate vector store for documents. If None, uses the same vector store as tables.\\n        This allows for different embedding strategies or storage backends for documents vs tables.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.enable_query_refinement","level":5,"title":"<code>enable_query_refinement = param.Boolean(default=True, doc='\\n        Whether to enable query refinement for improving search results.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.max_refinement_iterations","level":5,"title":"<code>max_refinement_iterations = param.Integer(default=3, bounds=(1, 10), doc='\\n        Maximum number of refinement iterations to perform.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.min_refinement_improvement","level":5,"title":"<code>min_refinement_improvement = param.Number(default=0.05, bounds=(0, 1), doc='\\n        Minimum improvement in similarity score required to keep refining.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.min_similarity","level":5,"title":"<code>min_similarity = param.Number(default=0.3, doc='\\n        The minimum similarity to include a document.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.n","level":5,"title":"<code>n = param.Integer(default=5, bounds=(1, None), doc='\\n        The number of document results to return.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.output_schema","level":5,"title":"<code>output_schema = VectorLookupOutputs</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.prompts","level":5,"title":"<code>prompts = param.Dict(default={'refine_query': {'template': PROMPTS_DIR / 'VectorLookupTool' / 'refine_query.jinja2', 'response_model': make_refined_query_model}}, doc='Dictionary of available prompts for the tool.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.refinement_similarity_threshold","level":5,"title":"<code>refinement_similarity_threshold = param.Number(default=0.05, bounds=(0, 1), doc='\\n        Similarity threshold below which query refinement is triggered.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.vector_store","level":5,"title":"<code>vector_store = param.ClassSelector(class_=VectorStore, constant=True, doc='\\n        Vector store object which is queried to provide additional context\\n        before responding.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.prepare","level":5,"title":"<code>prepare(context)</code>  <code>async</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupTool.respond","level":5,"title":"<code>respond(messages, context, **kwargs)</code>  <code>async</code>","text":"<p>Respond to a user query using the vector store.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[Message]</code> <p>The user query and any additional context</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the response</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The response from the vector store</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupToolUser","level":4,"title":"<code>VectorLookupToolUser</code>","text":"<p>               Bases: <code>ToolUser</code></p> <p>VectorLookupToolUser is a mixin class for actors that use vector lookup tools.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupToolUser.document_vector_store","level":5,"title":"<code>document_vector_store = param.ClassSelector(class_=VectorStore, default=None, doc='\\n        The vector store to use for document tools. If not provided, a new one will be created\\n        or inferred from the tools provided.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.VectorLookupToolUser.vector_store","level":5,"title":"<code>vector_store = param.ClassSelector(class_=VectorStore, default=None, doc='\\n        The vector store to use for the tools. If not provided, a new one will be created\\n        or inferred from the tools provided.')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"","path":["Reference","API","AI","AI Tools"],"tags":[]},{"location":"reference/api/ai/tools/#lumen.ai.tools.vector_lookup.make_refined_query_model","level":4,"title":"<code>make_refined_query_model(item_type_name='items')</code>","text":"<p>Creates a model for refining search queries in vector lookup tools.</p>","path":["Reference","API","AI","AI Tools"],"tags":[]}]}